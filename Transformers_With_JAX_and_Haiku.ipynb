{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Transformers With JAX and Haiku",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "68c661c0aa74432db9f9950c4e96a188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_413cd59b06ed4776b46cda8d15297ce6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff16acffb25548308a001ff47cdd43fa",
              "IPY_MODEL_dd68d19b60b944f28ec7513ded1050a3",
              "IPY_MODEL_de047ff4b8414748b26b9f97cf1bc3a5"
            ]
          }
        },
        "413cd59b06ed4776b46cda8d15297ce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff16acffb25548308a001ff47cdd43fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_66d45b9b5aa042fbbf6acff669cdddfc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Dl Completed...: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df009307e465461cb388a14f2d46968c"
          }
        },
        "dd68d19b60b944f28ec7513ded1050a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f059cdf7ab3a4354b732cc4e15b7f6b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27f1eae9cfaa4d73963170258e8cf502"
          }
        },
        "de047ff4b8414748b26b9f97cf1bc3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_784dc7b03ebf4fb0a85debbdafe2070a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:08&lt;00:00,  8.65s/ url]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78120a791345438db745360a8bccb5c9"
          }
        },
        "66d45b9b5aa042fbbf6acff669cdddfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df009307e465461cb388a14f2d46968c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f059cdf7ab3a4354b732cc4e15b7f6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27f1eae9cfaa4d73963170258e8cf502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "784dc7b03ebf4fb0a85debbdafe2070a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78120a791345438db745360a8bccb5c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c7ea9977c3e4333a5d02732d5eca180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7ee3562111574b8a991711528f3f4d74",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_afeb1194499f4bb1967c3b07f7e4a2cb",
              "IPY_MODEL_9968e77b12a5446583179555e3cc7880",
              "IPY_MODEL_afa0325a4291459696acc5d457b10c76"
            ]
          }
        },
        "7ee3562111574b8a991711528f3f4d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afeb1194499f4bb1967c3b07f7e4a2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4335c5e0e1014baea78d21b8645e55de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Dl Size...: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75950b02023a45a6b27172065d2b2427"
          }
        },
        "9968e77b12a5446583179555e3cc7880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f3db87e31d8040c99cbd546a0edad3cb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_710a733a5bcc468e99c9d9adc42ef48c"
          }
        },
        "afa0325a4291459696acc5d457b10c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8666e2d0dd0c46509745cedbe29a4f68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 80/80 [00:08&lt;00:00, 20.17 MiB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb3da8d354924c6185281e6da2530909"
          }
        },
        "4335c5e0e1014baea78d21b8645e55de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75950b02023a45a6b27172065d2b2427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3db87e31d8040c99cbd546a0edad3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "710a733a5bcc468e99c9d9adc42ef48c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8666e2d0dd0c46509745cedbe29a4f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb3da8d354924c6185281e6da2530909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1df968b1e69248e0b4cc06dccd2392fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_678f2e5530ce4d67aae1079ddc34d68c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2c4fba3c50554d5fa35770511d9a6f3c",
              "IPY_MODEL_2fb3067413da4168b39849ff5b755607",
              "IPY_MODEL_abfa791108e048b189a9d65f1e9da3e7"
            ]
          }
        },
        "678f2e5530ce4d67aae1079ddc34d68c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c4fba3c50554d5fa35770511d9a6f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_75b60f5bfe07450ea829a0395d2008a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_099776337fec4a17936681b269df1015"
          }
        },
        "2fb3067413da4168b39849ff5b755607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df54ac1712a44692939f54b8eb6e472f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0dd33e6ac88439488b1d06f260a6515"
          }
        },
        "abfa791108e048b189a9d65f1e9da3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4687af00fdd44471be0906d6457c9b46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 24812/0 [00:13&lt;00:00, 2407.35 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e26eec18ab31477891372cdd881bb7ad"
          }
        },
        "75b60f5bfe07450ea829a0395d2008a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "099776337fec4a17936681b269df1015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df54ac1712a44692939f54b8eb6e472f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0dd33e6ac88439488b1d06f260a6515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4687af00fdd44471be0906d6457c9b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e26eec18ab31477891372cdd881bb7ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1393077b835410b9120357a9ef5cf7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fa11460eabf94d08b99512f11a1351e1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_787d01a3d4074c8a96602245b3a4d497",
              "IPY_MODEL_3fb7bb25cc2f4c088d0a7b15e3cac638",
              "IPY_MODEL_ddc9c0cea36a4ddabb48de27800db7f3"
            ]
          }
        },
        "fa11460eabf94d08b99512f11a1351e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "787d01a3d4074c8a96602245b3a4d497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_305049b8c6e046e0b6e40532a9cd153d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90bed13077dc4739bf1d18454b0c6622"
          }
        },
        "3fb7bb25cc2f4c088d0a7b15e3cac638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e89ae8ef1df748d4b85265027d32f4dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 25000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 24999,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d854088023fe40cda2371852b45297e4"
          }
        },
        "ddc9c0cea36a4ddabb48de27800db7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_47ab33cde0d948acac6ae51889cbab83",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 24999/25000 [00:00&lt;00:00, 117698.04 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a46d2bc0ad64b6b9102694d5b5e3203"
          }
        },
        "305049b8c6e046e0b6e40532a9cd153d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90bed13077dc4739bf1d18454b0c6622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e89ae8ef1df748d4b85265027d32f4dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d854088023fe40cda2371852b45297e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47ab33cde0d948acac6ae51889cbab83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a46d2bc0ad64b6b9102694d5b5e3203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f6a8e0b560b471294e8b96ca7e84871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c824da61f14c47489216b626d343afc7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_46eb7057a35944359eaac3386e59f274",
              "IPY_MODEL_648b289669f243d38ed8cb5e176010f0",
              "IPY_MODEL_5ae2fad50c83418c942dae02e165065f"
            ]
          }
        },
        "c824da61f14c47489216b626d343afc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46eb7057a35944359eaac3386e59f274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e62b459bf7064e17877879e13c8ca8c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03d959e99a3c4425976cbe6fe892aec1"
          }
        },
        "648b289669f243d38ed8cb5e176010f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a418689b5adc4ebea97109a9a6204ebc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7958e00c4f3e4d10983d0bde6bf74fe4"
          }
        },
        "5ae2fad50c83418c942dae02e165065f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ebe3fd04df849f7ad4e113dad6fb731",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 24790/0 [00:10&lt;00:00, 2538.71 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef8fcaebfdc34a2ea03fee4d6026ace5"
          }
        },
        "e62b459bf7064e17877879e13c8ca8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03d959e99a3c4425976cbe6fe892aec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a418689b5adc4ebea97109a9a6204ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7958e00c4f3e4d10983d0bde6bf74fe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ebe3fd04df849f7ad4e113dad6fb731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef8fcaebfdc34a2ea03fee4d6026ace5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3680e41efb9402a963ffa706781d96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_29263eef88ef4029899920d0b65ac27d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65149805503f4bef9f9c9372c0827e9a",
              "IPY_MODEL_1faf079a12e14fed83d2e87567bc78b1",
              "IPY_MODEL_58955bf8c0054c0799f2a8ec63c541e3"
            ]
          }
        },
        "29263eef88ef4029899920d0b65ac27d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65149805503f4bef9f9c9372c0827e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ce2d4157bed465b9e87325e4d12c106",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10a2e4288d464b3eb347a65a3ad415bd"
          }
        },
        "1faf079a12e14fed83d2e87567bc78b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_80f13789d62c4838a12e18500942cbed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 25000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 24999,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e4e48c2f1a74a99be7de00ec543d5a0"
          }
        },
        "58955bf8c0054c0799f2a8ec63c541e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_690136ebeb024dd290ef44f698e62125",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 24999/25000 [00:00&lt;00:00, 132856.58 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c557e793469044f3932c9a122d98b756"
          }
        },
        "1ce2d4157bed465b9e87325e4d12c106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10a2e4288d464b3eb347a65a3ad415bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80f13789d62c4838a12e18500942cbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e4e48c2f1a74a99be7de00ec543d5a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "690136ebeb024dd290ef44f698e62125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c557e793469044f3932c9a122d98b756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "711147881323494f8deff88612a69a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2bfbbb13bf0945fbb76b71c737ffeb17",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2ac65326294431ea91d102ac78b7e6f",
              "IPY_MODEL_43dd414432254eb8a0845688d45dc65f",
              "IPY_MODEL_52b9a2686c6141b9adaa83214ec4b169"
            ]
          }
        },
        "2bfbbb13bf0945fbb76b71c737ffeb17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2ac65326294431ea91d102ac78b7e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_930cc907ff4342f48f731fb9d0e2b025",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12b212a501764a75a20226833f369341"
          }
        },
        "43dd414432254eb8a0845688d45dc65f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8131f72c70b24a928303dc6aca468acf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4aa6b2d17a5a4d2fb98730a41d05eec0"
          }
        },
        "52b9a2686c6141b9adaa83214ec4b169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_221092575ae4488ea581f96952970337",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49848/0 [00:25&lt;00:00, 2593.95 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3937b392e0e45b0946d6b6380b5d28f"
          }
        },
        "930cc907ff4342f48f731fb9d0e2b025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12b212a501764a75a20226833f369341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8131f72c70b24a928303dc6aca468acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4aa6b2d17a5a4d2fb98730a41d05eec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "221092575ae4488ea581f96952970337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3937b392e0e45b0946d6b6380b5d28f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b06dcca0f8334696a6012c2f184458d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_23975f1c2a8d446584f1d73482b74aae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2994ff6f82a74172b28e6f213fac574e",
              "IPY_MODEL_dbae898880e040758a0b41b99ba6fcb8",
              "IPY_MODEL_107b4ae2149041d08cea05d329ce358e"
            ]
          }
        },
        "23975f1c2a8d446584f1d73482b74aae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2994ff6f82a74172b28e6f213fac574e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c6b32cfe3d84754bed086ef295d7d84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f996d7f39134c1095afe3377a1c59ca"
          }
        },
        "dbae898880e040758a0b41b99ba6fcb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_484fdf48921c4f5492f470d0a3d43002",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 50000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49999,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_716e5bcb717342528ac5c4f900b442dd"
          }
        },
        "107b4ae2149041d08cea05d329ce358e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4c95f7a53ea04386bc7ec7f9ce59417a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49999/50000 [00:00&lt;00:00, 133600.69 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d68ec2b9959e4299be9f79eefa0e535e"
          }
        },
        "5c6b32cfe3d84754bed086ef295d7d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f996d7f39134c1095afe3377a1c59ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "484fdf48921c4f5492f470d0a3d43002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "716e5bcb717342528ac5c4f900b442dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c95f7a53ea04386bc7ec7f9ce59417a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d68ec2b9959e4299be9f79eefa0e535e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prokaj/kaggle-feedback-2021/blob/main/Transformers_With_JAX_and_Haiku.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2XMaLX1mNhk"
      },
      "source": [
        "Just last month [DeepMind open-sourced Haiku](https://github.com/deepmind/dm-haiku), the JAX version of their tensorflow [neural network library Sonnet](https://github.com/deepmind/sonnet).  Today we'll be walking through a port of the RoBERTa pre-trained model to JAX + Haiku, then finetuning the model to solve a downstream task! \n",
        "\n",
        "If you're unfamiliar with JAX, need a primer on JAX fundamentals, or simply want to know why you should care, check out my previous post -- [A First Look at JAX](https://www.pragmatic.ml/first-look-at-jax/) or wander on over to the [official JAX documentation](https://jax.readthedocs.io/en/latest/).\n",
        "\n",
        "Some brief notes about the format of this blog post:\n",
        "    - This post will be code-oriented and show code examples first before providing commentary. \n",
        "    - We're going to be working in a top-down fashion, so we'll lay out broad strokes and then fill in the detail.\n",
        "    - Along the way I'll add notes on potential JAX / Haiku stumbling blocks and rough edges that you may find useful if you're just getting started with either.\n",
        "\n",
        "If you'd like to run the code as you read along I've also made this walkthrough available as a Colab notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7BDW9r5uQC5"
      },
      "source": [
        "Without further ado, let's explore Haiku!\n",
        "\n",
        "The Haiku README provides an excellent short description of Haiku's role in the JAX ecosystem:\n",
        "\n",
        "> * Haiku is a simple neural network library for JAX that enables users to use familiar object-oriented programming \n",
        "models while allowing full access to JAX's pure function transformations.\n",
        "> * Haiku provides two core tools: a module abstraction, hk.Module, and a simple function transformation, hk.transform.\n",
        "> * hk.Modules are Python objects that hold references to their own parameters, other modules, and methods that apply functions on user inputs.\n",
        "> * hk.transform turns functions that use these object-oriented, functionally \"impure\" modules into pure functions that can be used with jax.jit, jax.grad, jax.pmap, etc.\n",
        "\n",
        "In addition to those two key abstractions, Haiku provides a collection of common neural network components like convolutions, pooling operations, RNN / GRU / LSTM units, batch norm and other normalization methods, padding operations, and a suite of a initializers. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "Mcz0gevOrkLZ",
        "outputId": "f6d8f39a-1988-4080-abce-a3c7dfb0bbd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U jax jaxlib==0.1.75+cuda11.cudnn82 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
        "# jaxlib"
      ],
      "metadata": {
        "id": "Gm0cwlN2hwX-",
        "outputId": "60785e29-974d-4bdb-a67c-13fb2affd9b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_releases.html\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (0.2.26)\n",
            "Collecting jaxlib==0.1.75+cuda11.cudnn82\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.1.75%2Bcuda11.cudnn82-cp37-none-manylinux2010_x86_64.whl (149.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 149.4 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.75+cuda11.cudnn82) (2.0)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.75+cuda11.cudnn82) (1.19.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.75+cuda11.cudnn82) (0.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.75+cuda11.cudnn82) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax) (3.10.0.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jaxlib==0.1.75+cuda11.cudnn82) (1.15.0)\n",
            "Installing collected packages: jaxlib\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.1.75\n",
            "    Uninstalling jaxlib-0.1.75:\n",
            "      Successfully uninstalled jaxlib-0.1.75\n",
            "Successfully installed jaxlib-0.1.75+cuda11.cudnn82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "print(jax.__version__)\n",
        "import jax.numpy as jnp\n",
        "jnp.zeros(10)\n"
      ],
      "metadata": {
        "id": "CSOok_85hYY5",
        "outputId": "9bb4edd0-3934-4ab0-a47e-52a2d10c3229",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2.26\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYbj4qH_uRYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f3ef5f6-283e-49a9-d81f-8d5e4b4a003a"
      },
      "source": [
        "!pip install git+https://github.com/deepmind/dm-haiku transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/deepmind/dm-haiku\n",
            "  Cloning https://github.com/deepmind/dm-haiku to /tmp/pip-req-build-kykt1loy\n",
            "  Running command git clone -q https://github.com/deepmind/dm-haiku /tmp/pip-req-build-kykt1loy\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.14.1)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.6.dev0) (0.12.0)\n",
            "Requirement already satisfied: jmp>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.6.dev0) (0.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.6.dev0) (1.19.5)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.6.dev0) (0.8.9)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.6.dev0) (3.10.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->dm-haiku==0.0.6.dev0) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_d-yf46lTeo"
      },
      "source": [
        "import haiku as hk\n",
        "\n",
        "class Transformer(hk.Module):\n",
        "\n",
        "    def __init__(self, config, *args, **kwargs):\n",
        "        super().__init__(name=\"Transformer\")\n",
        "        self.config = config\n",
        "    \n",
        "    def __call__(self, token_ids):\n",
        "        x = Embedding(config)(token_ids)\n",
        "        for layer_num, layer in enumerate(range(config.n_layers)):\n",
        "            x = TransformerBlock(config, layer_num=layer_num)(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LTWi6cDtJmb"
      },
      "source": [
        "First, a comment on how Haiku modules are typically structured.  The `__init__` function is where we manage module configuration -- storing values like the number of layers in our transformer, our hidden dimension size, and other parameters. In order for Haiku to function properly, the `__init__()` of all `hk.Modules` must call `super().__init__()`, optionally with a `name`. \n",
        "\n",
        "Note that if we wanted to we could have moved some of this logic around, constructing our TokenEmbedding object in the `__init__` method for instance. Although nothing prevents us from doing this, there are times when we don't have enough information to construct all our modules in the `__init__` method because our configuration is dependent on some property of our input.  Because of this, child `hk.Modules` are often constructed in the same method that is called when the module is applied to an input. It's also simply convenient to have the full declaration of module settings in line with the application of the module to an input, to prevent hopping back and forth between methods when reading code.\n",
        "\n",
        "In our example above, we use the `__call__` method as our application method for brevity but we could equivalently use `forward` or any other method name. An `hk.Module` can also expose more than one application method if desirable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDl06c3bVDcn"
      },
      "source": [
        "import haiku as hk\n",
        "\n",
        "class AlternateTransformer(hk.Module):\n",
        "    \"\"\"\n",
        "    An equally valid implementation\n",
        "    \"\"\"\n",
        "    def __init__(self, config, *args, **kwargs):\n",
        "        super().__init__(name=\"Transformer\")\n",
        "        self.config = config\n",
        "        self.embedder = Embedding(config)\n",
        "    \n",
        "    def embed(self, tokens):\n",
        "        return self.embedder(tokens)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        x = self.embedder(tokens)\n",
        "        for layer in config.n_layers:\n",
        "            x = TransformerBlock(config)(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SYsJBfqVJdH"
      },
      "source": [
        "If you're interested in more detail on how `hk.Module` and `hk.transform` function, I'd recommend Sabrina Mielke's recent article, [\"From PyTorch to JAX: towards neural net frameworks that purify stateful code\"](https://sjmielke.com/jax-purify.htm), which builds up the motivation for the design decisions that Haiku made.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hre0n9grY50o"
      },
      "source": [
        "If we had already implemented the `Embedding` and `TransformerBlock` modules, we could convert our new `hk.Module` to a JAX compatible function through the use of `hk.transform`. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPEc5qq3ZUJN"
      },
      "source": [
        "# We'll fill our our config later\n",
        "config = {'max_length': 512}\n",
        "\n",
        "def features(tokens):\n",
        "    transformer = Transformer(config)\n",
        "    return transformer(tokens)\n",
        "\n",
        "features_fn = hk.transform(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSvAcLL8azAk"
      },
      "source": [
        "Neat!  Let's write our `Embedding` module and plug in some pre-trained model weights from HuggingFace so we can start executing code. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJP4q2debYHX"
      },
      "source": [
        "from transformers import RobertaModel\n",
        "import jax.numpy as jnp\n",
        "\n",
        "\n",
        "class Embedding(hk.Module):\n",
        "    \"\"\"\n",
        "    Embeds tokens and positions into an array of shape [n_batch, n_seq, n_hidden]\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "    def __call__(self, token_ids, training=False):\n",
        "        \"\"\"\n",
        "        token_ids: ints of shape (batch, n_seq)\n",
        "        \"\"\"\n",
        "        word_embeddings = self.config['pretrained']['embeddings/word_embeddings']\n",
        "        \n",
        "        # We have to flatten our tokens before passing them to the hk.Embed module,\n",
        "        # as arrays with more than one dimension are interpreted as multi-dimensional indexes\n",
        "        flat_token_ids = jnp.reshape(token_ids, [token_ids.shape[0] * token_ids.shape[1]])\n",
        "        flat_token_embeddings = hk.Embed(\n",
        "            vocab_size=word_embeddings.shape[0],\n",
        "            embed_dim=word_embeddings.shape[1],\n",
        "            \n",
        "            # Here we're using hk.initializers.Constant to supply pre-trained embeddings\n",
        "            # to our hk.Embed module\n",
        "            w_init=hk.initializers.Constant(self.config['pretrained']['embeddings/word_embeddings'])\n",
        "        )(flat_token_ids)\n",
        "        \n",
        "        # After we've embedded our token IDs, we reshape to recover our batch dimension\n",
        "        token_embeddings = jnp.reshape(\n",
        "            flat_token_embeddings, \n",
        "            [token_ids.shape[0], token_ids.shape[1], word_embeddings.shape[1]]\n",
        "        )\n",
        "        \n",
        "        # Combine our token embeddings with a set of learned positional embeddings\n",
        "        embeddings = token_embeddings + PositionEmbeddings(self.config)()\n",
        "        embeddings = hk.LayerNorm(\n",
        "            axis=-1, \n",
        "            create_scale=True,\n",
        "            create_offset=True,\n",
        "            \n",
        "            # The layer norm parameters are also pretrained, so we have to take care to \n",
        "            # use a constant initializer for these as well\n",
        "            scale_init=hk.initializers.Constant(\n",
        "                self.config['pretrained']['embeddings/LayerNorm/gamma']\n",
        "            ),\n",
        "            offset_init=hk.initializers.Constant(\n",
        "                self.config['pretrained']['embeddings/LayerNorm/beta']\n",
        "            )\n",
        "        )(embeddings)\n",
        "        \n",
        "        # Dropout is will be applied later when we finetune our Roberta implementation \n",
        "        # to solve a classification task. For now we'll set `training` to False.\n",
        "        if training:\n",
        "            embeddings = hk.dropout(\n",
        "                # Haiku magic -- we'll explicitly provide a RNG key to haiku later to make this function\n",
        "                hk.next_rng_key(), \n",
        "                rate=self.config['embed_dropout_rate'], \n",
        "                x=embeddings\n",
        "            )\n",
        "        \n",
        "        return embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2Rm8LL3cE2d"
      },
      "source": [
        "Our Embedding module is pretty straightforward:\n",
        "\n",
        "*   Using `hk.Embed`, we perform a lookup to get the vector that corresponds to each of our token IDs.\n",
        "    * We initialize this to the pre-trained embedding matrix we downloaded.\n",
        "*   We add `PositionEmbeddings()` -- a `hk.Module` we have yet to define.  Assuming a fixed sequence length, this is nothing more than a static matrix that we broadcast to each sequence in our batch.\n",
        "*   We normalize our embeddings using layer norm, applying the scales and offsets learned during pre-training.\n",
        "*   Finally, we optionally apply dropout to our embeddings at train time.\n",
        "    * Note the hk.next_rng_key() feature. With vanilla JAX, we would have to make sure to pass our `PRNGKey` around to every module that needs it.  A handy feature of Haiku is that your `PRNGKey` is exposed via the `hk.next_rng_key` utility with the context of `hk.transform`. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuXwMMNjcEP_"
      },
      "source": [
        "\n",
        "class PositionEmbeddings(hk.Module):\n",
        "    \"\"\"\n",
        "    A position embedding of shape [n_seq, n_hidden]\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        # The Roberta position embeddings are offset by 2\n",
        "        self.offset = 2\n",
        "\n",
        "    def __call__(self):\n",
        "        pretrained_position_embedding = self.config['pretrained']['embeddings/position_embeddings']\n",
        "        position_weights = hk.get_parameter(\n",
        "            \"position_embeddings\", \n",
        "            pretrained_position_embedding.shape,\n",
        "            init=hk.initializers.Constant(pretrained_position_embedding)\n",
        "        )\n",
        "        \n",
        "        return position_weights[self.offset:self.offset + self.config['max_length']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w83Tfx2efQl"
      },
      "source": [
        "The `PositionEmbeddings` module is also pretty straightforward -- we simply slice the pre-trained position embedding matrix to the desired length and return it. However, our `PositionEmbeddings` has introduced a new key haiku function! \n",
        "\n",
        "```\n",
        "hk.get_parameter(name, shape, dtype, init)\n",
        "```\n",
        "\n",
        "The `hk.get_parameter` function is how Haiku keeps track of parameter state for us.  The module we're in and the `name` argument passed to `hk.get_parameter` register this new parameter in a Haiku-managed parameter store. If we were writing something similar with vanilla JAX, we would have to keep track of these parameters manually. Later on we'll see how `hk.transform` allows us to retrieve the values of our parameters using `init()`. \n",
        "\n",
        "[Extended docs for `hk.get_parameter`](https://dm-haiku.readthedocs.io/en/latest/api.html#haiku.get_parameter) are available in the [official Haiku documentation](https://dm-haiku.readthedocs.io/en/latest/).\n",
        "\n",
        "Now that you're familiar with `hk.get_parameter`, let's load in some pre-trained model weights so we can test out what we've put together so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4hScrweZlnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6190a8aa-17f7-4f35-ffdd-2c22cb63de77"
      },
      "source": [
        "from io import BytesIO\n",
        "from functools import lru_cache\n",
        "\n",
        "import joblib\n",
        "import requests\n",
        "\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "\n",
        "# We'll make use of these again later as a means to check our implementation\n",
        "huggingface_roberta = RobertaModel.from_pretrained('roberta-base', output_hidden_states=True)\n",
        "huggingface_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "# Some light postprocessing to make the parameter keys a bit more concise\n",
        "def postprocess_key(key):\n",
        "    return key.replace('model/featurizer/bert/', '').replace(':0', '').replace('self/', '')\n",
        "\n",
        "\n",
        "# Cache the downloaded file to go easy on the tubes \n",
        "@lru_cache()\n",
        "def get_pretrained_weights():\n",
        "    # We'll use the weight dictionary from the Roberta encoder at https://github.com/IndicoDataSolutions/finetune\n",
        "    remote_url = \"https://bendropbox.s3.amazonaws.com/roberta/roberta-model-sm-v2.jl\"\n",
        "    weights = joblib.load(BytesIO(requests.get(remote_url).content))\n",
        "\n",
        "    weights = {\n",
        "        postprocess_key(key): value\n",
        "        for key, value in weights.items()\n",
        "    }\n",
        "    \n",
        "    # We use huggingface's word embedding matrix because their token IDs mapping varies slightly from the \n",
        "    # format used in our joblib file above\n",
        "    weights['embeddings/word_embeddings'] = (\n",
        "        huggingface_roberta.get_input_embeddings().weight.detach().numpy()\n",
        "    )\n",
        "    return weights\n",
        "\n",
        "\n",
        "class Scope(object):\n",
        "    \"\"\"\n",
        "    A tiny utility to help make looking up into our dictionary cleaner.\n",
        "    There's no haiku magic here.\n",
        "    \"\"\"\n",
        "    def __init__(self, weights, prefix):\n",
        "        self.weights = weights\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return self.weights[self.prefix + key]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPr8IW9Lkf1b",
        "outputId": "78c53780-7de6-4be0-f55c-06005a7aaa15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pretrained = get_pretrained_weights()\n",
        "print([k for k in pretrained.keys() if 'embedding' in k])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['embeddings/word_embeddings', 'embeddings/LayerNorm/beta', 'embeddings/LayerNorm/gamma', 'embeddings/token_type_embeddings', 'embeddings/position_embeddings']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HedW0FSl56u"
      },
      "source": [
        "Looks like we have the weights we need for our `Embedding` module, but we're still missing a way to go from text to numeric token IDs in our word embedding matrix.  Let's load in the pre-written tokenizer from huggingface to save ourselves some pain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfdSTXulmQHR",
        "outputId": "9d5eaadd-dff6-4657-b370-c60e510e23c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample_text = \"This was a lot less painful than re-implementing a tokenizer\"\n",
        "encoded = huggingface_tokenizer.batch_encode_plus(\n",
        "    [sample_text, sample_text],\n",
        "    # pad_to_max_length=True,\n",
        "    max_length=config['max_length'],\n",
        "    padding='max_length',\n",
        "    truncation=True\n",
        ")\n",
        "sample_tokens = encoded['input_ids']\n",
        "print(sample_tokens[0][:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 713, 21, 10, 319, 540, 8661, 87, 769, 12, 757, 40224, 154, 10, 19233, 6315, 2, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLbi5eXLnsUM"
      },
      "source": [
        "Looks good!  We've passed the `pad_to_max_length` and `max_length` arguments so that the `huggingface_tokenizer` can handle padding out sequences to a constant length for us -- and it's clearly working as the sea of 1's above show us. Token ID 1 corresponds to the padding token used by RoBERTa.\n",
        "\n",
        "Now we have all the necessary ingredients to test out our embedding layer, let's `hk.transform` the embedding operation and take things for a spin."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5XQBdLfn_r2",
        "outputId": "3313ecd3-49cd-4b70-c6e4-e3396a7fb6cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from jax import jit\n",
        "from jax.random import PRNGKey\n",
        "import numpy as np\n",
        "\n",
        "config = {\n",
        "    'pretrained': pretrained,\n",
        "    'max_length': 512,\n",
        "    'embed_dropout_rate': 0.1\n",
        "}\n",
        "\n",
        "def embed_fn(tokens, training=False):\n",
        "    embedding = Embedding(config)(tokens)\n",
        "    return embedding\n",
        "\n",
        "rng = PRNGKey(42)\n",
        "embed = hk.transform(embed_fn, apply_rng=True)\n",
        "sample_tokens = np.asarray(sample_tokens)\n",
        "params = embed.init(rng, sample_tokens, training=False)\n",
        "embedded_tokens = jit(embed.apply)(params, rng, sample_tokens)\n",
        "print(embedded_tokens.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 512, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNkJ5Ruqy3f3"
      },
      "source": [
        "\n",
        "With that, we've successfully executed our first snippet of code using Haiku!\n",
        "\n",
        "First we wrote `embed_fn` to instantiate an instance of our `Embedding` module and call it.  This is necessary to wrap up all the requisite state for the embedding function for haiku.\n",
        "\n",
        "If you accidentally try to instantiate a `hk.Module` outside of a `hk.transform` context you'll receive a helpful reminder that this isn't permitted. Haiku imposes this constraint so it can \"purify\" our stateful `hk.Module` and convert it into a pure function that functions with JAX.\n",
        "\n",
        "```\n",
        "embedding = Embedding(config)\n",
        "```\n",
        "\n",
        "```\n",
        "ValueError: All `hk.Module`s must be initialized inside an `hk.transform`.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljzB0vhx3L-R"
      },
      "source": [
        "You've probably also noticed that we're using two methods we haven't yet spoken about -- `init()` and `apply()`.  \n",
        "\n",
        "```\n",
        "params = embed.init(rng, sample_tokens, training=False)\n",
        "```\n",
        "The `init` method is a haiku utility that gathers up all the parameters of our custom haiku modules for us and consolidates them into a `frozendict`. The `init()` method is also responsible for initializing any unitialized parameters, which is why we pass a source of randomness (our `rng`) as the first argument.\n",
        "\n",
        "Let's inspect our `params` variable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vytGcmMS3q9v",
        "outputId": "aa40f929-ccab-4ff9-d52d-486348d7e314",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print({key: type(value) for key, value in params.items()})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'embedding/embed': <class 'haiku._src.data_structures.FlatMap'>, 'embedding/position_embeddings': <class 'haiku._src.data_structures.FlatMap'>, 'embedding/layer_norm': <class 'haiku._src.data_structures.FlatMap'>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLGZ-4Zb3_Zh"
      },
      "source": [
        "When we use a `hk.Module` within another `hk.Module`, it gets placed in a subdictionary.  But if we drill down into our frozendict we'll eventually hit the bottom and uncover an `np.ndarray` -- the current state of the weights of our model.  If you're familiar with tensorflow's concept of a variable scope, this should feel familiar. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsyBSKQx4hwZ",
        "outputId": "b6f068c6-8832-494e-98f8-8a4a0e99f114",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print({key: type(value) for key, value in params['embedding/layer_norm'].items()})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'scale': <class 'jaxlib.xla_extension.DeviceArray'>, 'offset': <class 'jaxlib.xla_extension.DeviceArray'>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNyITBR24kkm"
      },
      "source": [
        "It's worth noting, however, that we need to use haiku's `hk.get_parameter` construct (or a `hk.Module`) for the parameters to be tracked automatically.  If we try to use a simple `jnp.ndarray` within the context of `hk.transform` it won't be tracked as a trainable parameter. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0judoXS443VS",
        "outputId": "f9848fcc-46d7-4209-db2d-a252306aa252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import jax\n",
        "\n",
        "def linear_fn(x):\n",
        "    w = jax.random.normal(hk.next_rng_key(), (10, 10))\n",
        "    b = jnp.zeros(10)\n",
        "    return np.dot(w, x) + b\n",
        "\n",
        "linear = hk.transform(linear_fn)\n",
        "params = linear.init(PRNGKey(0), np.random.rand(10))\n",
        "print(params.keys())\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeysOnlyKeysView([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ec4Z-UcJJKu"
      },
      "source": [
        "The second new method is `.apply()`:\n",
        "\n",
        "```\n",
        "embedded_tokens = embed.apply(params, rng, sample_tokens)\n",
        "```\n",
        "\n",
        "The `apply()` method injects the parameters of our model (and if we've passed `apply_rng` to `hk.transform`, our pseudo-random number generator) to the embed function so that we have all the necessary state to compute the output of our function.  This pattern is how `hk.transform` is able to turn a stateful `hk.Module` class into a JAX compatible operation -- `init()` and `apply()` are natural counterparts. Our `init()` method extracts the problematic state from our module, and the second passes that state back into the pure `apply()` method.  Because `apply()` is functionally pure, we're totally free to compose it with any of the standard JAX operations like `jit()` and `grad()`!\n",
        "\n",
        "```\n",
        "embedded_tokens = jit(embed.apply)(params, rng, sample_tokens)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8WC81XVMqoA"
      },
      "source": [
        "In all honestly, that's about all there is to working with Haiku!  That's part of the beauty of it -- Haiku aims to be a library, not a framework -- providing a suite of utilities that complement JAX but doing it's best not to get in your way by requiring custom formats or imposing problematic constraints.\n",
        "\n",
        "With the critical pieces of the haiku API behind us, let's continue implementing our transformer!  Next up -- the `TransformerBlock` module.\n",
        "\n",
        "![alt text](https://i.imgur.com/UrXOmY7.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXOt56z-Rowl"
      },
      "source": [
        "class TransformerBlock(hk.Module):\n",
        "\n",
        "    def __init__(self, config, layer_num):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.n = layer_num\n",
        "\n",
        "    def __call__(self, x, mask, training=False):\n",
        "        scope = Scope(self.config['pretrained'], f'encoder/layer_{self.n}/')\n",
        "        # Feed our input through a multi-head attention operation\n",
        "        attention_output = MultiHeadAttention(self.config, self.n)(x, mask, training=training)\n",
        "\n",
        "        # Add a residual connection with the input to the layer\n",
        "        residual = attention_output + x\n",
        "\n",
        "        # Apply layer norm to the combined output\n",
        "        attention_output = hk.LayerNorm(\n",
        "            axis=-1,\n",
        "            create_scale=True,\n",
        "            create_offset=True,\n",
        "            scale_init=hk.initializers.Constant(scope['attention/output/LayerNorm/gamma']),\n",
        "            offset_init=hk.initializers.Constant(scope['attention/output/LayerNorm/beta']),\n",
        "        )(residual)\n",
        "\n",
        "        # Project out to a larger dim, apply a gelu, and then project back down to our hidden dim\n",
        "        mlp_output = TransformerMLP(self.config, self.n)(attention_output, training=training)\n",
        "\n",
        "        # Residual connection to the output of the attention operation\n",
        "        output_residual = mlp_output + attention_output\n",
        "\n",
        "        # Apply another LayerNorm\n",
        "        layer_output = hk.LayerNorm(\n",
        "            axis=-1,\n",
        "            create_scale=True,\n",
        "            create_offset=True,\n",
        "            scale_init=hk.initializers.Constant(scope['output/LayerNorm/gamma']),\n",
        "            offset_init=hk.initializers.Constant(scope['output/LayerNorm/beta']),\n",
        "        )(output_residual) \n",
        "        return layer_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmiwUBmH8sx3"
      },
      "source": [
        "We feed the inputs to each transformer block through it's signature self-attention layer, then add in residuals and apply layer normalization.\n",
        "We then feed the attention outputs through a 2 layer MLP, apply the residuals from the self-attention output, and apply a second layer normalization step.\n",
        "\n",
        "Let's define our MultiHeadAttention layer next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsusUYin4sQW"
      },
      "source": [
        "![Multi-Head Self-Attention](https://i.imgur.com/FvjWVvX.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzLCMjzOZX-W"
      },
      "source": [
        "class MultiHeadAttention(hk.Module):\n",
        "\n",
        "    def __init__(self, config, layer_num):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.n = layer_num\n",
        "\n",
        "    def _split_into_heads(self, x):\n",
        "        return jnp.reshape(\n",
        "            x, \n",
        "            [\n",
        "                x.shape[0],\n",
        "                x.shape[1],\n",
        "                self.config['n_heads'],\n",
        "                x.shape[2] // self.config['n_heads']\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def __call__(self, x, mask, training=False):\n",
        "        \"\"\"\n",
        "        x: tensor of shape (batch, seq, n_hidden)\n",
        "        mask: tensor of shape (batch, seq)\n",
        "        \"\"\"\n",
        "        scope = Scope(self.config['pretrained'], f'encoder/layer_{self.n}/attention/')\n",
        "        \n",
        "        # Project to queries, keys, and values\n",
        "        # Shapes are all [batch, sequence_length, hidden_size]\n",
        "        queries = hk.Linear(\n",
        "            output_size=self.config['hidden_size'],\n",
        "            w_init=hk.initializers.Constant(scope['query/kernel']),\n",
        "            b_init=hk.initializers.Constant(scope['query/bias'])\n",
        "        )(x)\n",
        "        keys = hk.Linear(\n",
        "            output_size=self.config['hidden_size'],\n",
        "            w_init=hk.initializers.Constant(scope['key/kernel']),\n",
        "            b_init=hk.initializers.Constant(scope['key/bias'])\n",
        "        )(x)\n",
        "        values = hk.Linear(\n",
        "            output_size=self.config['hidden_size'],\n",
        "            w_init=hk.initializers.Constant(scope['value/kernel']),\n",
        "            b_init=hk.initializers.Constant(scope['value/bias'])\n",
        "        )(x)\n",
        "        \n",
        "        # Reshape our hidden state to group into heads\n",
        "        # New shape are [batch, sequence_length, n_heads, size_per_head]\n",
        "        queries = self._split_into_heads(queries)\n",
        "        keys = self._split_into_heads(keys)\n",
        "        values = self._split_into_heads(values)\n",
        "        \n",
        "\n",
        "        # Compute per head attention weights \n",
        "        # b: batch\n",
        "        # s: source sequence\n",
        "        # t: target sequence\n",
        "        # n: number of heads\n",
        "        # h: per-head hidden state\n",
        "        \n",
        "        # Note -- we could also write this with jnp.reshape and jnp.matmul, but I'm becoming\n",
        "        # a fan of how concise opting to use einsum notation for this kind of operation is.\n",
        "        # For more info, see https://rockt.github.io/2018/04/30/einsum and \n",
        "        # https://obilaniu6266h16.wordpress.com/2016/02/04/einstein-summation-in-numpy/\n",
        "        attention_logits = jnp.einsum('bsnh,btnh->bnst', queries, keys) / np.sqrt(queries.shape[-1])\n",
        "        # Add logits of mask tokens with a large negative number to prevent attending to those terms.\n",
        "        attention_logits += jnp.reshape(mask * -(2**12), [mask.shape[0], 1, 1, mask.shape[1]])\n",
        "        attention_weights = jax.nn.softmax(attention_logits, axis=-1)\n",
        "        per_head_attention_output = jnp.einsum('btnh,bnst->bsnh', values, attention_weights)\n",
        "        attention_output = jnp.reshape(\n",
        "            per_head_attention_output, \n",
        "            [\n",
        "                per_head_attention_output.shape[0],\n",
        "                per_head_attention_output.shape[1],\n",
        "                per_head_attention_output.shape[2] * per_head_attention_output.shape[3]\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Apply dense layer to output of attention operation\n",
        "        attention_output = hk.Linear(\n",
        "            output_size=self.config['hidden_size'],\n",
        "            w_init=hk.initializers.Constant(scope['output/dense/kernel']),\n",
        "            b_init=hk.initializers.Constant(scope['output/dense/bias'])\n",
        "        )(attention_output)\n",
        "\n",
        "        # Apply dropout at training time\n",
        "        if training:\n",
        "            attention_output = hk.dropout(\n",
        "                rng=hk.next_rng_key(),\n",
        "                rate=self.config['attention_drop_rate'],\n",
        "                x=attention_output\n",
        "            )\n",
        "\n",
        "        return attention_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldz2kmfp8sx7"
      },
      "source": [
        "\n",
        "We project our hidden state out to key, query, and value tensors of the same dimensions as the input hidden state. We then reshape the last dimension of our matrix to group neighboring activations into N heads. We dot our queries and keys to produce a measure of agreement that we'll use as an attention logit, divide by the square root of our head size as a way to prevent the attention distribution from being too sharp, and then apply our softmax to produce our attention weights.  Our then use our attention weights in conjunction with our values to produce our new hidden state, and reshape our matrices to re-combine the heads.  Finally, we apply a linear projection to our attention outputs and optionally apply dropout at training time.\n",
        "\n",
        "We won't spent too much time on the details here, as the intent of this blog post is to highlight using JAX and Haiku rather than devote too much time to an explanation of self-attention.\n",
        "\n",
        "If you'd like a more indepth refresher on the self-attention operation, I'd recommend:\n",
        "\n",
        "- [Alex Rush's Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html#attention)\n",
        "- [Jay Alammar's Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBXoQyZe_r-d"
      },
      "source": [
        "![alt text](https://i.imgur.com/4hDiOaa.pngps://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAHS3EpcaHQ1"
      },
      "source": [
        "\n",
        "def gelu(x):\n",
        "    \"\"\"\n",
        "    We use this in place of jax.nn.relu because the approximation used \n",
        "    produces a non-trivial difference in the output state\n",
        "    \"\"\"\n",
        "    return x * 0.5 * (1.0 + jax.scipy.special.erf(x / jnp.sqrt(2.0)))\n",
        "\n",
        "\n",
        "class TransformerMLP(hk.Module):\n",
        "\n",
        "    def __init__(self, config, layer_num):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.n = layer_num\n",
        "\n",
        "    def __call__(self, x, training=False):\n",
        "        # Project out to higher dim\n",
        "        scope = Scope(self.config['pretrained'], f'encoder/layer_{self.n}/')\n",
        "        intermediate_output = hk.Linear(\n",
        "            output_size=self.config['intermediate_size'],\n",
        "            w_init=hk.initializers.Constant(scope['intermediate/dense/kernel']),\n",
        "            b_init=hk.initializers.Constant(scope['intermediate/dense/bias'])\n",
        "        )(x)\n",
        "\n",
        "        # Apply gelu nonlinearity\n",
        "        intermediate_output = gelu(intermediate_output)\n",
        "\n",
        "        # Project back down to hidden size\n",
        "        output = hk.Linear(\n",
        "            output_size=self.config['hidden_size'],\n",
        "            w_init=hk.initializers.Constant(scope['output/dense/kernel']),\n",
        "            b_init=hk.initializers.Constant(scope['output/dense/bias']),\n",
        "        )(intermediate_output)\n",
        "\n",
        "        # Apply dropout at training time\n",
        "        if training:\n",
        "            output = hk.dropout(\n",
        "                rng=hk.next_rng_key(), \n",
        "                rate=self.config['fully_connected_drop_rate'],\n",
        "                x=output\n",
        "            )\n",
        "\n",
        "        return output\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-8HJFjN8syA"
      },
      "source": [
        "The final component of our pre-trained RoBERTa model is the Transformer MLP block.  The linear MLP block contains a linear up-projection from our hidden size to a larger intermediate hidden representation, the application of a single gaussian error linear unit (GELU), and a linear projection back down to our hidden size. As per usual, we optionally apply dropout at training time. \n",
        "\n",
        "In the code block below, we wrap up all our previous work, embedding our input token IDs with our `Embedding` module and applying 12 layers of our `TransformerBlock`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83ikp-ZeAF6h"
      },
      "source": [
        "import haiku as hk\n",
        "\n",
        "class RobertaFeaturizer(hk.Module):\n",
        "    def __init__(self, config, *args, **kwargs):\n",
        "        super().__init__(name=\"Transformer\")\n",
        "        self.config = config\n",
        "    \n",
        "    def __call__(self, token_ids, training=False):\n",
        "        x = Embedding(self.config)(token_ids, training=training)\n",
        "        mask = (token_ids == self.config['mask_id']).astype(jnp.float32)\n",
        "        for layer_num, layer in enumerate(range(config['n_layers'])):\n",
        "            x = TransformerBlock(config, layer_num=layer_num)(x, mask, training=training)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCSgLNxR8syD"
      },
      "source": [
        "With that final `hk.Module` complete, we'll populate the config object we've been referencing through our `hk.Module`'s and apply `hk.transform` to produce a pure function. Even without attaching a classification head to the pre-trained base, we already have features we could use for purposes of computing textual similarities or similar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRwclaIt-t6K",
        "outputId": "7abe99d5-fde8-4cfb-cb72-c7fb28ce4c70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from jax import jit\n",
        "from jax.random import PRNGKey\n",
        "\n",
        "config = {\n",
        "    'pretrained': pretrained,\n",
        "    'max_length': 512,\n",
        "    'embed_dropout_rate': 0.1,\n",
        "    'fully_connected_drop_rate': 0.1,\n",
        "    'attention_drop_rate': 0.1,\n",
        "    'hidden_size': 768,\n",
        "    'intermediate_size': 3072,\n",
        "    'n_heads': 12,\n",
        "    'n_layers': 12,\n",
        "    'mask_id': 1,\n",
        "    'weight_stddev': 0.02,\n",
        "\n",
        "    # For use later in finetuning\n",
        "    'n_classes': 2,\n",
        "    'classifier_drop_rate': 0.1,\n",
        "    'learning_rate': 1e-5,\n",
        "    'max_grad_norm': 1.0,\n",
        "    'l2': 0.1,\n",
        "    'n_epochs': 5,\n",
        "    'batch_size': 4\n",
        "}\n",
        "\n",
        "def featurizer_fn(tokens, training=False):\n",
        "    contextual_embeddings = RobertaFeaturizer(config)(tokens, training=training)\n",
        "    return contextual_embeddings\n",
        "\n",
        "rng = PRNGKey(42)\n",
        "roberta = hk.transform(featurizer_fn, apply_rng=True)\n",
        "sample_tokens = np.asarray(sample_tokens)\n",
        "params = roberta.init(rng, sample_tokens, training=False)\n",
        "contextual_embedding = jit(roberta.apply)(params, rng, sample_tokens)\n",
        "print(contextual_embedding.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 512, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAPxOHn88XXz"
      },
      "source": [
        "Let's check to make sure our implementation matches up with a known functional implementation -- we'll opt to use the hugging face model we instantiated earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8qbpwGzEPA1"
      },
      "source": [
        "import torch\n",
        "batch_token_ids = torch.tensor(huggingface_tokenizer.encode(sample_text)).unsqueeze(0)\n",
        "huggingface_output_state, huggingface_pooled_state, _ = huggingface_roberta.forward(batch_token_ids).values()\n",
        "print(np.allclose(\n",
        "    huggingface_output_state.detach().numpy(), \n",
        "    contextual_embedding[:1, :batch_token_ids.size()[1]], \n",
        "    atol=1e-3\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIAdWiaJ8qBg"
      },
      "source": [
        "Great!  The contextual embeddings line up, so our implementation is correct. \n",
        "\n",
        "Admittedly, the first time I ran this things didn't go quite so smoothly -- I missed the subtle difference in the two `gelu` implementations and the difference in outputs was enough to make this check fail.  We can't directly inspect the intermediate outputs of our functions if we have things wrapped in a `jit` call like our example above, but if you remove the `jit` call to `roberta.apply`, it's trivial to add print statements to our implementation to track activations at intermediate points in our network and compare to the Hugging Face implementation.  This is a common gotcha if you're new to JAX, and I recommend reading [JAX core developer Matthew Johnson's response to a github issue](https://github.com/google/jax/issues/196#issuecomment-451671635) on the topic of printing within `jit` if you're curious why this limitation exists.\n",
        "\n",
        "Now that our featurizer is implemented, let's wrap this up to use for downstream classification tasks! \n",
        "This is as easy as slicing off the hidden state of the first token and applying a linear projection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx2vIBdvCsNQ"
      },
      "source": [
        "class RobertaClassifier(hk.Module):\n",
        "\n",
        "    def __init__(self, config, *args, **kwargs):\n",
        "        super().__init__(name=\"Transformer\")\n",
        "        self.config = config\n",
        "    \n",
        "    def __call__(self, token_ids, training=False):\n",
        "        sequence_features = RobertaFeaturizer(self.config)(token_ids=token_ids, training=training)\n",
        "        \n",
        "        # Our classifier representation is just the output state of our first token\n",
        "        clf_state = sequence_features[:,0,:]\n",
        "        \n",
        "        if training:\n",
        "            clf_state = hk.dropout(\n",
        "                rng=hk.next_rng_key(),\n",
        "                rate=self.config['classifier_drop_rate'],\n",
        "                x=clf_state\n",
        "            )\n",
        "        \n",
        "        # We project down from our hidden dimension to n_classes and use this as our softmax logits\n",
        "        clf_logits = hk.Linear(\n",
        "            output_size=self.config['n_classes'],\n",
        "            w_init=hk.initializers.TruncatedNormal(self.config['weight_stddev'])\n",
        "        )(clf_state)\n",
        "        \n",
        "        return clf_logits\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT8njBXlBZJ1"
      },
      "source": [
        "Let's plug in a real dataset to try it out.  As much as I dislike the trope of testing text classifiers on sentiment analysis, we'll be using the IMDB Sentiment dataset from tensorflow datasets because it's already packaged up neatly for us. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS-SWhz8CnpI",
        "outputId": "06e08f8d-e2f4-4f8c-f79a-ad7a5a847268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710,
          "referenced_widgets": [
            "68c661c0aa74432db9f9950c4e96a188",
            "413cd59b06ed4776b46cda8d15297ce6",
            "ff16acffb25548308a001ff47cdd43fa",
            "dd68d19b60b944f28ec7513ded1050a3",
            "de047ff4b8414748b26b9f97cf1bc3a5",
            "66d45b9b5aa042fbbf6acff669cdddfc",
            "df009307e465461cb388a14f2d46968c",
            "f059cdf7ab3a4354b732cc4e15b7f6b6",
            "27f1eae9cfaa4d73963170258e8cf502",
            "784dc7b03ebf4fb0a85debbdafe2070a",
            "78120a791345438db745360a8bccb5c9",
            "8c7ea9977c3e4333a5d02732d5eca180",
            "7ee3562111574b8a991711528f3f4d74",
            "afeb1194499f4bb1967c3b07f7e4a2cb",
            "9968e77b12a5446583179555e3cc7880",
            "afa0325a4291459696acc5d457b10c76",
            "4335c5e0e1014baea78d21b8645e55de",
            "75950b02023a45a6b27172065d2b2427",
            "f3db87e31d8040c99cbd546a0edad3cb",
            "710a733a5bcc468e99c9d9adc42ef48c",
            "8666e2d0dd0c46509745cedbe29a4f68",
            "bb3da8d354924c6185281e6da2530909",
            "1df968b1e69248e0b4cc06dccd2392fb",
            "678f2e5530ce4d67aae1079ddc34d68c",
            "2c4fba3c50554d5fa35770511d9a6f3c",
            "2fb3067413da4168b39849ff5b755607",
            "abfa791108e048b189a9d65f1e9da3e7",
            "75b60f5bfe07450ea829a0395d2008a8",
            "099776337fec4a17936681b269df1015",
            "df54ac1712a44692939f54b8eb6e472f",
            "d0dd33e6ac88439488b1d06f260a6515",
            "4687af00fdd44471be0906d6457c9b46",
            "e26eec18ab31477891372cdd881bb7ad",
            "d1393077b835410b9120357a9ef5cf7e",
            "fa11460eabf94d08b99512f11a1351e1",
            "787d01a3d4074c8a96602245b3a4d497",
            "3fb7bb25cc2f4c088d0a7b15e3cac638",
            "ddc9c0cea36a4ddabb48de27800db7f3",
            "305049b8c6e046e0b6e40532a9cd153d",
            "90bed13077dc4739bf1d18454b0c6622",
            "e89ae8ef1df748d4b85265027d32f4dc",
            "d854088023fe40cda2371852b45297e4",
            "47ab33cde0d948acac6ae51889cbab83",
            "2a46d2bc0ad64b6b9102694d5b5e3203",
            "5f6a8e0b560b471294e8b96ca7e84871",
            "c824da61f14c47489216b626d343afc7",
            "46eb7057a35944359eaac3386e59f274",
            "648b289669f243d38ed8cb5e176010f0",
            "5ae2fad50c83418c942dae02e165065f",
            "e62b459bf7064e17877879e13c8ca8c1",
            "03d959e99a3c4425976cbe6fe892aec1",
            "a418689b5adc4ebea97109a9a6204ebc",
            "7958e00c4f3e4d10983d0bde6bf74fe4",
            "1ebe3fd04df849f7ad4e113dad6fb731",
            "ef8fcaebfdc34a2ea03fee4d6026ace5",
            "d3680e41efb9402a963ffa706781d96e",
            "29263eef88ef4029899920d0b65ac27d",
            "65149805503f4bef9f9c9372c0827e9a",
            "1faf079a12e14fed83d2e87567bc78b1",
            "58955bf8c0054c0799f2a8ec63c541e3",
            "1ce2d4157bed465b9e87325e4d12c106",
            "10a2e4288d464b3eb347a65a3ad415bd",
            "80f13789d62c4838a12e18500942cbed",
            "9e4e48c2f1a74a99be7de00ec543d5a0",
            "690136ebeb024dd290ef44f698e62125",
            "c557e793469044f3932c9a122d98b756",
            "711147881323494f8deff88612a69a33",
            "2bfbbb13bf0945fbb76b71c737ffeb17",
            "e2ac65326294431ea91d102ac78b7e6f",
            "43dd414432254eb8a0845688d45dc65f",
            "52b9a2686c6141b9adaa83214ec4b169",
            "930cc907ff4342f48f731fb9d0e2b025",
            "12b212a501764a75a20226833f369341",
            "8131f72c70b24a928303dc6aca468acf",
            "4aa6b2d17a5a4d2fb98730a41d05eec0",
            "221092575ae4488ea581f96952970337",
            "f3937b392e0e45b0946d6b6380b5d28f",
            "b06dcca0f8334696a6012c2f184458d7",
            "23975f1c2a8d446584f1d73482b74aae",
            "2994ff6f82a74172b28e6f213fac574e",
            "dbae898880e040758a0b41b99ba6fcb8",
            "107b4ae2149041d08cea05d329ce358e",
            "5c6b32cfe3d84754bed086ef295d7d84",
            "7f996d7f39134c1095afe3377a1c59ca",
            "484fdf48921c4f5492f470d0a3d43002",
            "716e5bcb717342528ac5c4f900b442dd",
            "4c95f7a53ea04386bc7ec7f9ce59417a",
            "d68ec2b9959e4299be9f79eefa0e535e"
          ]
        }
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "def load_dataset(split, training, batch_size, n_epochs=1, n_examples=None):\n",
        "    \"\"\"Loads the dataset as a generator of batches.\"\"\"\n",
        "    ds = tfds.load(\"imdb_reviews\", split=f\"{split}[:{n_examples}]\").cache().repeat(n_epochs)\n",
        "    if training:\n",
        "        ds = ds.shuffle(10 * batch_size, seed=0)\n",
        "    ds = ds.batch(batch_size)\n",
        "    return tfds.as_numpy(ds)\n",
        "\n",
        "n_examples = 25000\n",
        "train = load_dataset(\"train\", training=True, batch_size=4, n_epochs=config['n_epochs'], n_examples=n_examples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Load dataset info from /tmp/tmpb5otv2b5tfds\n",
            "INFO:absl:Field info.config_name from disk and from code do not match. Keeping the one from code.\n",
            "INFO:absl:Field info.config_description from disk and from code do not match. Keeping the one from code.\n",
            "INFO:absl:Field info.citation from disk and from code do not match. Keeping the one from code.\n",
            "INFO:absl:Generating dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68c661c0aa74432db9f9950c4e96a188",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c7ea9977c3e4333a5d02732d5eca180",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Downloading http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz into /root/tensorflow_datasets/downloads/ai.stanfor.edu_amaas_sentime_aclImdb_v1PaujRp-TxjBWz59jHXsMDm5WiexbxzaFQkEnXc3Tvo8.tar.gz.tmp.0c3f5f4e21564d7399d90d40b35a6bb7...\n",
            "INFO:absl:Generating split train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1df968b1e69248e0b4cc06dccd2392fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteJFD46U/imdb_reviews-train.tfrecord\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1393077b835410b9120357a9ef5cf7e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/25000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Done writing /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteJFD46U/imdb_reviews-train.tfrecord. Shard lengths: [25000]\n",
            "INFO:absl:Generating split test\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f6a8e0b560b471294e8b96ca7e84871",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteJFD46U/imdb_reviews-test.tfrecord\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3680e41efb9402a963ffa706781d96e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/25000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Done writing /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteJFD46U/imdb_reviews-test.tfrecord. Shard lengths: [25000]\n",
            "INFO:absl:Generating split unsupervised\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "711147881323494f8deff88612a69a33",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteJFD46U/imdb_reviews-unsupervised.tfrecord\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b06dcca0f8334696a6012c2f184458d7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/50000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Done writing /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteJFD46U/imdb_reviews-unsupervised.tfrecord. Shard lengths: [50000]\n",
            "INFO:absl:Skipping computing stats for mode ComputeStatsMode.SKIP.\n",
            "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:25000], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fSjd-MZCwVz"
      },
      "source": [
        "We'll add in an `encode_batch` utility to make calling the huggingface tokenizer more concise, transformer our new `RobertaClassifier` module into a pure function, and initialize our model state."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install optax"
      ],
      "metadata": {
        "id": "nKUae8ZCnuON",
        "outputId": "2c86f412-bfbd-44f6-9409-3285b3328ded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optax\n",
            "  Downloading optax-0.1.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=3.10.0 in /usr/local/lib/python3.7/dist-packages (from optax) (3.10.0.2)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.1.75+cuda11.cudnn82)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from optax) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax) (0.12.0)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.2.26)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->optax) (1.15.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.11.2)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.6)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax) (2.0)\n",
            "Installing collected packages: chex, optax\n",
            "Successfully installed chex-0.1.0 optax-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4MMySIgC6rh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d69d2881-699f-4f94-810d-7c1e50692341"
      },
      "source": [
        "#from jax.experimental import optix\n",
        "import optax\n",
        "\n",
        "def roberta_classification_fn(batch_token_ids, training):\n",
        "    model = RobertaClassifier(config)(\n",
        "        jnp.asarray(batch_token_ids), \n",
        "        training=training\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def encode_batch(batch_text):\n",
        "    # Accept either utf-8 encoded bytes or unicode\n",
        "    batch_text = [\n",
        "        text.decode('utf-8') if isinstance(text, bytes) else text \n",
        "        for text in batch_text\n",
        "    ]\n",
        "    \n",
        "    # Use huggingface's tokenizer to convert from raw text to integer token ids\n",
        "    token_ids = huggingface_tokenizer.batch_encode_plus(\n",
        "        batch_text, \n",
        "        pad_to_max_length=True, \n",
        "        max_length=config['max_length'],\n",
        "    )['input_ids']\n",
        "    return np.asarray(token_ids)\n",
        "\n",
        "\n",
        "# Purify our RobertaClassifier through the use of hk.transform and initialize our classifier\n",
        "rng = jax.random.PRNGKey(42)\n",
        "roberta_classifier = hk.transform(roberta_classification_fn, apply_rng=True)\n",
        "params = roberta_classifier.init(\n",
        "    rng, \n",
        "    batch_token_ids=encode_batch(['Sample text', 'Sample text']), \n",
        "    training=True\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13FkGz158syX"
      },
      "source": [
        "Next we jit compile some functions that use our roberta classifier for computing the loss, measuring model accuracy, and computing gradient updates.\n",
        "Because passed `apply_rng=True` to the call to `hk.transform`, the first arguments to `roberta_classifier.apply` are `params` and `rng`.  After the positional haiku arguments we supply the rest of the arguments our transformed roberta_classifier function expects.\n",
        "\n",
        "Note that our `update` function calls our `loss` function -- so although we didn't decorate our `loss` function with `@jax.jit` directly we'll still reap the benefits when we call `update`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0OrGss88syY"
      },
      "source": [
        "def loss(params, rng, batch_token_ids, batch_labels):\n",
        "    logits = roberta_classifier.apply(params, rng, batch_token_ids, training=True)\n",
        "    labels = hk.one_hot(batch_labels, config['n_classes'])\n",
        "    softmax_xent = -jnp.sum(labels * jax.nn.log_softmax(logits))\n",
        "    softmax_xent /= labels.shape[0]\n",
        "    return softmax_xent\n",
        "\n",
        "@jax.jit\n",
        "def accuracy(params, rng, batch_token_ids, batch_labels):\n",
        "    predictions = roberta_classifier.apply(params, rng, batch_token_ids, training=False)\n",
        "    return jnp.mean(jnp.argmax(predictions, axis=-1) == batch_labels)\n",
        "\n",
        "@jax.jit\n",
        "def update(params, rng, opt_state, batch_token_ids, batch_labels):\n",
        "    batch_loss, grads = jax.value_and_grad(loss)(params, rng, batch_token_ids, batch_labels)\n",
        "    updates, opt_state = opt.update(grads, opt_state)\n",
        "    new_params = optax.apply_updates(params, updates)\n",
        "    return new_params, opt_state, batch_loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9RzrI8e8syc"
      },
      "source": [
        "Finetuning transformers for downstream tasks requires a few tricks for reliable performance -- we'll use a linear warmup + decay along with gradient clipping for our optimizers. JAX exposes 2 different sets of optimization utilities in `jax.experimental.optimizers` and `jax.experimental.optix` respectively. For finetuning RoBERTa we'll be using the latter, as it includes learning rate schedule utilities through `optix.scale_by_schedule` as well as a utility for gradient clipping with `optix.clip_by_global_norm`. We can apply our bag of optimization tricks in combination with a vanilla adam optimizer using `optix.chain` as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-uWRAsMIS4L"
      },
      "source": [
        "def make_lr_schedule(warmup_percentage, total_steps):\n",
        "    def lr_schedule(step):\n",
        "        percent_complete = step / total_steps\n",
        "        before_peak = jax.lax.convert_element_type(\n",
        "            (percent_complete <= warmup_percentage),\n",
        "            np.float32\n",
        "        )\n",
        "        scale = (\n",
        "            (before_peak * (percent_complete / warmup_percentage) + (1 - before_peak))\n",
        "            * (1 - percent_complete)\n",
        "        )\n",
        "        return scale\n",
        "    return lr_schedule\n",
        "\n",
        "\n",
        "total_steps = config['n_epochs'] * (n_examples // config['batch_size'])\n",
        "lr_schedule = make_lr_schedule(warmup_percentage=0.1, total_steps=total_steps)\n",
        "opt = optax.chain(\n",
        "    optax.clip_by_global_norm(config['max_grad_norm']),\n",
        "    optax.adam(learning_rate=config['learning_rate']),\n",
        "    optax.scale_by_schedule(lr_schedule)\n",
        ")\n",
        "opt_state = opt.init(params)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRcUMlnr8syf"
      },
      "source": [
        "Below, we throw together one final utility before writing our training loop -- a short convenience function to print how our train and test accuracy change over time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rglzrhxC8syg"
      },
      "source": [
        "@jax.jit\n",
        "def measure_current_performance(params, n_examples=None, splits=('train', 'test')):\n",
        "    # Load our training evaluation and test evaluation splits \n",
        "    if 'train' in splits:\n",
        "        train_eval = load_dataset(\"train\", training=False, batch_size=25, n_examples=n_examples)\n",
        "        # Compute mean train accuracy\n",
        "        train_accuracy = np.mean([\n",
        "            accuracy(\n",
        "                params, \n",
        "                rng, \n",
        "                encode_batch(train_eval_batch['text']), \n",
        "                train_eval_batch['label']\n",
        "            )\n",
        "            for train_eval_batch in train_eval\n",
        "        ])\n",
        "        print(f\"\\t Train acc: {train_accuracy:.3f}\")\n",
        "    \n",
        "    if 'test' in splits:\n",
        "        test_eval = load_dataset(\"test\", training=False, batch_size=25, n_examples=n_examples)\n",
        "        # Compute mean test accuracy\n",
        "        test_accuracy = np.mean([\n",
        "            accuracy(\n",
        "                params, \n",
        "                rng,\n",
        "                encode_batch(test_eval_batch['text']), \n",
        "                test_eval_batch['label'],\n",
        "            )\n",
        "            for test_eval_batch in test_eval\n",
        "        ])\n",
        "        print(f\"\\t Test accuracy: {test_accuracy:.3f}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFqwpsBB8syj"
      },
      "source": [
        "In our training loop, we simply pull batches of examples from our training data iterator and call the update function to modify the state of our parameters.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8QKBe7J8syj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0ac9d4e-5c92-40d1-a5b3-be3f0e882f1c"
      },
      "source": [
        "for step, train_batch in enumerate(train):\n",
        "    if (step+1) % 100 == 0:\n",
        "        print(f\"[Step {step}]\")\n",
        "    if (step+1) % 100 == 0 and step != 0:\n",
        "        measure_current_performance(params, n_examples=100)\n",
        "\n",
        "    # Perform adam update\n",
        "    next_batch = train_batch #next(train)\n",
        "    batch_token_ids = encode_batch(next_batch['text'])\n",
        "    batch_labels = next_batch['label']\n",
        "    params, opt_state, batch_loss = update(\n",
        "        params, rng, opt_state, batch_token_ids, batch_labels\n",
        "    )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 99]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.510\n",
            "\t Test accuracy: 0.440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.510\n",
            "\t Test accuracy: 0.440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.510\n",
            "\t Test accuracy: 0.440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.520\n",
            "\t Test accuracy: 0.480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.910\n",
            "\t Test accuracy: 0.840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.910\n",
            "\t Test accuracy: 0.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.890\n",
            "\t Test accuracy: 0.820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.890\n",
            "\t Test accuracy: 0.830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 1099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.920\n",
            "\t Test accuracy: 0.830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 1199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.940\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 1299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.920\n",
            "\t Test accuracy: 0.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 1399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.910\n",
            "\t Test accuracy: 0.840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 1499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.920\n",
            "\t Test accuracy: 0.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 1599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 1699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 1799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 1899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 1999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 2099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.940\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 2199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 2299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.920\n",
            "\t Test accuracy: 0.880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 2399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 2499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 2599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 2699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 2799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 2899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.940\n",
            "\t Test accuracy: 0.880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 3099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 3199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 3299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 3399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 3499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 3599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.920\n",
            "\t Test accuracy: 0.880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 3699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 3799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.940\n",
            "\t Test accuracy: 0.880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 3899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.920\n",
            "\t Test accuracy: 0.880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 3999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.910\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 4099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.920\n",
            "\t Test accuracy: 0.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 4199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.940\n",
            "\t Test accuracy: 0.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 4299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.960\n",
            "\t Test accuracy: 0.830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 4399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.960\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 4499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 4599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.960\n",
            "\t Test accuracy: 0.880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 4699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 4799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.940\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 4899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 4999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 5099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 5199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.930\n",
            "\t Test accuracy: 0.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 5299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.960\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 5399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 5499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.960\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 5599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.940\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 5699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.940\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 5799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 5899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 5999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.960\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 6099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 6199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.960\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 6299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 6399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 6499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 6599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 6699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 6799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 6899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 6999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 7099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 7199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 7299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 7399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 7499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 7599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 7699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.960\n",
            "\t Test accuracy: 0.880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 7799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 7899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.970\n",
            "\t Test accuracy: 0.880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 7999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 8099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.970\n",
            "\t Test accuracy: 0.870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 8199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.960\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 8299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 8399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 8499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 8599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.970\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 8699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 8799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 8899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.970\n",
            "\t Test accuracy: 0.870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 8999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 9099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 9199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 9299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.960\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 9399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 9499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 9599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 9699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 9799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.970\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 9899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 9999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.970\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 10099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.970\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 10199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 10299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.950\n",
            "\t Test accuracy: 0.930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 10399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 10499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 10599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.960\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 10699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 10799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 10899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 10999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 11099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 11199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 11299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 11399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 11499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 11599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 11699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 11799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.970\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 11899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 11999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.970\n",
            "\t Test accuracy: 0.930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 12099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.970\n",
            "\t Test accuracy: 0.940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 12199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 12299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 12399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 12499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 12599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 12699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 12799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 12899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.980\n",
            "\t Test accuracy: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 12999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 13099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 13199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 13299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 13399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 13499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 1.000\n",
            "\t Test accuracy: 0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 13599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test[:100], from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Train acc: 0.990\n",
            "\t Test accuracy: 0.900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdKkud6u8syn"
      },
      "source": [
        "When all is said and done, we achieve a respectable test accuracy of 0.xx on the IMDB review dataset. Not too shabby!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLHm04RcIyIB"
      },
      "source": [
        "measure_current_performance(params, n_examples=25000, splits='test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY9PEiep8syq"
      },
      "source": [
        ""
      ]
    }
  ]
}