{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_github = user_secrets.get_secret(\"github\")\n! rm -rf feedback2021\n! git clone https://{secret_github}@github.com/VilmosProkaj/feedback2021.git\n! pip install feedback2021/","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:37:46.046086Z","iopub.execute_input":"2022-03-02T07:37:46.049864Z","iopub.status.idle":"2022-03-02T07:38:22.630261Z","shell.execute_reply.started":"2022-03-02T07:37:46.049806Z","shell.execute_reply":"2022-03-02T07:38:22.628910Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCloning into 'feedback2021'...\nremote: Enumerating objects: 221, done.\u001b[K\nremote: Counting objects: 100% (221/221), done.\u001b[K\nremote: Compressing objects: 100% (130/130), done.\u001b[K\nremote: Total 221 (delta 108), reused 167 (delta 54), pack-reused 0\u001b[K\nReceiving objects: 100% (221/221), 59.72 KiB | 2.60 MiB/s, done.\nResolving deltas: 100% (108/108), done.\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nProcessing ./feedback2021\n\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from feedback2021==0.0.post1.dev31+g4acb08f) (3.4.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->feedback2021==0.0.post1.dev31+g4acb08f) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->feedback2021==0.0.post1.dev31+g4acb08f) (3.5.0)\nBuilding wheels for collected packages: feedback2021\n  Building wheel for feedback2021 (PEP 517) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for feedback2021: filename=feedback2021-0.0.post1.dev31+g4acb08f-py3-none-any.whl size=23539 sha256=7a9594e809f5dead07e3c3bf79ed350dc65a4cb4e1f95574975513aeb2f1379f\n  Stored in directory: /tmp/pip-ephem-wheel-cache-se2qy9m0/wheels/58/ad/18/0ce3edd06dac18258cb4965c488a42e46fa829de9c6aa2319e\nSuccessfully built feedback2021\nInstalling collected packages: feedback2021\n  Attempting uninstall: feedback2021\n    Found existing installation: feedback2021 0.0.post1.dev31+g4acb08f\n    Uninstalling feedback2021-0.0.post1.dev31+g4acb08f:\n      Successfully uninstalled feedback2021-0.0.post1.dev31+g4acb08f\nSuccessfully installed feedback2021-0.0.post1.dev31+g4acb08f\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install -U jax jaxlib dm_haiku optax\n#!pip install --upgrade pip\n# Installs the wheel compatible with CUDA 11 and cuDNN 8.2 or newer.\n# ! pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html  # Note: wheels only available on linux.\n## !pip install --upgrade jax jaxlib==0.3.0+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n#! pip install dm_haiku","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:22.633277Z","iopub.execute_input":"2022-03-02T07:38:22.633753Z","iopub.status.idle":"2022-03-02T07:38:34.738333Z","shell.execute_reply.started":"2022-03-02T07:38:22.633706Z","shell.execute_reply":"2022-03-02T07:38:34.736981Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: jax in /opt/conda/lib/python3.7/site-packages (0.3.1)\nRequirement already satisfied: jaxlib in /opt/conda/lib/python3.7/site-packages (0.3.0)\nRequirement already satisfied: dm_haiku in /opt/conda/lib/python3.7/site-packages (0.0.6)\nRequirement already satisfied: optax in /opt/conda/lib/python3.7/site-packages (0.1.1)\nRequirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from jax) (1.7.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from jax) (4.1.1)\nRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.7/site-packages (from jax) (1.19.5)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from jax) (0.12.0)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.7/site-packages (from jax) (3.3.0)\nRequirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/conda/lib/python3.7/site-packages (from jaxlib) (1.12)\nRequirement already satisfied: jmp>=0.0.2 in /opt/conda/lib/python3.7/site-packages (from dm_haiku) (0.0.2)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from dm_haiku) (0.8.9)\nRequirement already satisfied: chex>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from optax) (0.1.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py->jax) (1.15.0)\nRequirement already satisfied: dm-tree>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from chex>=0.0.4->optax) (0.1.6)\nRequirement already satisfied: toolz>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from chex>=0.0.4->optax) (0.11.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import kaggle_init","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.740398Z","iopub.execute_input":"2022-03-02T07:38:34.741161Z","iopub.status.idle":"2022-03-02T07:38:34.746440Z","shell.execute_reply.started":"2022-03-02T07:38:34.741113Z","shell.execute_reply":"2022-03-02T07:38:34.745189Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"kaggle_init.on_kaggle(), kaggle_init.is_cuda_available(), kaggle_init.is_tpu_available()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.749144Z","iopub.execute_input":"2022-03-02T07:38:34.749984Z","iopub.status.idle":"2022-03-02T07:38:34.764079Z","shell.execute_reply.started":"2022-03-02T07:38:34.749930Z","shell.execute_reply":"2022-03-02T07:38:34.762985Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"(True, False, True)"},"metadata":{}}]},{"cell_type":"code","source":"# %env XLA_PYTHON_CLIENT_MEM_FRACTION=.75\ncompute_on_tpu = True\nif compute_on_tpu:\n    if kaggle_init.is_tpu_available():\n        from feedback2021.jax_tpu_init import jax_tpu_init\n        jax_tpu_init()       \n    else:\n        import os\n        os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=2'\n#import jax\n#jax.devices()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.765512Z","iopub.execute_input":"2022-03-02T07:38:34.765870Z","iopub.status.idle":"2022-03-02T07:38:34.777421Z","shell.execute_reply.started":"2022-03-02T07:38:34.765830Z","shell.execute_reply":"2022-03-02T07:38:34.776223Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"TPU seemed to initialized\nwith\n\t os.environ.pop(\"TPU_INITIALIZED\")\nyou can restart to process\n","output_type":"stream"}]},{"cell_type":"code","source":"# jax_tpu_init??","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.781425Z","iopub.execute_input":"2022-03-02T07:38:34.781825Z","iopub.status.idle":"2022-03-02T07:38:34.791270Z","shell.execute_reply.started":"2022-03-02T07:38:34.781789Z","shell.execute_reply":"2022-03-02T07:38:34.790291Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"LOG_TO_WANDB = False","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.792904Z","iopub.execute_input":"2022-03-02T07:38:34.793660Z","iopub.status.idle":"2022-03-02T07:38:34.801739Z","shell.execute_reply.started":"2022-03-02T07:38:34.793603Z","shell.execute_reply":"2022-03-02T07:38:34.800628Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB:\n    !pip install --upgrade wandb -q # experiment tracking","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.803162Z","iopub.execute_input":"2022-03-02T07:38:34.803850Z","iopub.status.idle":"2022-03-02T07:38:34.813683Z","shell.execute_reply.started":"2022-03-02T07:38:34.803809Z","shell.execute_reply":"2022-03-02T07:38:34.812693Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB:\n    import wandb\n    import os\n    os.environ[\"WANDB_PROJECT\"] = \"kaggle_feedback\"\n    os.environ[\"WANDB_ENTITY\"] = \"prvi\"\n    os.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n    os.environ[\"WANDB_WATCH\"] = \"gradient\"\n\n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        api_key = user_secrets.get_secret(\"wandb\")\n        os.environ[\"WANDB_API_KEY\"] = api_key\n        wandb.login()\n        wandb.init(dir=\"/tmp/\") \n    except:\n        print('If you want to use your W&B account, '\n              'go to Add-ons -> Secrets and provide your W&B access token.\\n'\n              'Use the Label name `wandb`. \\n'\n              'Get your W&B access token from here: https://wandb.ai/authorize')","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.815238Z","iopub.execute_input":"2022-03-02T07:38:34.815912Z","iopub.status.idle":"2022-03-02T07:38:34.825714Z","shell.execute_reply.started":"2022-03-02T07:38:34.815848Z","shell.execute_reply":"2022-03-02T07:38:34.824605Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"from feedback2021.helper import id2label, label2id\n\nfrom feedback2021.prepare_data import (create_train_dataset_pd, \n                                       to_chunk_data, \n                                       chunk_mapping,\n                                       add_input_ids, \n                                       add_labels,\n                                       add_rle_word2,\n                                       has_name,\n                                    )\n\nimport feedback2021.metric as metric\n\nfrom feedback2021.postprocess import (mk_metric, \n                                      mk_prediction_transform, \n                                      mk_binary_metric, \n                                      mk_binary_prediction_transform)\n\nfrom feedback2021.visualize import show_result\n\nimport feedback2021.hk_roberta as hk_roberta","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.832927Z","iopub.execute_input":"2022-03-02T07:38:34.833624Z","iopub.status.idle":"2022-03-02T07:38:34.843423Z","shell.execute_reply.started":"2022-03-02T07:38:34.833579Z","shell.execute_reply":"2022-03-02T07:38:34.842108Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# CONFIG\njust_test = False\nexperiment_id = 1\ntask = \"token_classification\"\nmodel_checkpoint = \"roberta-base\" \n# \"allenai/longformer-base-4096\" \n# \"distilroberta-base\" # \"microsoft/deberta-v3-xsmall\" #\"roberta-base\"\nif just_test:\n    max_length = 128\n    stride = 128\nelse:\n    max_length = 512\n    stride = 128\nmin_tokens = 6\nmodel_path = f'{model_checkpoint.split(\"/\")[-1]}-{experiment_id}'\ndata_from_wandb = False\nsave_to_wandb = False or not data_from_wandb\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-03-02T07:38:34.845363Z","iopub.execute_input":"2022-03-02T07:38:34.845664Z","iopub.status.idle":"2022-03-02T07:38:34.860016Z","shell.execute_reply.started":"2022-03-02T07:38:34.845611Z","shell.execute_reply":"2022-03-02T07:38:34.858845Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.861568Z","iopub.execute_input":"2022-03-02T07:38:34.865104Z","iopub.status.idle":"2022-03-02T07:38:36.469161Z","shell.execute_reply.started":"2022-03-02T07:38:34.865057Z","shell.execute_reply":"2022-03-02T07:38:36.467858Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"#import tensorflow.config\n#tensorflow.config.experimental.set_visible_devices([], \"GPU\")","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:36.470882Z","iopub.execute_input":"2022-03-02T07:38:36.471881Z","iopub.status.idle":"2022-03-02T07:38:36.478432Z","shell.execute_reply.started":"2022-03-02T07:38:36.471836Z","shell.execute_reply":"2022-03-02T07:38:36.477092Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"from feedback2021.clean_train_data import mk_clean_train_data\nif just_test:\n    cleaned_train = mk_clean_train_data(num_records=100) #cleaned_train[:100]\nelse:\n    cleaned_train = mk_clean_train_data()\n\ntext_id2idx = dict(zip(cleaned_train.index, range(len(cleaned_train))))\nidx2text_id = {v:k for k,v in text_id2idx.items()}\ncleaned_train.index = range(len(cleaned_train))\n\ndata = create_train_dataset_pd(cleaned_train_df=cleaned_train, \n                               tokenizer=tokenizer, \n                               verbose=True)\n\nfrom sklearn.model_selection import train_test_split\n\ndata = dict(zip(['train','test'], \n                train_test_split(data,\n                                 test_size=0.1, \n                                 shuffle=True, \n                                 random_state=42)))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:36.480040Z","iopub.execute_input":"2022-03-02T07:38:36.480442Z","iopub.status.idle":"2022-03-02T07:39:53.413057Z","shell.execute_reply.started":"2022-03-02T07:38:36.480402Z","shell.execute_reply":"2022-03-02T07:39:53.411983Z"},"trusted":true},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"reformat train data:   0%|          | 0/144293 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a3310f604ac4bf785506ba5506c19c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"reading essays:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15813a2d50754c2083b67f196ac61001"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"searching for disaligned labels:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4184bbff7fc8417b9551ae9e289fc1b7"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    word mapping:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c70e3364e60e4bf1959e6d0cf803812f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adding token rle:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"047f444609734f07ad55e6faf53ebcd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adding word rle:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9be343664b354925a2a31c9e145fda0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":" adding label:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1dfbeb23211466eb76c72fdf0f497dd"}},"metadata":{}}]},{"cell_type":"code","source":"data['train'].head(), data['test'].head()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:53.414697Z","iopub.execute_input":"2022-03-02T07:39:53.415104Z","iopub.status.idle":"2022-03-02T07:39:54.027430Z","shell.execute_reply.started":"2022-03-02T07:39:53.415062Z","shell.execute_reply":"2022-03-02T07:39:54.026316Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"(                                                    text  \\\n 7969   Driverless cars seem to be evolving from the l...   \n 14635  Today we as humans live in a society that is c...   \n 11747  Distance learning can look like the future of ...   \n 14057  According to Phones and Driving from the follo...   \n 4901   \"The Face on Mars\" Could not be an alien creat...   \n \n                                                 rle_char  \\\n 7969   [(1, 0, 171), (2, 173, 183), (3, 197, 661), (4...   \n 14635  [(1, 0, 314), (2, 316, 452), (4, 555, 689), (3...   \n 11747  [(1, 0, 269), (2, 271, 391), (4, 396, 544), (6...   \n 14057  [(1, 0, 700), (2, 703, 831), (3, 833, 1310), (...   \n 4901   [(1, 1, 153), (4, 156, 259), (3, 262, 662), (2...   \n \n                                                input_ids  \\\n 7969   [46022, 1672, 1677, 2045, 7, 28, 14007, 31, 5,...   \n 14635  [5625, 52, 25, 5868, 697, 11, 10, 2313, 14, 16...   \n 11747  [48625, 2239, 64, 356, 101, 5, 499, 9, 30211, ...   \n 14057  [14693, 7, 4129, 6909, 8, 19181, 31, 5, 511, 1...   \n 4901   [113, 133, 12346, 15, 6507, 113, 9918, 45, 28,...   \n \n                                           offset_mapping  \\\n 7969   [(0, 6), (6, 10), (11, 15), (16, 20), (21, 23)...   \n 14635  [(0, 5), (6, 8), (9, 11), (12, 18), (19, 23), ...   \n 11747  [(0, 8), (9, 17), (18, 21), (22, 26), (27, 31)...   \n 14057  [(0, 9), (10, 12), (13, 15), (15, 19), (20, 23...   \n 4901   [(0, 1), (1, 4), (5, 9), (10, 12), (13, 17), (...   \n \n                                             word_mapping  \\\n 7969   [(0, 10), (11, 15), (16, 20), (21, 23), (24, 2...   \n 14635  [(0, 5), (6, 8), (9, 11), (12, 18), (19, 23), ...   \n 11747  [(0, 8), (9, 17), (18, 21), (22, 26), (27, 31)...   \n 14057  [(0, 9), (10, 12), (13, 19), (20, 23), (24, 31...   \n 4901   [(0, 4), (5, 9), (10, 12), (13, 18), (19, 24),...   \n \n                                                rle_token  \\\n 7969   [(1, 0, 36), (2, 37, 41), (3, 43, 149), (4, 15...   \n 14635  [(1, 0, 60), (2, 61, 88), (4, 111, 137), (3, 1...   \n 11747  [(1, 0, 49), (2, 51, 74), (4, 75, 107), (6, 10...   \n 14057  [(1, 0, 133), (2, 136, 163), (3, 164, 288), (4...   \n 4901   [(1, 1, 36), (4, 39, 61), (3, 62, 153), (2, 15...   \n \n                                                 rle_word  \\\n 7969   [(1, 0, 33), (2, 33, 36), (3, 38, 133), (4, 13...   \n 14635  [(1, 0, 54), (2, 54, 81), (4, 97, 123), (3, 12...   \n 11747  [(1, 0, 46), (2, 46, 68), (4, 69, 98), (6, 98,...   \n 14057  [(1, 0, 118), (2, 118, 142), (3, 142, 209), (4...   \n 4901   [(1, 0, 27), (4, 27, 48), (3, 48, 122), (2, 12...   \n \n                                                   labels  \n 7969   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n 14635  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n 11747  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n 14057  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n 4901   [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ,\n                                                     text  \\\n 10360  FACS (Facial Action Coding System) is it a goo...   \n 10224  Dear Principal,\\n\\nI think that students shoul...   \n 8720   Home schooling, also known as home education, ...   \n 8798   The \"Face\" that was found on Mars is not an al...   \n 12291  Some reasons to join the Cowboys. Joining the ...   \n \n                                                 rle_char  \\\n 10360  [(1, 0, 125), (2, 127, 161), (4, 163, 218), (3...   \n 10224  [(2, 17, 165), (3, 167, 315), (4, 318, 504), (...   \n 8720   [(1, 0, 564), (4, 567, 652), (3, 654, 1149), (...   \n 8798   [(2, 0, 50), (4, 52, 128), (3, 130, 373), (3, ...   \n 12291          [(2, 0, 32), (3, 34, 643), (5, 647, 820)]   \n \n                                                input_ids  \\\n 10360  [597, 2562, 104, 36, 597, 27015, 5828, 230, 19...   \n 10224  [23314, 13619, 6, 50118, 50118, 100, 206, 14, ...   \n 8720   [19457, 30211, 6, 67, 684, 25, 184, 1265, 6, 1...   \n 8798   [133, 22, 34892, 113, 14, 21, 303, 15, 6507, 1...   \n 12291  [6323, 2188, 7, 1962, 5, 6446, 4, 3889, 6074, ...   \n \n                                           offset_mapping  \\\n 10360  [(0, 1), (1, 3), (3, 4), (5, 6), (6, 7), (7, 1...   \n 10224  [(0, 4), (5, 14), (14, 15), (15, 16), (16, 17)...   \n 8720   [(0, 4), (5, 14), (14, 15), (16, 20), (21, 26)...   \n 8798   [(0, 3), (4, 5), (5, 9), (9, 10), (11, 15), (1...   \n 12291  [(0, 4), (5, 12), (13, 15), (16, 20), (21, 24)...   \n \n                                             word_mapping  \\\n 10360  [(0, 4), (5, 12), (13, 19), (20, 26), (27, 34)...   \n 10224  [(0, 4), (5, 15), (17, 18), (19, 24), (25, 29)...   \n 8720   [(0, 4), (5, 15), (16, 20), (21, 26), (27, 29)...   \n 8798   [(0, 3), (4, 10), (11, 15), (16, 19), (20, 25)...   \n 12291  [(0, 4), (5, 12), (13, 15), (16, 20), (21, 24)...   \n \n                                                rle_token  \\\n 10360  [(1, 0, 32), (2, 33, 43), (4, 44, 54), (3, 55,...   \n 10224  [(2, 5, 34), (3, 35, 63), (4, 66, 101), (3, 10...   \n 8720   [(1, 0, 113), (4, 116, 131), (3, 132, 225), (4...   \n 8798   [(2, 0, 13), (4, 14, 30), (3, 31, 83), (3, 86,...   \n 12291            [(2, 0, 6), (3, 7, 153), (5, 156, 200)]   \n \n                                                 rle_word  \\\n 10360  [(1, 0, 25), (2, 25, 33), (4, 33, 42), (3, 42,...   \n 10224  [(2, 2, 30), (3, 30, 57), (4, 57, 91), (3, 91,...   \n 8720   [(1, 0, 93), (4, 93, 108), (3, 108, 196), (4, ...   \n 8798   [(2, 0, 11), (4, 11, 25), (3, 25, 74), (3, 74,...   \n 12291            [(2, 0, 6), (3, 6, 132), (5, 132, 167)]   \n \n                                                   labels  \n 10360  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n 10224  [0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n 8720   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n 8798   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 4, ...  \n 12291  [2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, ...  )"},"metadata":{}}]},{"cell_type":"code","source":"if LOG_TO_WANDB and save_to_wandb:\n    data.remove_columns([#'input_ids', \n                         #'rle_token', \n                         'labels', \n                         #'offset_mapping'\n    ]).save_to_disk('data')\n\n    artifact = wandb.Artifact('data', description='train test split', type='dataset')\n    artifact.add_dir('data')\n    wandb.log_artifact(artifact)\n    !ls -sRh data\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:54.029380Z","iopub.execute_input":"2022-03-02T07:39:54.029701Z","iopub.status.idle":"2022-03-02T07:39:54.039118Z","shell.execute_reply.started":"2022-03-02T07:39:54.029661Z","shell.execute_reply":"2022-03-02T07:39:54.037959Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# if  not isinstance(data.column_names, dict):\n#     data = data.train_test_split(test_size=0.1, shuffle=True, seed=42)\n    \n# chunk_data = to_chunk_data(data, \n#                            chunk_len=max_length, \n#                            stride=stride, \n#                            prefix=[tokenizer.bos_token_id],\n#                            postfix=[tokenizer.eos_token_id])\n# chunk_data","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:54.040586Z","iopub.execute_input":"2022-03-02T07:39:54.041552Z","iopub.status.idle":"2022-03-02T07:39:54.051163Z","shell.execute_reply.started":"2022-03-02T07:39:54.041489Z","shell.execute_reply":"2022-03-02T07:39:54.050131Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"def chop_up(data, tokenizer, max_length, stride):\n    examples = {k: list(data[k]) for k in data.columns}\n    examples['labels'] = list(data['labels'])\n    examples['id'] = list(data.index.values)\n    f = chunk_mapping(chunk_len=max_length, \n                      stride=stride, \n                      prefix=[tokenizer.bos_token_id],\n                      postfix=[tokenizer.eos_token_id])\n    return f(examples)\n\ndef to_records(data):\n    return [dict(zip(data.keys(), rec))  for rec in zip(*data.values())]\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:54.052577Z","iopub.execute_input":"2022-03-02T07:39:54.053525Z","iopub.status.idle":"2022-03-02T07:39:54.063153Z","shell.execute_reply.started":"2022-03-02T07:39:54.053483Z","shell.execute_reply":"2022-03-02T07:39:54.061979Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"chunk_data = {\n    k: chop_up(v, tokenizer, max_length=max_length, stride=stride)\n    for k,v in data.items()\n}","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:54.064704Z","iopub.execute_input":"2022-03-02T07:39:54.065209Z","iopub.status.idle":"2022-03-02T07:39:55.840575Z","shell.execute_reply.started":"2022-03-02T07:39:54.065153Z","shell.execute_reply":"2022-03-02T07:39:55.839448Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"import yaml\nprint(yaml.dump(\n    {\n        k: {\n            k0: f'size={len(v0[0])}, type={type(v0[0][0]).__name__}' \n            if isinstance(v0[0], list) else v0[0] \n            for k0, v0 in v.items()\n        } \n     for k,v in chunk_data.items()\n    }\n))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.843012Z","iopub.execute_input":"2022-03-02T07:39:55.843823Z","iopub.status.idle":"2022-03-02T07:39:55.877482Z","shell.execute_reply.started":"2022-03-02T07:39:55.843778Z","shell.execute_reply":"2022-03-02T07:39:55.876405Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"test:\n  input_ids: size=216, type=int\n  labels: size=216, type=int\n  offset: 0\n  text_id: !!python/object/apply:numpy.core.multiarray.scalar\n  - &id001 !!python/object/apply:numpy.dtype\n    args:\n    - i8\n    - false\n    - true\n    state: !!python/tuple\n    - 3\n    - <\n    - null\n    - null\n    - null\n    - -1\n    - -1\n    - 0\n  - !!binary |\n    eCgAAAAAAAA=\ntrain:\n  input_ids: size=512, type=int\n  labels: size=512, type=int\n  offset: 0\n  text_id: !!python/object/apply:numpy.core.multiarray.scalar\n  - *id001\n  - !!binary |\n    IR8AAAAAAAA=\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.879094Z","iopub.execute_input":"2022-03-02T07:39:55.879660Z","iopub.status.idle":"2022-03-02T07:39:55.902151Z","shell.execute_reply.started":"2022-03-02T07:39:55.879602Z","shell.execute_reply":"2022-03-02T07:39:55.901080Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"# if not has_name(data, 'rle_word'):\n#     from feedback2021.helper import Block\n#     def add_rle_word2(data):\n#         # assert has_name(data, 'offset_mapping'), 'add input_ids first!'\n#         if not has_name(data,'word_mapping'):\n#             data = add_word_mapping(data)\n#         return data.map(lambda x: {'rle_word': [Block(t).inv_map(x['word_mapping']) \n#                                                  for t in x['rle_char']]},\n#                             desc='rle to word coordinates')\n#     data = add_rle_word2(data)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.903714Z","iopub.execute_input":"2022-03-02T07:39:55.904145Z","iopub.status.idle":"2022-03-02T07:39:55.913411Z","shell.execute_reply.started":"2022-03-02T07:39:55.904101Z","shell.execute_reply":"2022-03-02T07:39:55.912450Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# from collections import defaultdict\n# import numpy as np\n# word_counts = defaultdict(list)\n# from  datasets import concatenate_datasets\n# all_data = concatenate_datasets(list(data.values()))\n# for x in all_data['rle_word']:\n#     for cls_id, start, end  in x:\n#         word_counts[id2label[cls_id]].append(end-start)\n\n# for k, v in word_counts.items():\n#     plt.hist(v,bins=np.arange(1,max(v)+1)-0.5)\n#     plt.title(f'{k} min:{min(v)} max: {max(v)}, 2%,5%: {np.percentile(v,[2,5])}')\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.916479Z","iopub.execute_input":"2022-03-02T07:39:55.918295Z","iopub.status.idle":"2022-03-02T07:39:55.924707Z","shell.execute_reply.started":"2022-03-02T07:39:55.918253Z","shell.execute_reply":"2022-03-02T07:39:55.923809Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"## Model and Training","metadata":{}},{"cell_type":"code","source":"# chunk_data = chunk_data.rename_column('labels','label')\n# DataLoader?","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.926033Z","iopub.execute_input":"2022-03-02T07:39:55.926850Z","iopub.status.idle":"2022-03-02T07:39:55.937142Z","shell.execute_reply.started":"2022-03-02T07:39:55.926809Z","shell.execute_reply":"2022-03-02T07:39:55.936155Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# def mk_collate_fn(tokenizer, max_length=512):\n#     def collate_fn(features):\n        \n#         batch ={key: np.array([f[key]+[t]*(max_length-len(f[key])) for f in features], dtype=np.int32)\n#                 for t,key in zip([tokenizer.pad_token_id,-100],['input_ids','labels'])}\n#         return batch\n#     return collate_fn\n# from torch.utils.data import DataLoader\n\n# train_dataset = DataLoader(chunk_data_list, shuffle=True, #.remove_columns(['offset', 'text_id']), \n#                            batch_size=16,\n#                            collate_fn=mk_collate_fn(tokenizer, 512))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.938794Z","iopub.execute_input":"2022-03-02T07:39:55.939108Z","iopub.status.idle":"2022-03-02T07:39:55.951696Z","shell.execute_reply.started":"2022-03-02T07:39:55.939070Z","shell.execute_reply":"2022-03-02T07:39:55.950633Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"%%time\nimport tensorflow.data as tfdata\n#ds=\nimport numpy as np\n\ndef mk_collate_fn(tokenizer, max_length=512):\n    def collate_fn(features):\n        \n        batch = features.copy()\n        for t, key in zip([tokenizer.pad_token_id,-100], ['input_ids','labels']):\n            batch[key] = np.array([f+[t]*(max_length-len(f)) for f in batch[key]], \n                                  dtype=np.int32)\n        return batch\n    \n    return collate_fn\n\n    \ncollate_fn = mk_collate_fn(tokenizer, max_length)\n\nds ={k: tfdata.Dataset.from_tensor_slices(collate_fn(v)) for k,v in chunk_data.items()}\n#(chunk_data_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.953260Z","iopub.execute_input":"2022-03-02T07:39:55.953748Z","iopub.status.idle":"2022-03-02T07:40:15.128698Z","shell.execute_reply.started":"2022-03-02T07:39:55.953705Z","shell.execute_reply":"2022-03-02T07:40:15.127351Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"CPU times: user 30 s, sys: 5.7 s, total: 35.7 s\nWall time: 19.2 s\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 16 if kaggle_init.is_tpu_available() else 2\ndummy_data = tfdata.Dataset.from_tensor_slices(\n    {\n        'input_ids': np.zeros((batch_size, max_length), dtype=np.int32),\n        'labels': -100*np.ones((batch_size, max_length), dtype=np.int32),\n        'text_id': -1*np.ones(batch_size, dtype=np.int32),\n        ## np.array([-1]*batch_size), #np.array(['0'*11]*batch_size),\n        'offset': np.zeros(batch_size, dtype=np.int32)\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.130390Z","iopub.execute_input":"2022-03-02T07:40:15.130862Z","iopub.status.idle":"2022-03-02T07:40:15.141460Z","shell.execute_reply.started":"2022-03-02T07:40:15.130769Z","shell.execute_reply":"2022-03-02T07:40:15.140303Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"dummy_data","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.146839Z","iopub.execute_input":"2022-03-02T07:40:15.147558Z","iopub.status.idle":"2022-03-02T07:40:15.156918Z","shell.execute_reply.started":"2022-03-02T07:40:15.147513Z","shell.execute_reply":"2022-03-02T07:40:15.155725Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"<TensorSliceDataset shapes: {input_ids: (512,), labels: (512,), text_id: (), offset: ()}, types: {input_ids: tf.int32, labels: tf.int32, text_id: tf.int32, offset: tf.int32}>"},"metadata":{}}]},{"cell_type":"code","source":"import jax\njax.devices(), jax.device_count()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.158525Z","iopub.execute_input":"2022-03-02T07:40:15.158984Z","iopub.status.idle":"2022-03-02T07:40:15.170548Z","shell.execute_reply.started":"2022-03-02T07:40:15.158943Z","shell.execute_reply":"2022-03-02T07:40:15.169427Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"([TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n  TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n  TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n  TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n  TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n  TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n  TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n  TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)],\n 8)"},"metadata":{}}]},{"cell_type":"code","source":"def subset(x):\n    return {k: x[k] for k in ['input_ids', 'labels', 'offset']}\n\ntrain_dataset = (ds['train'].\n                 # map(subset).\n                 repeat().\n                 shuffle(4096).\n                 batch(batch_size=batch_size).\n                 batch(batch_size=jax.device_count()).as_numpy_iterator())\n\ntest_dataset = (ds['test'].\n                concatenate(dummy_data.repeat(jax.device_count())).\n                #map(subset).\n                batch(batch_size=batch_size, drop_remainder=True).\n                batch(batch_size=jax.device_count(), drop_remainder=True))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.172099Z","iopub.execute_input":"2022-03-02T07:40:15.172420Z","iopub.status.idle":"2022-03-02T07:40:15.349359Z","shell.execute_reply.started":"2022-03-02T07:40:15.172381Z","shell.execute_reply":"2022-03-02T07:40:15.348419Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"len(ds['test']), len(ds['train'])","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.351107Z","iopub.execute_input":"2022-03-02T07:40:15.351751Z","iopub.status.idle":"2022-03-02T07:40:15.360210Z","shell.execute_reply.started":"2022-03-02T07:40:15.351707Z","shell.execute_reply":"2022-03-02T07:40:15.359281Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"(5116, 43645)"},"metadata":{}}]},{"cell_type":"code","source":"class Metric:\n    def __init__(self):\n        self.reset()\n    def reset(self):\n        self._value = 0\n        self._n = 0\n    def update(self,v):\n        self._n += 1\n        self._value += v\n    def value(self):\n        return self._value/self._n","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.361635Z","iopub.execute_input":"2022-03-02T07:40:15.362448Z","iopub.status.idle":"2022-03-02T07:40:15.372528Z","shell.execute_reply.started":"2022-03-02T07:40:15.362388Z","shell.execute_reply":"2022-03-02T07:40:15.371550Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"{k: f'shape={v.shape}, dtype={v.dtype}' for k,v in next(iter(train_dataset)).items()}","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.376796Z","iopub.execute_input":"2022-03-02T07:40:15.377855Z","iopub.status.idle":"2022-03-02T07:40:15.416407Z","shell.execute_reply.started":"2022-03-02T07:40:15.377808Z","shell.execute_reply":"2022-03-02T07:40:15.414920Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"{'input_ids': 'shape=(8, 16, 512), dtype=int32',\n 'labels': 'shape=(8, 16, 512), dtype=int32',\n 'offset': 'shape=(8, 16), dtype=int32',\n 'text_id': 'shape=(8, 16), dtype=int32'}"},"metadata":{}}]},{"cell_type":"code","source":"local_device_count = jax.device_count()\nlocal_device_count","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.417944Z","iopub.execute_input":"2022-03-02T07:40:15.418445Z","iopub.status.idle":"2022-03-02T07:40:15.425978Z","shell.execute_reply.started":"2022-03-02T07:40:15.418388Z","shell.execute_reply":"2022-03-02T07:40:15.424911Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"8"},"metadata":{}}]},{"cell_type":"code","source":"import haiku as hk\nimport jax.numpy as jnp\nimport optax\nimport functools\nfrom typing import Any, Mapping\n\ndef mk_loss_fn(config):\n    \n    def loss_fn(logits, data):\n    #                params,\n    #                rng,\n    #                data: Mapping[str, jnp.ndarray],\n    #                is_training: bool = True) -> jnp.ndarray:\n        \"\"\"Compute the loss on data wrt params.\"\"\"\n\n\n    #     logits = forward_fn(params, rng, data, is_training)\n        targets = jax.nn.one_hot(data['labels'], len(config['id2label']))\n        assert logits.shape == targets.shape\n\n        mask = jnp.not_equal(data['input_ids'], config['pad_token_id'])\n        mask = mask * jnp.greater_equal(data['labels'], 0)\n        loss = -jnp.sum(targets * jax.nn.log_softmax(logits), axis=-1)\n        loss = jnp.sum(loss * mask, axis=-1) / jnp.clip(jnp.sum(mask, axis=-1),1)\n\n        return jnp.mean(loss)\n    \n    return loss_fn\n\nclass Updater:\n    \"\"\"A stateless abstraction around an init_fn/update_fn pair.\n    This extracts some common boilerplate from the training loop.\n    \"\"\"\n\n    def __init__(self, \n                 net, \n                 loss_fn,\n                 optimizer: optax.GradientTransformation):\n        \n        self._net_init = net.init\n        self._loss_fn = lambda params,rng, data: loss_fn(net.apply(params, rng, data, is_training=True), data)\n        self._opt = optimizer\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def init(self, rng, data, pretrained_params=None):\n        \"\"\"Initializes state of the updater.\"\"\"\n        out_rng, init_rng = jax.random.split(rng)\n        params = self._net_init(init_rng, data)\n        if pretrained_params is not None:\n            params = hk.data_structures.merge(params, pretrained_params)\n        #params = hk.data_structures.map(lambda x: jnp.stack([x]*local_device_count), params)\n        opt_state = self._opt.init(params)\n        # rng = jax.random.PRNGKey(FLAGS.train_init_random_seed)\n        #rng = jnp.broadcast_to(rng, (local_device_count,) + rng.shape)\n        out = dict(\n            step=np.array(0),\n            rng=out_rng,\n            opt_state=opt_state,\n            params=params,\n            loss=np.array(0),\n        )\n        return out\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def update(self, state: Mapping[str, Any], data: Mapping[str, jnp.ndarray]):\n        \"\"\"Updates the state using some data and returns metrics.\"\"\"\n        rng, new_rng = jax.random.split(state['rng'])\n        params = state['params']\n        loss, grads = jax.value_and_grad(self._loss_fn)(params, rng, data)\n\n        if compute_on_tpu:\n            grads = jax.lax.pmean(grads, 'i')\n\n\n        updates, opt_state = self._opt.update(grads, state['opt_state'])\n        params = optax.apply_updates(params, updates)\n\n        new_state = {\n            'step': state['step'] + 1,\n            'rng': new_rng,\n            'opt_state': opt_state,\n            'params': params,\n            'loss': state['loss'] + loss\n        }\n\n        return new_state ","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.427984Z","iopub.execute_input":"2022-03-02T07:40:15.428763Z","iopub.status.idle":"2022-03-02T07:40:15.455407Z","shell.execute_reply.started":"2022-03-02T07:40:15.428720Z","shell.execute_reply":"2022-03-02T07:40:15.454347Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"def mk_net_eval(net):\n    def run_net(param, rng, data):\n        return net.apply(param, rng, data, is_training=False)\n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    return run_net\n\ndef predict(net, state, data):\n    predictions = []\n    data = data.map(lambda x: ({'input_ids':x['input_ids']},\n                               x['input_ids'],\n                               x['text_id'], \n                               x['offset'])).as_numpy_iterator()\n    \n    \n    for data, ids, text_id, offset  in data:    \n        logits = net(state['params'], state['rng'], data)\n        logits0 = jax.device_get(logits)\n        del logits\n        logits0 = logits0.reshape((-1,)+logits0.shape[2:])\n        ## 0,1,2 are <s> </s> <pad>!\n        mask = (ids>2).reshape((-1,)+ids.shape[2:])\n        predictions.extend(zip(text_id.reshape(-1), \n                               offset.reshape(-1), \n                               (logit[m] for logit,m in zip(logits0, mask))))\n                               #data['input_ids'].reshape((-1,)+data['input_ids']))\n    return predictions\n\nfrom collections import defaultdict\ndef collect_chunks(raw_predictions):\n    predictions = defaultdict(list)\n    for idx, offset, logit in raw_predictions:\n        predictions[idx].append((offset, logit))\n    return dict(predictions)\n\ndef combine_offset_list(offset_lst):\n    offset_lst = [(offset, np.asarray(c)) for offset, c in offset_lst]\n    total_len = max(offset+len(c) for offset, c in offset_lst)\n    chunk_shape = offset_lst[0][1].shape\n    res = np.zeros((total_len,)+chunk_shape[1:])\n    cnt = np.zeros((total_len,)+(1,)*(len(chunk_shape)-1))\n    for i, (o, c) in enumerate(offset_lst):\n        res[o:o+len(c)] += c\n        cnt[o:o+len(c)] += 1\n    return res/cnt.clip(1)\n\nfrom feedback2021.helper import label2id, id2label, Block\ndef pred_rle(pred):\n    \n    res = []\n    cur_cls = -1\n    min_cls = label2id.get('None',-1)\n    \n    for i, cls_id in enumerate(pred):\n        \n        if (cur_cls>min_cls) and (cur_cls!=cls_id):\n            res.append(Block((cur_cls, start, i)))\n            cur_cls = -1\n        \n        if cls_id>min_cls and cur_cls==-1: \n            cur_cls, start = cls_id, i\n    \n    if cur_cls>min_cls:\n        res.append(Block((cur_cls, start, i+1)))\n    \n    return res\n\n\nimport  feedback2021.metric as metric\n\ndef compute_metric(net, state, chunked_data, raw_df):\n    predictions = predict(net, state, chunked_data)\n    predictions = collect_chunks(predictions)\n    predictions = {k: pred_rle(np.argmax(combine_offset_list(v), axis=-1)) \n                   for k,v in predictions.items()}\n    \n    raw_data = zip(raw_df.index, raw_df['offset_mapping'], raw_df['word_mapping'])\n    predictions = [\n            [b.map(om).inv_map(wm) for b in predictions[idx]]\n            for idx, om, wm in raw_data\n        ]\n\n    scores = np.array([ \n            metric.score_example(y_pred=y_pred, y_true=y_true)\n            for y_pred,y_true in zip(predictions, raw_df['rle_word'])\n        ]).sum(axis=0)\n        \n    res = {id2label[i+1]: metric.f1(*score) for i, score in enumerate(scores)}\n    res['f1'] = sum(res.values())/len(res)\n        \n    return res\n    \n    \n    \n\n## predict(jax.pmap(net.apply, axis_name='i'), state, dataset)\n\n        \ndef get_predictions(net, loss_fn, state, test_ds):\n\n    def run_net(state, data):\n        logits = net.apply(state['params'], state['rng'], data, is_training=False)\n        loss = loss_fn(logits, data)\n        pred = jax.numpy.argmax(logits, axis=-1)\n        state['loss'] = state['loss'] + loss\n        return pred, state\n        \n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    predictions = []\n    for batch in test_ds.as_numpy_iterator():\n        pred, state = run_net(state, batch)\n        predictions.append(pred)\n        \n    predictions = [ pred \n                    for preds in jax.device_get(predictions) \n                    for pred in preds.reshape((-1,) + preds.shape[2:]) ]\n    return predictions, state\n\ndef eval_net(net, loss_fn, state, test_ds):\n\n    def run_net(state, data, loss, cnt):\n        cnt0 = jnp.greater(data['labels'].max(axis=-1),0).sum()\n        logits = net.apply(state['params'], state['rng'], data, is_training=False)\n        loss0 = loss_fn(logits, data) * data['labels'].shape[0]\n        #pred = jax.numpy.argmax(logits, axis=-1)\n        #state['loss'] = state['loss'] + loss\n        return loss + loss0, cnt + cnt0\n        \n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    #predictions = []\n    loss = np.zeros(jax.device_count())\n    cnt = np.zeros(jax.device_count())\n    for batch in test_ds.as_numpy_iterator():\n        loss, cnt = run_net(state, batch, loss, cnt)\n        # predictions.append(pred)\n    return float(loss.sum()/cnt.sum())","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:49:14.486674Z","iopub.execute_input":"2022-03-02T07:49:14.487125Z","iopub.status.idle":"2022-03-02T07:49:14.542189Z","shell.execute_reply.started":"2022-03-02T07:49:14.487068Z","shell.execute_reply":"2022-03-02T07:49:14.540797Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"class Log:\n    def __init__(self, step=0):\n        self.step = step\n        self.start_time = self.prev_time = time.time()\n        \n    def update(self, state):\n        step = int(state['step'][0])\n        step_delta, self.step = step-self.step, step\n        \n        c_time = time.time()\n        time_delta, self.prev_time = c_time - self.prev_time, c_time\n        \n        loss = float(state['loss'].mean())/step_delta\n        state['loss'] = 0*state['loss']\n        \n        return {'step': self.step,\n                'loss': loss,\n                'elapsed_time': time_delta,\n                'total_time':   c_time-self.start_time,\n                'iter_per_sec': time_delta/max(1,step_delta),\n                'sec_per_iter': step_delta/max(1,time_delta),\n               }\n\ndef format_log(log):\n    return \"iteration: {step:<5}, loss: {loss:.4f}, elapsed_time:{elapsed_time:.2f}\".format(**log)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.509789Z","iopub.execute_input":"2022-03-02T07:40:15.510467Z","iopub.status.idle":"2022-03-02T07:40:15.525167Z","shell.execute_reply.started":"2022-03-02T07:40:15.510424Z","shell.execute_reply":"2022-03-02T07:40:15.524031Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"import logging\nimport time\nfrom transformers import AutoConfig\nfrom feedback2021.hk_roberta import (build_forward_fn, \n                                     lm_loss_fn, \n                                     # GradientUpdater, \n                                     hk, optax, functools, Mapping, jnp, jax)\n\n## global variables\n# batch_size = 16  # Train batch size per core\ntotal_batch_size = batch_size*jax.device_count()\nlearning_rate = 1.25e-5*(total_batch_size/32) # Max learning-rate\ngrad_clip_value = 0.2  # Gradient norm clip value\n\ncheckpoint_dir = '/jax-transformer'  # Directory to store checkpoints\nif just_test:\n    LOG_EVERY = 2\n    MAX_STEPS = 4\nelse:\n    LOG_EVERY = len(ds['train'])//(2*total_batch_size)\n    MAX_STEPS = (4*len(ds['train']))//total_batch_size+1\n\nconfig = AutoConfig.from_pretrained(model_checkpoint, #'distilroberta-base', \n                                    label2id=label2id, \n                                    id2label=id2label).to_dict()\ntranslation = hk_roberta.weight_name_translation(config=config, prefix='roberta')\npretrained_params = hk_roberta.load_hf_pytorch_weights(model_checkpoint, #'distilroberta-base', \n                                                       translation)\n\nlogging.info = print\nlogging.info('Starting...')\n\nforward_fn = build_forward_fn(config)\n\nforward_fn = hk.transform(forward_fn)\n\n#loss_fn = functools.partial(lm_loss_fn, forward_fn.apply, config)\nloss_fn = mk_loss_fn(config)\n\nlr_schedule=optax.warmup_cosine_decay_schedule(init_value=0, \n                                               peak_value=1, \n                                               warmup_steps=min(50, MAX_STEPS//6), \n                                               decay_steps=MAX_STEPS-min(50,MAX_STEPS//6), \n                                               end_value=1e-4)\n\noptimizer = optax.chain(\n        optax.clip_by_global_norm(grad_clip_value),\n        optax.adam(learning_rate, b1=0.9, b2=0.99),\n        optax.scale_by_schedule(lr_schedule),\n    )\n\nupdater = Updater(forward_fn, loss_fn, optimizer)\n\n# Initialize parameters.\nlogging.info('Initializing parameters...')\nrng = jax.random.PRNGKey(428)\nbatch = next(iter(train_dataset))\nstate = updater.init(rng, #jnp.broadcast_to(rng, (local_device_count,) + rng.shape), \n                     {k:v[0] for k,v in batch.items()},\n                     pretrained_params=pretrained_params)\nif compute_on_tpu:\n    state = jax.device_put_replicated(state, jax.devices())\n    update = jax.pmap(updater.update, axis_name='i')\nelse:\n    update = updater.update\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.526908Z","iopub.execute_input":"2022-03-02T07:40:15.527771Z","iopub.status.idle":"2022-03-02T07:40:35.757956Z","shell.execute_reply.started":"2022-03-02T07:40:15.527722Z","shell.execute_reply":"2022-03-02T07:40:35.756590Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"unused torch weights: roberta.embeddings.token_type_embeddings.weight,\nroberta.pooler.dense.weight, roberta.pooler.dense.bias, lm_head.bias,\nlm_head.dense.weight, lm_head.dense.bias, lm_head.layer_norm.weight,\nlm_head.layer_norm.bias, lm_head.decoder.weight\nStarting...\nInitializing parameters...\n","output_type":"stream"}]},{"cell_type":"code","source":"learning_rate, 5e-5*(total_batch_size/32)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:35.764593Z","iopub.execute_input":"2022-03-02T07:40:35.765306Z","iopub.status.idle":"2022-03-02T07:40:35.775505Z","shell.execute_reply.started":"2022-03-02T07:40:35.765231Z","shell.execute_reply":"2022-03-02T07:40:35.774366Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"(5e-05, 0.0002)"},"metadata":{}}]},{"cell_type":"code","source":"logging.info('Starting train loop...')\ntrain_iter = train_dataset\nlog = Log()\nnet_eval_fn = mk_net_eval(forward_fn)\nfor step  in range(MAX_STEPS): #enumerate(train_dataset):\n        batch = next(train_iter)\n        state = update(state, batch)\n        # We use JAX runahead to mask data preprocessing and JAX dispatch overheads.\n        # Using values from state/metrics too often will block the runahead and can\n        # cause these overheads to become more prominent.\n        if step % LOG_EVERY == 0 or (step+1)== MAX_STEPS:\n            last_log=log.update(state)\n            logging.info(last_log)\n            print(compute_metric(net_eval_fn, state, test_dataset, data['test']))\n            # test_loss = eval_net(forward_fn, loss_fn, state, test_dataset)\n            # last_log['test_loss'] = test_loss #float(state['loss'].mean())\n            \n            \n\n# logging.info(last_log)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:52:10.239026Z","iopub.execute_input":"2022-03-02T07:52:10.239600Z","iopub.status.idle":"2022-03-02T08:02:17.842195Z","shell.execute_reply.started":"2022-03-02T07:52:10.239554Z","shell.execute_reply":"2022-03-02T08:02:17.841040Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"Starting train loop...\n{'step': 3, 'loss': 0.7534740765889486, 'elapsed_time': 0.35556960105895996, 'total_time': 0.35556960105895996, 'iter_per_sec': 0.11852320035298665, 'sec_per_iter': 3.0}\n{'Lead': 0.0, 'Position': 0.027722930253894173, 'Evidence': 0.0, 'Claim': 0.0003870718018192375, 'Concluding Statement': 0.0, 'Counterclaim': 0.0, 'Rebuttal': 0.0, 'f1': 0.00401571457938763}\n{'step': 173, 'loss': 0.916682523839614, 'elapsed_time': 82.15834403038025, 'total_time': 82.51391363143921, 'iter_per_sec': 0.4832843766492956, 'sec_per_iter': 2.069175103348455}\n{'Lead': 0.31341077085533264, 'Position': 0.27235279864308215, 'Evidence': 0.3947723647073261, 'Claim': 0.3103284902084649, 'Concluding Statement': 0.4070897655803316, 'Counterclaim': 0.2469775474956822, 'Rebuttal': 0.12072434607645875, 'f1': 0.2950937262238112}\n{'step': 343, 'loss': 0.5488656436695772, 'elapsed_time': 73.58670043945312, 'total_time': 156.10061407089233, 'iter_per_sec': 0.432862943761489, 'sec_per_iter': 2.310200063119767}\n{'Lead': 0.5008403361344538, 'Position': 0.47658979734451434, 'Evidence': 0.5273098134018283, 'Claim': 0.491613005803323, 'Concluding Statement': 0.6295030239284776, 'Counterclaim': 0.2904636920384952, 'Rebuttal': 0.16257088846880907, 'f1': 0.43984150815998585}\n{'step': 513, 'loss': 0.49512513104607075, 'elapsed_time': 73.58967137336731, 'total_time': 229.69028544425964, 'iter_per_sec': 0.43288041984333714, 'sec_per_iter': 2.3101067966111932}\n{'Lead': 0.5829737151824245, 'Position': 0.5191489361702127, 'Evidence': 0.5592476489028213, 'Claim': 0.49791103465224873, 'Concluding Statement': 0.7037037037037037, 'Counterclaim': 0.3471295060080107, 'Rebuttal': 0.215625, 'f1': 0.4893913635170603}\n{'step': 683, 'loss': 0.43471536075367645, 'elapsed_time': 73.10572528839111, 'total_time': 302.79601073265076, 'iter_per_sec': 0.43003367816700655, 'sec_per_iter': 2.3253992670119272}\n{'Lead': 0.61015625, 'Position': 0.5479744136460555, 'Evidence': 0.56359375, 'Claim': 0.5100408441116405, 'Concluding Statement': 0.7102016250376166, 'Counterclaim': 0.3321351545650611, 'Rebuttal': 0.2137809187279152, 'f1': 0.4982689937268984}\n{'step': 853, 'loss': 0.4007848403033088, 'elapsed_time': 73.2603976726532, 'total_time': 376.05640840530396, 'iter_per_sec': 0.4309435157214894, 'sec_per_iter': 2.3204897243338056}\n{'Lead': 0.5846632931101596, 'Position': 0.5315110098709187, 'Evidence': 0.5519203413940256, 'Claim': 0.496938294865756, 'Concluding Statement': 0.6746776084407972, 'Counterclaim': 0.34759358288770054, 'Rebuttal': 0.23267750213858, 'f1': 0.48856880467256253}\n{'step': 1023, 'loss': 0.35791410558363973, 'elapsed_time': 70.4713134765625, 'total_time': 446.52772188186646, 'iter_per_sec': 0.4145371380974265, 'sec_per_iter': 2.4123290969528894}\n{'Lead': 0.6147047006830052, 'Position': 0.5387359836901121, 'Evidence': 0.5380648141020706, 'Claim': 0.49321615787850753, 'Concluding Statement': 0.678235294117647, 'Counterclaim': 0.34972677595628415, 'Rebuttal': 0.22257806244995998, 'f1': 0.4907516841253695}\n{'step': 1193, 'loss': 0.34057123520795035, 'elapsed_time': 73.40339541435242, 'total_time': 519.9311172962189, 'iter_per_sec': 0.4317846789079554, 'sec_per_iter': 2.3159691597421697}\n{'Lead': 0.6153229041315684, 'Position': 0.5426395939086295, 'Evidence': 0.5326382592928377, 'Claim': 0.49932801011937705, 'Concluding Statement': 0.6796575140242103, 'Counterclaim': 0.34321766561514194, 'Rebuttal': 0.22152886115444617, 'f1': 0.4906189726066016}\n{'step': 1363, 'loss': 0.32407706765567557, 'elapsed_time': 73.41060161590576, 'total_time': 593.3417189121246, 'iter_per_sec': 0.4318270683288574, 'sec_per_iter': 2.3157418173666944}\n{'Lead': 0.6113328012769353, 'Position': 0.5457348406988695, 'Evidence': 0.5417496552780757, 'Claim': 0.50090515545061, 'Concluding Statement': 0.6815078658355596, 'Counterclaim': 0.3559435862995299, 'Rebuttal': 0.22953451043338685, 'f1': 0.49524405932470955}\n{'step': 1366, 'loss': 0.3381648858388265, 'elapsed_time': 7.702139139175415, 'total_time': 601.0438580513, 'iter_per_sec': 2.5673797130584717, 'sec_per_iter': 0.3895021818991935}\n{'Lead': 0.6109119872560733, 'Position': 0.5480719794344473, 'Evidence': 0.543236399907926, 'Claim': 0.5010234608723035, 'Concluding Statement': 0.6831300208271348, 'Counterclaim': 0.3527054108216433, 'Rebuttal': 0.22738190552441953, 'f1': 0.4952087378062783}\n","output_type":"stream"}]},{"cell_type":"code","source":"net_eval_fn = mk_net_eval(forward_fn)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:50:45.448387Z","iopub.execute_input":"2022-03-02T07:50:45.449598Z","iopub.status.idle":"2022-03-02T07:50:45.458910Z","shell.execute_reply.started":"2022-03-02T07:50:45.449542Z","shell.execute_reply":"2022-03-02T07:50:45.457765Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(compute_metric(net_eval_fn, state, test_dataset, data['test']))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:51:22.812991Z","iopub.execute_input":"2022-03-02T07:51:22.813397Z","iopub.status.idle":"2022-03-02T07:51:34.447243Z","shell.execute_reply.started":"2022-03-02T07:51:22.813356Z","shell.execute_reply":"2022-03-02T07:51:34.446075Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"{'Lead': 0.0, 'Position': 0.02795737909642073, 'Evidence': 0.0, 'Claim': 0.00038757186228279824, 'Concluding Statement': 0.0, 'Counterclaim': 0.0, 'Rebuttal': 0.0, 'f1': 0.0040492787083862185}\nCPU times: user 15.8 s, sys: 3.68 s, total: 19.5 s\nWall time: 11.6 s\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = get_predictions(forward_fn, loss_fn, state=state, test_ds=test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:35:38.784742Z","iopub.execute_input":"2022-02-25T12:35:38.785273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# next(test_dataset.as_numpy_iterator())\n#next(iter(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:35:26.825227Z","iopub.execute_input":"2022-02-25T12:35:26.825509Z","iopub.status.idle":"2022-02-25T12:35:26.879572Z","shell.execute_reply.started":"2022-02-25T12:35:26.825481Z","shell.execute_reply":"2022-02-25T12:35:26.878887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(pred), pred[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:50:54.188065Z","iopub.execute_input":"2022-02-24T08:50:54.188883Z","iopub.status.idle":"2022-02-24T08:50:54.195233Z","shell.execute_reply.started":"2022-02-24T08:50:54.188841Z","shell.execute_reply":"2022-02-24T08:50:54.19407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = hk.data_structures.map(lambda name,module,x: x[0], state['params'])\nimport pickle\nwith open('params.pkl','wb') as f:\n    pickle.dump(params, f)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T06:13:23.821943Z","iopub.execute_input":"2022-02-23T06:13:23.822508Z","iopub.status.idle":"2022-02-23T06:13:27.022087Z","shell.execute_reply.started":"2022-02-23T06:13:23.822465Z","shell.execute_reply":"2022-02-23T06:13:27.020853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shraded_ds = [list(ds['train'].shard(8, i).as_numpy_iterator()) for i in range(8)]","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:00:08.984632Z","iopub.execute_input":"2022-02-26T06:00:08.985611Z","iopub.status.idle":"2022-02-26T06:00:25.119974Z","shell.execute_reply.started":"2022-02-26T06:00:08.985566Z","shell.execute_reply":"2022-02-26T06:00:25.118793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sharded_ds = jax.device_put_sharded(shards=shraded_ds, devices=jax.devices())","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:01:13.078175Z","iopub.execute_input":"2022-02-26T06:01:13.079144Z","iopub.status.idle":"2022-02-26T06:01:42.867983Z","shell.execute_reply.started":"2022-02-26T06:01:13.079094Z","shell.execute_reply":"2022-02-26T06:01:40.989601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_schedule=optax.warmup_cosine_decay_schedule(init_value=0, \n                                               peak_value=1, \n                                               warmup_steps=500, \n                                               decay_steps=8500, \n                                               end_value=1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:41:44.23837Z","iopub.execute_input":"2022-02-21T06:41:44.238975Z","iopub.status.idle":"2022-02-21T06:41:44.245739Z","shell.execute_reply.started":"2022-02-21T06:41:44.238926Z","shell.execute_reply":"2022-02-21T06:41:44.244518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jaxlib, jax\njaxlib.__version__, jax.__version__, hk.__version__","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:45:48.632171Z","iopub.execute_input":"2022-02-21T06:45:48.632588Z","iopub.status.idle":"2022-02-21T06:45:48.640181Z","shell.execute_reply.started":"2022-02-21T06:45:48.632543Z","shell.execute_reply":"2022-02-21T06:45:48.639215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt = np.arange(0,9000,10)\nlr = [lr_schedule(jnp.array([i])) for i in cnt]\nplt.plot(cnt, lr)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:41:48.464737Z","iopub.execute_input":"2022-02-21T06:41:48.465445Z","iopub.status.idle":"2022-02-21T06:42:26.896087Z","shell.execute_reply.started":"2022-02-21T06:41:48.465381Z","shell.execute_reply":"2022-02-21T06:42:26.893875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{'loss': 2.4778389930725098, 'step': 0.0, 'steps_per_sec': 13.779059174634387}\n{'loss': 1.3683964014053345, 'step': 500.0, 'steps_per_sec': 2.5767113856201855}\n{'loss': 1.6631159782409668, 'step': 1000.0, 'steps_per_sec': 2.57725389686341}\n{'loss': 1.3581798076629639, 'step': 1500.0, 'steps_per_sec': 2.5771785561488483}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{k:v.shape for k,v in data.items()}","metadata":{"execution":{"iopub.status.busy":"2022-02-26T05:57:06.831234Z","iopub.execute_input":"2022-02-26T05:57:06.831874Z","iopub.status.idle":"2022-02-26T05:57:06.840862Z","shell.execute_reply.started":"2022-02-26T05:57:06.831826Z","shell.execute_reply":"2022-02-26T05:57:06.839748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jax.numpy.array([1,1])\n#jax.device_get('gpu')\n#jax.devices('gpu')\n! nvcc --version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n# TRAINING HYPERPARAMS\neffective_batch_size = 32\nmax_steps = 4000\nlog_steps = 500\n#n_step_examples = 8*500\nbatch_size = 16\ngrad_accumulation = effective_batch_size//batch_size\nlearning_rate = 5e-5\nweight_decay = 0.01\nwarmup_ratio = 0.1\nn_epochs = 3\nmodel_name = model_checkpoint.split(\"/\")[-1]\ntraining_args = TrainingArguments(\n    f\"{model_name}-{task}\",\n    evaluation_strategy = \"steps\",\n    eval_steps = log_steps,\n    logging_strategy = \"steps\",\n    logging_steps = log_steps,\n    save_strategy = \"steps\",\n    save_steps = log_steps,\n    learning_rate = learning_rate,\n    per_device_train_batch_size = batch_size,\n    per_device_eval_batch_size = batch_size,\n    #num_train_epochs = n_epochs,\n    max_steps = max_steps,\n    weight_decay = weight_decay,\n    report_to = 'wandb', \n    gradient_accumulation_steps = grad_accumulation,\n    warmup_steps = int(1.5*(log_steps)),\n    # logging_steps = 100,\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    greater_is_better=True,\n)\n#training_args","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['test']=add_rle_word2(data['test'])\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=chunk_data[\"train\"].remove_columns(['offset', 'text_id']), #.select(range(100)),\n    eval_dataset=chunk_data[\"test\"].remove_columns(['offset', 'text_id']), #.select(range(100)),\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=mk_binary_metric(chunk_ds=chunk_data['test'],\n                                     orig_ds=data['test'])\n    #,\n    #                                 min_word_cnt=[0,10,5,10,3,10,6,6]), #.select(range(100))), \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.save_model(model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wandb.init()\nimport pickle\nfrom feedback2021.postprocess import mk_prediction_transform\nfor k,v in chunk_data.items():\n    predictions = trainer.predict(v.remove_columns(['offset', 'text_id']))\n    prediction_transform = mk_binary_prediction_transform(chunk_ds=v, orig_ds=data[k])\n    predictions = prediction_transform(predictions[0])\n    with open(f'{k}_predictions.pkl','wb') as f:\n        pickle.dump(predictions, f)\n    wandb.save(f'{k}_predictions.pkl','./','now')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! rm longformer-base-4096-token_classification/ -rf\n#!rm distilroberta-base-token_classification -rf\n! ls -sh distilroberta-base-1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# From this point on there is no need to gpu!","metadata":{"execution":{"iopub.execute_input":"2021-12-30T06:52:35.965148Z","iopub.status.busy":"2021-12-30T06:52:35.964896Z","iopub.status.idle":"2021-12-30T06:52:36.089436Z","shell.execute_reply":"2021-12-30T06:52:36.088549Z","shell.execute_reply.started":"2021-12-30T06:52:35.96512Z"}}},{"cell_type":"code","source":"prediction_file = wandb.restore('predictions.pkl', run_path='prvi/huggingface/d17yam8m')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_file_name = 'test_predictions.pkl' #if os.path.exists('test_predictions.pkl') else prediction_file.name\nwith open(prediction_file_name, 'rb') as f:\n    saved_predictions = pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chunk_ds, orig_ds = chunk_data['test'].to_dict(), data['test'].to_dict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter_prediction(prediction, min_word_cnt):\n    return [b for b in prediction if b[2]-b[1]>=min_word_cnt[b[0]]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport pandas as pd\nres = []\nfor mwc in tqdm(range(0,15)):\n#     transform_prediction = mk_prediction_transform(chunk_ds=chunk_ds,\n#                                                    orig_ds=orig_ds, min_word_cnt=mwc)\n#     predictions = transform_prediction(saved_predictions[0])\n    \n    scores = np.array([metric.score_example(y_true=y_true, \n                                            y_pred=filter_prediction(y_pred,mwc)) \n              for y_pred,y_true in zip(saved_predictions,orig_ds['rle_word'])]).sum(axis=0)\n    scores = [metric.f1(*score) for score in scores]\n    f1 = sum(scores)/len(scores)\n    scores = {id2label[i+1]:score for i,score in enumerate(scores)}\n    scores['f1'] = f1\n    scores['min_word_cnt']=mwc\n    res.append(scores)\n\npd.DataFrame(res).set_index('min_word_cnt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mwc =[0, 10, 6, 15, 6, 11, 9, 8]\n\nscores_ = np.array([metric.score_example(y_true=y_true, \n                                        y_pred=filter_prediction(y_pred,mwc)) \n              for y_pred,y_true in zip(saved_predictions,orig_ds['rle_word'])]).sum(axis=0)\nscores = [metric.f1(*score) for score in scores_]\nf1 = sum(scores)/len(scores)\nscores = {id2label[i+1]:score for i,score in enumerate(scores)}\nscores['f1'] = f1\n    \n# transform_prediction = mk_prediction_transform(chunk_ds=chunk_ds,\n#                                                 orig_ds=orig_ds, \n#                                                min_word_cnt=[0, 10, 6, 15, 6, 11, 9, 8])\n# predictions = transform_prediction(saved_predictions[0])\n# scores = np.array([metric.score_example(y_true=y_true, y_pred=y_pred) \n#               for y_true,y_pred in zip(predictions,orig_ds['pred_range'])]).sum(axis=0)\n# scores = [metric.f1(*score) for score in scores]\n# f1 = sum(scores)/len(scores)\n# scores = {id2label[i+1]:score for i,score in enumerate(scores)}\n# scores['f1'] = f1\nscores    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = [ sorted(pred, key=lambda x: x[1]) for pred in saved_predictions]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_result(i=20, orig_ds=data['test'],predictions=predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsaved_predictions[8],data['test'][8]['rle_token']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = [metric.score_example(y_true=y_true, y_pred=y_pred) for y_true,y_pred in zip(predictions,orig_ds['pred_range'])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[metric.f1(*x) for x in np.array(scores).sum(axis=0)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = np.argsort(np.array(scores)[:,:,1:].sum(axis=(1,2)))[::-1]\nidx[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}