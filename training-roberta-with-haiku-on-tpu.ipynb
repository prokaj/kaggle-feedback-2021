{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_github = user_secrets.get_secret(\"github\")\n! rm -rf feedback2021\n! git clone https://{secret_github}@github.com/VilmosProkaj/feedback2021.git\n! pip install feedback2021/","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:37:38.187543Z","iopub.execute_input":"2022-02-25T12:37:38.187875Z","iopub.status.idle":"2022-02-25T12:38:08.848864Z","shell.execute_reply.started":"2022-02-25T12:37:38.187781Z","shell.execute_reply":"2022-02-25T12:38:08.847823Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'feedback2021'...\nremote: Enumerating objects: 216, done.\u001b[K\nremote: Counting objects: 100% (216/216), done.\u001b[K\nremote: Compressing objects: 100% (127/127), done.\u001b[K\nremote: Total 216 (delta 105), reused 163 (delta 52), pack-reused 0\u001b[K\nReceiving objects: 100% (216/216), 59.29 KiB | 595.00 KiB/s, done.\nResolving deltas: 100% (105/105), done.\nProcessing ./feedback2021\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from feedback2021==0.0.post1.dev30+g983bd4b) (4.10.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->feedback2021==0.0.post1.dev30+g983bd4b) (3.6.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->feedback2021==0.0.post1.dev30+g983bd4b) (4.0.1)\nBuilding wheels for collected packages: feedback2021\n  Building wheel for feedback2021 (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for feedback2021: filename=feedback2021-0.0.post1.dev30+g983bd4b-py3-none-any.whl size=23561 sha256=d5e16f76b13729f37f264935c45c590e3a50dd3d8c61f67f7a1c87f8386f13ab\n  Stored in directory: /tmp/pip-ephem-wheel-cache-md2l1ssw/wheels/58/ad/18/0ce3edd06dac18258cb4965c488a42e46fa829de9c6aa2319e\nSuccessfully built feedback2021\nInstalling collected packages: feedback2021\nSuccessfully installed feedback2021-0.0.post1.dev30+g983bd4b\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install -U jax jaxlib dm_haiku optax\n#!pip install --upgrade pip\n# Installs the wheel compatible with CUDA 11 and cuDNN 8.2 or newer.\n# ! pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html  # Note: wheels only available on linux.\n## !pip install --upgrade jax jaxlib==0.3.0+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n#! pip install dm_haiku","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:38:08.851287Z","iopub.execute_input":"2022-02-25T12:38:08.851547Z","iopub.status.idle":"2022-02-25T12:38:29.783126Z","shell.execute_reply.started":"2022-02-25T12:38:08.851517Z","shell.execute_reply":"2022-02-25T12:38:29.782238Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: jax in /opt/conda/lib/python3.7/site-packages (0.2.28)\nCollecting jax\n  Downloading jax-0.3.1.tar.gz (912 kB)\n     |████████████████████████████████| 912 kB 533 kB/s            \n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: jaxlib in /opt/conda/lib/python3.7/site-packages (0.1.76)\nCollecting jaxlib\n  Downloading jaxlib-0.3.0-cp37-none-manylinux2010_x86_64.whl (65.4 MB)\n     |████████████████████████████████| 65.4 MB 56.4 MB/s            \n\u001b[?25hCollecting dm_haiku\n  Downloading dm_haiku-0.0.6-py3-none-any.whl (309 kB)\n     |████████████████████████████████| 309 kB 46.9 MB/s            \n\u001b[?25hRequirement already satisfied: optax in /opt/conda/lib/python3.7/site-packages (0.1.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from jax) (0.15.0)\nRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.7/site-packages (from jax) (1.20.3)\nRequirement already satisfied: opt_einsum in /opt/conda/lib/python3.7/site-packages (from jax) (3.3.0)\nRequirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from jax) (1.7.3)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from jax) (4.0.1)\nRequirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/conda/lib/python3.7/site-packages (from jaxlib) (1.12)\nCollecting jmp>=0.0.2\n  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from dm_haiku) (0.8.9)\nRequirement already satisfied: chex>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from optax) (0.1.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py->jax) (1.16.0)\nRequirement already satisfied: toolz>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from chex>=0.0.4->optax) (0.11.2)\nRequirement already satisfied: dm-tree>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from chex>=0.0.4->optax) (0.1.6)\nBuilding wheels for collected packages: jax\n  Building wheel for jax (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jax: filename=jax-0.3.1-py3-none-any.whl size=1054277 sha256=6dbc5888ad42f8928bf155c952f76b2db2cfb98539c9456a413b110f444dc021\n  Stored in directory: /root/.cache/pip/wheels/04/14/e8/ee9de500f173ec900a5167686d9bb17c0171ed678680b96a57\nSuccessfully built jax\nInstalling collected packages: jaxlib, jax, jmp, dm-haiku\n  Attempting uninstall: jaxlib\n    Found existing installation: jaxlib 0.1.76\n    Uninstalling jaxlib-0.1.76:\n      Successfully uninstalled jaxlib-0.1.76\n  Attempting uninstall: jax\n    Found existing installation: jax 0.2.28\n    Uninstalling jax-0.2.28:\n      Successfully uninstalled jax-0.2.28\nSuccessfully installed dm-haiku-0.0.6 jax-0.3.1 jaxlib-0.3.0 jmp-0.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import kaggle_init","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:38:29.785041Z","iopub.execute_input":"2022-02-25T12:38:29.785559Z","iopub.status.idle":"2022-02-25T12:38:29.793895Z","shell.execute_reply.started":"2022-02-25T12:38:29.785516Z","shell.execute_reply":"2022-02-25T12:38:29.793268Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"kaggle_init.on_kaggle(), kaggle_init.is_cuda_available(), kaggle_init.is_tpu_available()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:39:13.984314Z","iopub.execute_input":"2022-02-25T12:39:13.984614Z","iopub.status.idle":"2022-02-25T12:39:13.994216Z","shell.execute_reply.started":"2022-02-25T12:39:13.984585Z","shell.execute_reply":"2022-02-25T12:39:13.993573Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(True, False, False)"},"metadata":{}}]},{"cell_type":"code","source":"import os\nos.environ","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:55:13.282127Z","iopub.execute_input":"2022-02-23T08:55:13.282678Z","iopub.status.idle":"2022-02-23T08:55:13.289041Z","shell.execute_reply.started":"2022-02-23T08:55:13.282643Z","shell.execute_reply":"2022-02-23T08:55:13.288273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %env XLA_PYTHON_CLIENT_MEM_FRACTION=.75\ncompute_on_tpu = True\nif compute_on_tpu:\n    if kaggle_init.is_tpu_available():\n        from feedback2021.jax_tpu_init import jax_tpu_init\n        jax_tpu_init()       \n    else:\n        import os\n        os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=2'\n#import jax\n#jax.devices()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:39:16.681041Z","iopub.execute_input":"2022-02-25T12:39:16.681577Z","iopub.status.idle":"2022-02-25T12:39:16.686799Z","shell.execute_reply.started":"2022-02-25T12:39:16.681541Z","shell.execute_reply":"2022-02-25T12:39:16.686214Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# jax_tpu_init??","metadata":{"execution":{"iopub.status.busy":"2022-02-21T12:46:26.782749Z","iopub.execute_input":"2022-02-21T12:46:26.783173Z","iopub.status.idle":"2022-02-21T12:46:26.789086Z","shell.execute_reply.started":"2022-02-21T12:46:26.783134Z","shell.execute_reply":"2022-02-21T12:46:26.787885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOG_TO_WANDB = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB:\n    !pip install --upgrade wandb -q # experiment tracking","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB:\n    import wandb\n    import os\n    os.environ[\"WANDB_PROJECT\"] = \"kaggle_feedback\"\n    os.environ[\"WANDB_ENTITY\"] = \"prvi\"\n    os.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n    os.environ[\"WANDB_WATCH\"] = \"gradient\"\n\n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        api_key = user_secrets.get_secret(\"wandb\")\n        os.environ[\"WANDB_API_KEY\"] = api_key\n        wandb.login()\n        wandb.init(dir=\"/tmp/\") \n    except:\n        print('If you want to use your W&B account, '\n              'go to Add-ons -> Secrets and provide your W&B access token.\\n'\n              'Use the Label name `wandb`. \\n'\n              'Get your W&B access token from here: https://wandb.ai/authorize')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from feedback2021.helper import id2label, label2id\n\nfrom feedback2021.prepare_data import (create_train_dataset_pd, \n                                       to_chunk_data, \n                                       chunk_mapping,\n                                       add_input_ids, \n                                       add_labels,\n                                       add_rle_word2,\n                                       has_name,\n                                    )\n\nimport feedback2021.metric as metric\n\nfrom feedback2021.postprocess import (mk_metric, \n                                      mk_prediction_transform, \n                                      mk_binary_metric, \n                                      mk_binary_prediction_transform)\n\nfrom feedback2021.visualize import show_result\n\nimport feedback2021.hk_roberta as hk_roberta","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:39:21.723082Z","iopub.execute_input":"2022-02-25T12:39:21.723918Z","iopub.status.idle":"2022-02-25T12:39:23.487596Z","shell.execute_reply.started":"2022-02-25T12:39:21.723861Z","shell.execute_reply":"2022-02-25T12:39:23.486616Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# CONFIG\njust_test = True\nexperiment_id = 1\ntask = \"token_classification\"\nmodel_checkpoint = \"distilroberta-base\" \n# \"allenai/longformer-base-4096\" \n# \"distilroberta-base\" # \"microsoft/deberta-v3-xsmall\" #\"roberta-base\"\nif just_test:\n    max_length = 128\n    stride = 128\nelse:\n    max_length = 512\n    stride = 128\nmin_tokens = 6\nmodel_path = f'{model_checkpoint.split(\"/\")[-1]}-{experiment_id}'\ndata_from_wandb = False\nsave_to_wandb = False or not data_from_wandb\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-02-25T12:39:48.906333Z","iopub.execute_input":"2022-02-25T12:39:48.907221Z","iopub.status.idle":"2022-02-25T12:39:48.913711Z","shell.execute_reply.started":"2022-02-25T12:39:48.907171Z","shell.execute_reply":"2022-02-25T12:39:48.912759Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:39:52.521067Z","iopub.execute_input":"2022-02-25T12:39:52.521376Z","iopub.status.idle":"2022-02-25T12:40:02.949493Z","shell.execute_reply.started":"2022-02-25T12:39:52.521345Z","shell.execute_reply":"2022-02-25T12:40:02.948476Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6578aadc09a44722aeb2537ef6c18f38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1804505991134dac8d744c16ea212050"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8b561c9f8974df7aacea8fc281e52a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b45f40b6d0be48ae82cd42309dd917f4"}},"metadata":{}}]},{"cell_type":"code","source":"#import tensorflow.config\n#tensorflow.config.experimental.set_visible_devices([], \"GPU\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:07:43.463027Z","iopub.execute_input":"2022-02-18T16:07:43.463293Z","iopub.status.idle":"2022-02-18T16:07:43.466366Z","shell.execute_reply.started":"2022-02-18T16:07:43.463265Z","shell.execute_reply":"2022-02-18T16:07:43.465714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from feedback2021.clean_train_data import mk_clean_train_data\nif just_test:\n    cleaned_train = mk_clean_train_data(num_records=100) #cleaned_train[:100]\nelse:\n    cleaned_train = mk_clean_train_data()\n\ndata = create_train_dataset_pd(cleaned_train_df=cleaned_train, \n                               tokenizer=tokenizer, \n                               verbose=True)\n\nfrom sklearn.model_selection import train_test_split\n\ndata = dict(zip(['train','test'], \n                train_test_split(data,\n                                 test_size=0.1, \n                                 shuffle=True, \n                                 random_state=42)))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:40:03.403145Z","iopub.execute_input":"2022-02-25T12:40:03.403433Z","iopub.status.idle":"2022-02-25T12:40:14.601704Z","shell.execute_reply.started":"2022-02-25T12:40:03.403400Z","shell.execute_reply":"2022-02-25T12:40:14.600684Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"reformat train data:   0%|          | 0/144293 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad4858eafe5c47f7840b17e01d135f46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"reading essays:   0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfd559be31d546d5a76394196e6c7284"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"searching for disaligned labels:   0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"929df162519d479aa7063beb0475c8df"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    word mapping:   0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d81dfeff62c34f4d9b9bcc32c3d408ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adding token rle:   0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d76e6c451394accaa7198bc4c480f30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":" adding label:   0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"215bef1a5bb4413497c1b07b0dcb40cb"}},"metadata":{}}]},{"cell_type":"code","source":"data['train'].head(), data['test'].head()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:40:33.107165Z","iopub.execute_input":"2022-02-25T12:40:33.107452Z","iopub.status.idle":"2022-02-25T12:40:33.476060Z","shell.execute_reply.started":"2022-02-25T12:40:33.107422Z","shell.execute_reply":"2022-02-25T12:40:33.475208Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(                                                           text  \\\n id                                                                \n 004EA492DA04  Dear Principal,\\n\\nI think that making someone...   \n 0083B82A9C6F  Dear Principal,\\n\\nI believe that the best pol...   \n 015BB7DA58EE  Have you ever been bored in a class room such ...   \n 00885C23A764  The idea of having cars that can do the drivin...   \n 019B73E2A599  Hey you! Do you need some advice about somethi...   \n \n                                                        rle_char  \\\n id                                                                \n 004EA492DA04  [(2, 17, 100), (4, 102, 245), (3, 512, 611), (...   \n 0083B82A9C6F  [(2, 17, 74), (3, 77, 354), (6, 357, 486), (7,...   \n 015BB7DA58EE  [(1, 0, 328), (2, 330, 473), (4, 476, 540), (3...   \n 00885C23A764  [(1, 0, 396), (2, 398, 565), (3, 568, 1688), (...   \n 019B73E2A599  [(1, 0, 155), (2, 157, 284), (4, 293, 312), (4...   \n \n                                                       input_ids  \\\n id                                                                \n 004EA492DA04  [23314, 13619, 6, 50118, 50118, 100, 206, 14, ...   \n 0083B82A9C6F  [23314, 13619, 6, 50118, 50118, 100, 679, 14, ...   \n 015BB7DA58EE  [17781, 47, 655, 57, 23809, 11, 10, 1380, 929,...   \n 00885C23A764  [133, 1114, 9, 519, 1677, 14, 64, 109, 5, 1428...   \n 019B73E2A599  [13368, 47, 328, 1832, 47, 240, 103, 2949, 59,...   \n \n                                                  offset_mapping  \\\n id                                                                \n 004EA492DA04  [(0, 4), (5, 14), (14, 15), (15, 16), (16, 17)...   \n 0083B82A9C6F  [(0, 4), (5, 14), (14, 15), (15, 16), (16, 17)...   \n 015BB7DA58EE  [(0, 4), (5, 8), (9, 13), (14, 18), (19, 24), ...   \n 00885C23A764  [(0, 3), (4, 8), (9, 11), (12, 18), (19, 23), ...   \n 019B73E2A599  [(0, 3), (4, 7), (7, 8), (9, 11), (12, 15), (1...   \n \n                                                    word_mapping  \\\n id                                                                \n 004EA492DA04  [(0, 4), (5, 15), (17, 18), (19, 24), (25, 29)...   \n 0083B82A9C6F  [(0, 4), (5, 15), (17, 18), (19, 26), (27, 31)...   \n 015BB7DA58EE  [(0, 4), (5, 8), (9, 13), (14, 18), (19, 24), ...   \n 00885C23A764  [(0, 3), (4, 8), (9, 11), (12, 18), (19, 23), ...   \n 019B73E2A599  [(0, 3), (4, 8), (9, 11), (12, 15), (16, 20), ...   \n \n                                                       rle_token  \\\n id                                                                \n 004EA492DA04  [(2, 5, 21), (4, 22, 50), (3, 105, 129), (4, 1...   \n 0083B82A9C6F  [(2, 5, 16), (3, 19, 81), (6, 84, 110), (7, 11...   \n 015BB7DA58EE  [(1, 0, 78), (2, 79, 103), (4, 106, 120), (3, ...   \n 00885C23A764  [(1, 0, 81), (2, 82, 113), (3, 116, 339), (4, ...   \n 019B73E2A599  [(1, 0, 34), (2, 35, 58), (4, 59, 63), (4, 64,...   \n \n                                                          labels  \n id                                                               \n 004EA492DA04  [0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n 0083B82A9C6F  [0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n 015BB7DA58EE  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n 00885C23A764  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n 019B73E2A599  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ,\n                                                            text  \\\n id                                                                \n 017FB36B3B0C  You just finished a long, hard day at school. ...   \n 00E3F86E3E6A  dear principle,\\n\\nI believe that we do not ne...   \n 014BF1790D44  TEACHER_NAME\\n\\nSCHOOL_NAME\\n\\nDes Plaines, Il...   \n 00BD97EA4041  Should computers read the emotional expression...   \n 00B2AE3212D2  .\\n\\nSenator i believe the electoral college s...   \n \n                                                        rle_char  \\\n id                                                                \n 017FB36B3B0C  [(1, 0, 379), (2, 381, 457), (4, 458, 518), (4...   \n 00E3F86E3E6A  [(2, 17, 101), (4, 103, 204), (6, 206, 272), (...   \n 014BF1790D44  [(2, 95, 165), (4, 168, 382), (3, 385, 930), (...   \n 00BD97EA4041  [(1, 0, 74), (2, 76, 131), (4, 133, 270), (3, ...   \n 00B2AE3212D2  [(2, 3, 164), (3, 166, 664), (3, 668, 784), (4...   \n \n                                                       input_ids  \\\n id                                                                \n 017FB36B3B0C  [1185, 95, 1550, 10, 251, 6, 543, 183, 23, 334...   \n 00E3F86E3E6A  [417, 4352, 9322, 6, 50118, 50118, 100, 679, 1...   \n 014BF1790D44  [6433, 11083, 2076, 1215, 48307, 50118, 50118,...   \n 00BD97EA4041  [31231, 7796, 1166, 5, 3722, 17528, 9, 521, 11...   \n 00B2AE3212D2  [4, 50118, 50118, 36328, 939, 679, 5, 7169, 15...   \n \n                                                  offset_mapping  \\\n id                                                                \n 017FB36B3B0C  [(0, 3), (4, 8), (9, 17), (18, 19), (20, 24), ...   \n 00E3F86E3E6A  [(0, 1), (1, 4), (5, 14), (14, 15), (15, 16), ...   \n 014BF1790D44  [(0, 2), (2, 5), (5, 7), (7, 8), (8, 12), (12,...   \n 00BD97EA4041  [(0, 6), (7, 16), (17, 21), (22, 25), (26, 35)...   \n 00B2AE3212D2  [(0, 1), (1, 2), (2, 3), (3, 10), (11, 12), (1...   \n \n                                                    word_mapping  \\\n id                                                                \n 017FB36B3B0C  [(0, 3), (4, 8), (9, 17), (18, 19), (20, 25), ...   \n 00E3F86E3E6A  [(0, 4), (5, 15), (17, 18), (19, 26), (27, 31)...   \n 014BF1790D44  [(0, 12), (14, 25), (27, 30), (31, 39), (40, 4...   \n 00BD97EA4041  [(0, 6), (7, 16), (17, 21), (22, 25), (26, 35)...   \n 00B2AE3212D2  [(0, 1), (3, 10), (11, 12), (13, 20), (21, 24)...   \n \n                                                       rle_token  \\\n id                                                                \n 017FB36B3B0C  [(1, 0, 84), (2, 85, 98), (4, 98, 109), (4, 11...   \n 00E3F86E3E6A  [(2, 6, 21), (4, 22, 41), (6, 42, 55), (7, 55,...   \n 014BF1790D44  [(2, 39, 55), (4, 58, 103), (3, 106, 231), (4,...   \n 00BD97EA4041  [(1, 0, 11), (2, 12, 23), (4, 24, 52), (3, 55,...   \n 00B2AE3212D2  [(2, 3, 30), (3, 31, 134), (3, 137, 162), (4, ...   \n \n                                                          labels  \n id                                                               \n 017FB36B3B0C  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n 00E3F86E3E6A  [0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n 014BF1790D44  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n 00BD97EA4041  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, ...  \n 00B2AE3212D2  [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  )"},"metadata":{}}]},{"cell_type":"code","source":"if LOG_TO_WANDB and save_to_wandb:\n    data.remove_columns([#'input_ids', \n                         #'rle_token', \n                         'labels', \n                         #'offset_mapping'\n    ]).save_to_disk('data')\n\n    artifact = wandb.Artifact('data', description='train test split', type='dataset')\n    artifact.add_dir('data')\n    wandb.log_artifact(artifact)\n    !ls -sRh data\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if  not isinstance(data.column_names, dict):\n#     data = data.train_test_split(test_size=0.1, shuffle=True, seed=42)\n    \n# chunk_data = to_chunk_data(data, \n#                            chunk_len=max_length, \n#                            stride=stride, \n#                            prefix=[tokenizer.bos_token_id],\n#                            postfix=[tokenizer.eos_token_id])\n# chunk_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def chop_up(data, tokenizer, max_length, stride):\n    examples = {k: list(data[k]) for k in data.columns}\n    examples['labels'] = list(data['labels'])\n    examples['id'] = list(data.index.values)\n    f = chunk_mapping(chunk_len=max_length, \n                      stride=stride, \n                      prefix=[tokenizer.bos_token_id],\n                      postfix=[tokenizer.eos_token_id])\n    return f(examples)\n\ndef to_records(data):\n    return [dict(zip(data.keys(), rec))  for rec in zip(*data.values())]\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:40:39.465957Z","iopub.execute_input":"2022-02-25T12:40:39.466242Z","iopub.status.idle":"2022-02-25T12:40:39.473742Z","shell.execute_reply.started":"2022-02-25T12:40:39.466213Z","shell.execute_reply":"2022-02-25T12:40:39.472865Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"chunk_data = {\n    k: chop_up(v, tokenizer, max_length=max_length, stride=stride)\n    for k,v in data.items()\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:40:43.359472Z","iopub.execute_input":"2022-02-25T12:40:43.359908Z","iopub.status.idle":"2022-02-25T12:40:43.368166Z","shell.execute_reply.started":"2022-02-25T12:40:43.359877Z","shell.execute_reply":"2022-02-25T12:40:43.367400Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import yaml\nprint(yaml.dump(\n    {\n        k: {\n            k0: f'size={len(v0[0])}, type={type(v0[0][0]).__name__}' \n            if isinstance(v0[0], list) else v0[0] \n            for k0, v0 in v.items()\n        } \n     for k,v in chunk_data.items()\n    }\n))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:40:45.467364Z","iopub.execute_input":"2022-02-25T12:40:45.467764Z","iopub.status.idle":"2022-02-25T12:40:45.473988Z","shell.execute_reply.started":"2022-02-25T12:40:45.467734Z","shell.execute_reply":"2022-02-25T12:40:45.473444Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"test:\n  input_ids: size=128, type=int\n  labels: size=128, type=int\n  offset: 0\n  text_id: 017FB36B3B0C\ntrain:\n  input_ids: size=128, type=int\n  labels: size=128, type=int\n  offset: 0\n  text_id: 004EA492DA04\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-18T20:40:22.999032Z","iopub.execute_input":"2022-02-18T20:40:22.999325Z","iopub.status.idle":"2022-02-18T20:40:23.005487Z","shell.execute_reply.started":"2022-02-18T20:40:22.999294Z","shell.execute_reply":"2022-02-18T20:40:23.004696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if not has_name(data, 'rle_word'):\n#     from feedback2021.helper import Block\n#     def add_rle_word2(data):\n#         # assert has_name(data, 'offset_mapping'), 'add input_ids first!'\n#         if not has_name(data,'word_mapping'):\n#             data = add_word_mapping(data)\n#         return data.map(lambda x: {'rle_word': [Block(t).inv_map(x['word_mapping']) \n#                                                  for t in x['rle_char']]},\n#                             desc='rle to word coordinates')\n#     data = add_rle_word2(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from collections import defaultdict\n# import numpy as np\n# word_counts = defaultdict(list)\n# from  datasets import concatenate_datasets\n# all_data = concatenate_datasets(list(data.values()))\n# for x in all_data['rle_word']:\n#     for cls_id, start, end  in x:\n#         word_counts[id2label[cls_id]].append(end-start)\n\n# for k, v in word_counts.items():\n#     plt.hist(v,bins=np.arange(1,max(v)+1)-0.5)\n#     plt.title(f'{k} min:{min(v)} max: {max(v)}, 2%,5%: {np.percentile(v,[2,5])}')\n#     plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model and Training","metadata":{}},{"cell_type":"code","source":"# chunk_data = chunk_data.rename_column('labels','label')\n# DataLoader?","metadata":{"execution":{"iopub.status.busy":"2022-02-18T18:13:53.277895Z","iopub.execute_input":"2022-02-18T18:13:53.278471Z","iopub.status.idle":"2022-02-18T18:13:53.338729Z","shell.execute_reply.started":"2022-02-18T18:13:53.278431Z","shell.execute_reply":"2022-02-18T18:13:53.337945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# def mk_collate_fn(tokenizer, max_length=512):\n#     def collate_fn(features):\n        \n#         batch ={key: np.array([f[key]+[t]*(max_length-len(f[key])) for f in features], dtype=np.int32)\n#                 for t,key in zip([tokenizer.pad_token_id,-100],['input_ids','labels'])}\n#         return batch\n#     return collate_fn\n# from torch.utils.data import DataLoader\n\n# train_dataset = DataLoader(chunk_data_list, shuffle=True, #.remove_columns(['offset', 'text_id']), \n#                            batch_size=16,\n#                            collate_fn=mk_collate_fn(tokenizer, 512))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T19:05:29.59293Z","iopub.execute_input":"2022-02-18T19:05:29.593448Z","iopub.status.idle":"2022-02-18T19:05:29.602207Z","shell.execute_reply.started":"2022-02-18T19:05:29.59341Z","shell.execute_reply":"2022-02-18T19:05:29.601535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport tensorflow.data as tfdata\n#ds=\nimport numpy as np\n\ndef mk_collate_fn(tokenizer, max_length=512):\n    def collate_fn(features):\n        \n        batch = features.copy()\n        for t, key in zip([tokenizer.pad_token_id,-100], ['input_ids','labels']):\n            batch[key] = np.array([f+[t]*(max_length-len(f)) for f in batch[key]], \n                                  dtype=np.int32)\n        return batch\n    \n    return collate_fn\n\n    \ncollate_fn = mk_collate_fn(tokenizer, max_length)\n\nds ={k: tfdata.Dataset.from_tensor_slices(collate_fn(v)) for k,v in chunk_data.items()}\n#(chunk_data_list)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:40:50.831932Z","iopub.execute_input":"2022-02-25T12:40:50.832316Z","iopub.status.idle":"2022-02-25T12:40:50.860775Z","shell.execute_reply.started":"2022-02-25T12:40:50.832277Z","shell.execute_reply":"2022-02-25T12:40:50.859726Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"CPU times: user 20.6 ms, sys: 822 µs, total: 21.4 ms\nWall time: 20.6 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 32 if kaggle_init.is_tpu_available() else 2\ndummy_data = tfdata.Dataset.from_tensor_slices(\n    {\n        'input_ids': np.zeros((batch_size, max_length), dtype=np.int32),\n        'labels': -100*np.ones((batch_size, max_length), dtype=np.int32),\n        'text_id': np.array(['0'*11]*batch_size),\n        'offset': np.array(np.zeros(batch_size, dtype=np.int32))\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:40:53.662376Z","iopub.execute_input":"2022-02-25T12:40:53.662897Z","iopub.status.idle":"2022-02-25T12:40:53.671796Z","shell.execute_reply.started":"2022-02-25T12:40:53.662859Z","shell.execute_reply":"2022-02-25T12:40:53.671184Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"dummy_data","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:56:43.980698Z","iopub.execute_input":"2022-02-24T07:56:43.981196Z","iopub.status.idle":"2022-02-24T07:56:43.990582Z","shell.execute_reply.started":"2022-02-24T07:56:43.981126Z","shell.execute_reply":"2022-02-24T07:56:43.989179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jax\njax.devices()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:41:11.151601Z","iopub.execute_input":"2022-02-25T12:41:11.151862Z","iopub.status.idle":"2022-02-25T12:41:11.172821Z","shell.execute_reply.started":"2022-02-25T12:41:11.151834Z","shell.execute_reply":"2022-02-25T12:41:11.172212Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[CpuDevice(id=0), CpuDevice(id=1)]"},"metadata":{}}]},{"cell_type":"code","source":"def subset(x):\n    return {k: x[k] for k in ['input_ids', 'labels', 'offset']}\n\ntrain_dataset = (ds['train'].\n                 map(subset).\n                 repeat().\n                 shuffle(4096).\n                 batch(batch_size=batch_size).\n                 batch(batch_size=jax.device_count()).as_numpy_iterator())\n\ntest_dataset = (ds['test'].\n                concatenate(dummy_data.repeat(jax.device_count())).\n                map(subset).batch(batch_size=batch_size, drop_remainder=True).\n                batch(batch_size=jax.device_count()))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:41:13.680819Z","iopub.execute_input":"2022-02-25T12:41:13.681165Z","iopub.status.idle":"2022-02-25T12:41:13.746694Z","shell.execute_reply.started":"2022-02-25T12:41:13.681129Z","shell.execute_reply":"2022-02-25T12:41:13.746030Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"len(ds['test']), len(ds['train'])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:24:53.701058Z","iopub.execute_input":"2022-02-25T12:24:53.701983Z","iopub.status.idle":"2022-02-25T12:24:53.707197Z","shell.execute_reply.started":"2022-02-25T12:24:53.701939Z","shell.execute_reply":"2022-02-25T12:24:53.706621Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(41, 393)"},"metadata":{}}]},{"cell_type":"code","source":"class Metric:\n    def __init__(self):\n        self.reset()\n    def reset(self):\n        self._value = 0\n        self._n = 0\n    def update(self,v):\n        self._n += 1\n        self._value += v\n    def value(self):\n        return self._value/self._n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T12:51:18.38627Z","iopub.execute_input":"2022-02-21T12:51:18.386819Z","iopub.status.idle":"2022-02-21T12:51:18.396472Z","shell.execute_reply.started":"2022-02-21T12:51:18.386763Z","shell.execute_reply":"2022-02-21T12:51:18.394711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{k: f'shape={v.shape}, dtype={v.dtype}' for k,v in next(iter(train_dataset)).items()}","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:56:58.010235Z","iopub.execute_input":"2022-02-24T07:56:58.010685Z","iopub.status.idle":"2022-02-24T07:56:58.098718Z","shell.execute_reply.started":"2022-02-24T07:56:58.010652Z","shell.execute_reply":"2022-02-24T07:56:58.098066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"local_device_count = jax.device_count()\nlocal_device_count","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:57:00.978749Z","iopub.execute_input":"2022-02-24T07:57:00.979077Z","iopub.status.idle":"2022-02-24T07:57:00.985938Z","shell.execute_reply.started":"2022-02-24T07:57:00.97904Z","shell.execute_reply":"2022-02-24T07:57:00.984821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import haiku as hk\nimport jax.numpy as jnp\nimport optax\nimport functools\nfrom typing import Any, Mapping\n\ndef mk_loss_fn(config):\n    \n    def loss_fn(logits, data):\n    #                params,\n    #                rng,\n    #                data: Mapping[str, jnp.ndarray],\n    #                is_training: bool = True) -> jnp.ndarray:\n        \"\"\"Compute the loss on data wrt params.\"\"\"\n\n\n    #     logits = forward_fn(params, rng, data, is_training)\n        targets = jax.nn.one_hot(data['labels'], len(config['id2label']))\n        assert logits.shape == targets.shape\n\n        mask = jnp.not_equal(data['input_ids'], config['pad_token_id'])\n        mask = mask * jnp.greater_equal(data['labels'], 0)\n        loss = -jnp.sum(targets * jax.nn.log_softmax(logits), axis=-1)\n        loss = jnp.sum(loss * mask) / jnp.sum(mask)\n\n        return loss\n    \n    return loss_fn\n\nclass Updater:\n    \"\"\"A stateless abstraction around an init_fn/update_fn pair.\n    This extracts some common boilerplate from the training loop.\n    \"\"\"\n\n    def __init__(self, \n                 net, \n                 loss_fn,\n                 optimizer: optax.GradientTransformation):\n        \n        self._net_init = net.init\n        self._loss_fn = lambda params,rng, data: loss_fn(net.apply(params, rng, data, is_training=True), data)\n        self._opt = optimizer\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def init(self, rng, data, pretrained_params=None):\n        \"\"\"Initializes state of the updater.\"\"\"\n        out_rng, init_rng = jax.random.split(rng)\n        params = self._net_init(init_rng, data)\n        if pretrained_params is not None:\n            params = hk.data_structures.merge(params, pretrained_params)\n        #params = hk.data_structures.map(lambda x: jnp.stack([x]*local_device_count), params)\n        opt_state = self._opt.init(params)\n        # rng = jax.random.PRNGKey(FLAGS.train_init_random_seed)\n        #rng = jnp.broadcast_to(rng, (local_device_count,) + rng.shape)\n        out = dict(\n            step=np.array(0),\n            rng=out_rng,\n            opt_state=opt_state,\n            params=params,\n            loss=np.array(0),\n        )\n        return out\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def update(self, state: Mapping[str, Any], data: Mapping[str, jnp.ndarray]):\n        \"\"\"Updates the state using some data and returns metrics.\"\"\"\n        rng, new_rng = jax.random.split(state['rng'])\n        params = state['params']\n        loss, grads = jax.value_and_grad(self._loss_fn)(params, rng, data)\n\n        if compute_on_tpu:\n            grads = jax.lax.pmean(grads, 'i')\n\n\n        updates, opt_state = self._opt.update(grads, state['opt_state'])\n        params = optax.apply_updates(params, updates)\n\n        new_state = {\n            'step': state['step'] + 1,\n            'rng': new_rng,\n            'opt_state': opt_state,\n            'params': params,\n            'loss': state['loss'] + loss\n        }\n\n        return new_state ","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:41:18.498996Z","iopub.execute_input":"2022-02-25T12:41:18.499302Z","iopub.status.idle":"2022-02-25T12:41:18.519147Z","shell.execute_reply.started":"2022-02-25T12:41:18.499268Z","shell.execute_reply":"2022-02-25T12:41:18.518170Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def get_predictions(net, loss_fn, state, test_ds):\n\n    def run_net(state, data):\n        logits = net.apply(state['params'], state['rng'], data, is_training=False)\n        loss = loss_fn(logits, data)\n        pred = jax.numpy.argmax(logits, axis=-1)\n        state['loss'] = state['loss'] + loss\n        return pred, state\n        \n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    predictions = []\n    for batch in test_ds.as_numpy_iterator():\n        pred, state = run_net(state, batch)\n        predictions.append(pred)\n        \n    predictions = [ pred \n                    for preds in jax.device_get(predictions) \n                    for pred in preds.reshape((-1,) + preds.shape[2:]) ]\n    return predictions, state\n\n\n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:41:23.142486Z","iopub.execute_input":"2022-02-25T12:41:23.143292Z","iopub.status.idle":"2022-02-25T12:41:23.151579Z","shell.execute_reply.started":"2022-02-25T12:41:23.143250Z","shell.execute_reply":"2022-02-25T12:41:23.150553Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class Log:\n    def __init__(self, step=0):\n        self.step = step\n        self.start_time = self.prev_time = time.time()\n        \n    def update(self, state):\n        step = int(state['step'][0])\n        step_delta, self.step = step-self.step, step\n        \n        c_time = time.time()\n        time_delta, self.prev_time = c_time - self.prev_time, c_time\n        \n        loss = float(state['loss'].mean())/step_delta\n        state['loss'] = 0*state['loss']\n        \n        return {'step': self.step,\n                'loss': loss,\n                'elapsed_time': time_delta,\n                'total_time':   c_time-self.start_time,\n                'iter_per_sec': time_delta/max(1,step_delta),\n                'sec_per_iter': step_delta/max(1,time_delta),\n               }\n\ndef format_log(log):\n    return \"iteration: {step:<5}, loss: {loss:.4f}, elapsed_time:{elapsed_time:.2f}\".format(**log)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:41:26.295700Z","iopub.execute_input":"2022-02-25T12:41:26.295984Z","iopub.status.idle":"2022-02-25T12:41:26.305409Z","shell.execute_reply.started":"2022-02-25T12:41:26.295954Z","shell.execute_reply":"2022-02-25T12:41:26.304385Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import logging\nimport time\nfrom transformers import AutoConfig\nfrom feedback2021.hk_roberta import (build_forward_fn, \n                                     lm_loss_fn, \n                                     # GradientUpdater, \n                                     hk, optax, functools, Mapping, jnp, jax)\n\n## global variables\n# batch_size = 16  # Train batch size per core\ntotal_batch_size = batch_size*jax.device_count()\nlearning_rate = 2.5e-5*(total_batch_size/32) # Max learning-rate\ngrad_clip_value = 0.15  # Gradient norm clip value\n\ncheckpoint_dir = '/jax-transformer'  # Directory to store checkpoints\nif just_test:\n    LOG_EVERY = 2\n    MAX_STEPS = 4\nelse:\n    LOG_EVERY = 250\n    MAX_STEPS = (3*len(ds['train']))//total_batch_size\n\nconfig = AutoConfig.from_pretrained(model_checkpoint, #'distilroberta-base', \n                                    label2id=label2id, \n                                    id2label=id2label).to_dict()\ntranslation = hk_roberta.weight_name_translation(config=config, prefix='roberta')\npretrained_params = hk_roberta.load_hf_pytorch_weights(model_checkpoint, #'distilroberta-base', \n                                                       translation)\n\nlogging.info = print\nlogging.info('Starting...')\n\nforward_fn = build_forward_fn(config)\n\nforward_fn = hk.transform(forward_fn)\n\n#loss_fn = functools.partial(lm_loss_fn, forward_fn.apply, config)\nloss_fn = mk_loss_fn(config)\n\nlr_schedule=optax.warmup_cosine_decay_schedule(init_value=0, \n                                               peak_value=1, \n                                               warmup_steps=min(100, MAX_STEPS//6), \n                                               decay_steps=MAX_STEPS-min(100,MAX_STEPS//6), \n                                               end_value=1e-4)\n\noptimizer = optax.chain(\n        optax.clip_by_global_norm(grad_clip_value),\n        optax.adam(learning_rate, b1=0.9, b2=0.99),\n        optax.scale_by_schedule(lr_schedule),\n    )\n\nupdater = Updater(forward_fn, loss_fn, optimizer)\n\n# Initialize parameters.\nlogging.info('Initializing parameters...')\nrng = jax.random.PRNGKey(428)\ndata = next(iter(train_dataset))\nstate = updater.init(rng, #jnp.broadcast_to(rng, (local_device_count,) + rng.shape), \n                     {k:v[0] for k,v in data.items()},\n                     pretrained_params=pretrained_params)\nif compute_on_tpu:\n    state = jax.device_put_replicated(state, jax.devices())\n    update = jax.pmap(updater.update, axis_name='i')\nelse:\n    update = updater.update\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:41:31.034603Z","iopub.execute_input":"2022-02-25T12:41:31.035490Z","iopub.status.idle":"2022-02-25T12:42:01.512926Z","shell.execute_reply.started":"2022-02-25T12:41:31.035429Z","shell.execute_reply":"2022-02-25T12:42:01.510848Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/316M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0300c2abb134430399a1bc9c337a9a9a"}},"metadata":{}},{"name":"stdout","text":"unused torch weights: roberta.embeddings.token_type_embeddings.weight,\nroberta.pooler.dense.weight, roberta.pooler.dense.bias, lm_head.bias,\nlm_head.dense.weight, lm_head.dense.bias, lm_head.layer_norm.weight,\nlm_head.layer_norm.bias, lm_head.decoder.weight\nStarting...\nInitializing parameters...\n","output_type":"stream"}]},{"cell_type":"code","source":"logging.info('Starting train loop...')\ntrain_iter = iter(train_dataset)\nlog = Log()\nfor step  in range(MAX_STEPS): #enumerate(train_dataset):\n        data = next(train_iter)\n        state = update(state, data)\n        # We use JAX runahead to mask data preprocessing and JAX dispatch overheads.\n        # Using values from state/metrics too often will block the runahead and can\n        # cause these overheads to become more prominent.\n        if step % LOG_EVERY == 0 or (step+1)== MAX_STEPS:\n            last_log=log.update(state)\n            predictions, state = get_predictions(forward_fn, loss_fn, state, test_dataset)\n            last_log['test_loss'] = float(state['loss'].mean())\n            state['loss'] = 0*state['loss']\n            logging.info(last_log)\n\n# logging.info(last_log)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:42:01.514940Z","iopub.execute_input":"2022-02-25T12:42:01.515184Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Starting train loop...\n{'step': 1, 'loss': 2.0039656162261963, 'elapsed_time': 66.15073871612549, 'total_time': 66.15073871612549, 'iter_per_sec': 66.15073871612549, 'sec_per_iter': 0.015116989158523655, 'test_loss': nan}\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = get_predictions(forward_fn, loss_fn, state=state, test_ds=test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:35:38.784742Z","iopub.execute_input":"2022-02-25T12:35:38.785273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# next(test_dataset.as_numpy_iterator())\n#next(iter(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:35:26.825227Z","iopub.execute_input":"2022-02-25T12:35:26.825509Z","iopub.status.idle":"2022-02-25T12:35:26.879572Z","shell.execute_reply.started":"2022-02-25T12:35:26.825481Z","shell.execute_reply":"2022-02-25T12:35:26.878887Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'input_ids': array([[[    0,  1185,    95,  1550,    10,   251,     6,   543,   183,\n             23,   334,     4,   370,   214, 17067,     6,     8,    47,\n             64,  6254,   489,   110,  2473,   490,     4,   635,     6,\n            110,  9322,    34,  1552,    47,     7,   185,    41,  8935,\n          13249,   710, 32127,  1940,     6,     8,    47,    33,     7,\n           1930,   277,  1946,    23,   334,     4,   572,   334,    34,\n           1249,     6,    38,    95,   236,     7,   120,   184,     8,\n           4477,    11,   127,  3137, 24382,  3267,     4,    85,    74,\n             28,   182, 38279,   114,    38,    56,     7,  1930,   277,\n          17322,  1946,    23,   334,     4,    38, 11967,     7,  7980,\n             70,   521,     7,  4064,    11,    23,   513,    65,  1940,\n            142,   521,   240,     7,  1532,     7,  1760,    15,    49,\n            308,  3168,     6,    51,   189,    33,    10,   182,  3610,\n            301,    23,   184,     6,     8,    24,  3639, 10495,  3992,\n             15,     2],\n         [    0,     4, 50118, 50118, 10993,     6,   209,   664,  3362,\n            531,  1532,     7,  1760,    15,    49,   308,  3168,     4,\n             85,    18,    10,  2139,   301,  6707,    13,    82,     7,\n            213,    13,    99,    51,   465,    10, 25896,     7,     4,\n           1806,   218,    75,    95,  2067,    13,    49, 36365,     7,\n             28,  1552,     7,   109,     4,   520,    47,   555,    41,\n           4194,     6,    47,    33,     7,   146,  2390,    13,  2512,\n              4,  4130,     6,    77,  1159,  1760,    15,    49,   308,\n           3168,    51,   555,    55,  4009,     4,  6983,    32,    45,\n           6908,   236,     7,   109,    41,  1940,   114,    24,    18,\n            402,    51,   399,    75,   190,   236,     7,   109,    11,\n              5,    78,   317,     4,   520,    10,  4607,  2434,    62,\n             13,    41,  8935, 13249,   710, 32127,  1235,     6,    24,\n           3374,   169,    55, 18260,    13,   106,     4, 24817,     6,\n             24,     2]],\n \n        [[    0,   619,    55,  2149,     4,   520,    10,  7044,   473,\n             99,    51,   236,     6,    51,   216,    14,    51, 17021,\n           1235,    11,    10,   169,    51,   770,     7,     4,    85,\n             18,  2770,    13,    10,  4607,     7,   619,  2149,   142,\n             24,    40,   146,   106,   236,     7,   109,    55,  2149,\n           2163,    11,     5,   499,     4,   407,    14,    16,   596,\n            521,   197, 11427,  1235,    15,  3501,    15,    49,   308,\n           3168,     4, 50118, 50118, 32703,     6,   209,    82,   189,\n             33,   350,  3610,     9,    10,   184,   301, 50141,   560,\n            109,    41,  8935, 13249,   710, 32127,  1940,     4,  1216,\n           1159,    33,    10,   284,    23,   184,     6,     8,    24,\n             18,  8544,   114,    52,   492,   106,   410,    86,     7,\n           1930,    86,    19,   106,     4,    20,  1159,  6254,   120,\n              7,   192,   106,    19,     5,  1280,     9,    86,    51,\n           1930,     2],\n         [    0,   396,     5,  8935, 13249,   710, 32127,  1940,     4,\n             85,    16,   505,    23,    42,  1046,    13,     5, 10226,\n              7,  1119,   670,  3554,    19,    49,  1232,     4,    38,\n            923,     5,  2175,    38,    33,    19,   127,   284,     6,\n             53,    77,    38,   437,  3610,    19,   334,    38,   393,\n            192,   106,     4,  4130,     6,   209,  1159,   351,    75,\n             33,   615,    86,     7,  1930,    19,    49,   964,     4,\n            370,   393,   216,   114,    49,  8935, 13249,   710, 32127,\n           1713,    34,    49,   964,    11,    24,     6,     8,   114,\n             47,  1654,   106,     7,  1962,    65,     6,    24,    18,\n           3752,    14,    51,    74,     4,   497,   209,  4864,     6,\n              5,  1159,   236,     7,   146,  6180,     8,  2254,    49,\n           2719,     4,   318,    52,   146,   106,  1095,    23,   334,\n              6,    24,   189,    28,   543,     7,   109,    14,     4,\n          24817,     2]]], dtype=int32),\n 'labels': array([[[-100,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n             1,    1,    1,    1,    1,    0,    2,    2,    2,    2,\n             2,    2,    2,    2,    2,    2,    2,    2,    2,    4,\n             4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n             0,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n             0,    0,    4,    4,    4,    4,    4, -100],\n         [-100,    0,    0,    0,    0,    0,    4,    4,    4,    4,\n             4,    4,    4,    4,    4,    4,    4,    0,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3, -100]],\n \n        [[-100,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    0,    0,    0,    0,    0,    4,\n             4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n             4,    4,    4,    4,    4,    4,    4,    4,    0,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3, -100],\n         [-100,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n             3,    3,    3,    3,    3,    3,    3, -100]]], dtype=int32),\n 'offset': array([[  0, 128],\n        [256, 384]], dtype=int32)}"},"metadata":{}}]},{"cell_type":"code","source":"len(pred), pred[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:50:54.188065Z","iopub.execute_input":"2022-02-24T08:50:54.188883Z","iopub.status.idle":"2022-02-24T08:50:54.195233Z","shell.execute_reply.started":"2022-02-24T08:50:54.188841Z","shell.execute_reply":"2022-02-24T08:50:54.19407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = hk.data_structures.map(lambda name,module,x: x[0], state['params'])\nimport pickle\nwith open('params.pkl','wb') as f:\n    pickle.dump(params, f)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T06:13:23.821943Z","iopub.execute_input":"2022-02-23T06:13:23.822508Z","iopub.status.idle":"2022-02-23T06:13:27.022087Z","shell.execute_reply.started":"2022-02-23T06:13:23.822465Z","shell.execute_reply":"2022-02-23T06:13:27.020853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-23T06:13:31.428136Z","iopub.execute_input":"2022-02-23T06:13:31.428826Z","iopub.status.idle":"2022-02-23T06:13:32.394128Z","shell.execute_reply.started":"2022-02-23T06:13:31.428764Z","shell.execute_reply":"2022-02-23T06:13:32.39248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_schedule=optax.warmup_cosine_decay_schedule(init_value=0, \n                                               peak_value=1, \n                                               warmup_steps=500, \n                                               decay_steps=8500, \n                                               end_value=1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:41:44.23837Z","iopub.execute_input":"2022-02-21T06:41:44.238975Z","iopub.status.idle":"2022-02-21T06:41:44.245739Z","shell.execute_reply.started":"2022-02-21T06:41:44.238926Z","shell.execute_reply":"2022-02-21T06:41:44.244518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jaxlib, jax\njaxlib.__version__, jax.__version__, hk.__version__","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:45:48.632171Z","iopub.execute_input":"2022-02-21T06:45:48.632588Z","iopub.status.idle":"2022-02-21T06:45:48.640181Z","shell.execute_reply.started":"2022-02-21T06:45:48.632543Z","shell.execute_reply":"2022-02-21T06:45:48.639215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt = np.arange(0,9000,10)\nlr = [lr_schedule(jnp.array([i])) for i in cnt]\nplt.plot(cnt, lr)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:41:48.464737Z","iopub.execute_input":"2022-02-21T06:41:48.465445Z","iopub.status.idle":"2022-02-21T06:42:26.896087Z","shell.execute_reply.started":"2022-02-21T06:41:48.465381Z","shell.execute_reply":"2022-02-21T06:42:26.893875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{'loss': 2.4778389930725098, 'step': 0.0, 'steps_per_sec': 13.779059174634387}\n{'loss': 1.3683964014053345, 'step': 500.0, 'steps_per_sec': 2.5767113856201855}\n{'loss': 1.6631159782409668, 'step': 1000.0, 'steps_per_sec': 2.57725389686341}\n{'loss': 1.3581798076629639, 'step': 1500.0, 'steps_per_sec': 2.5771785561488483}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jax.core.gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T18:59:27.862142Z","iopub.execute_input":"2022-02-18T18:59:27.862405Z","iopub.status.idle":"2022-02-18T18:59:29.421439Z","shell.execute_reply.started":"2022-02-18T18:59:27.862376Z","shell.execute_reply":"2022-02-18T18:59:29.420597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jax.numpy.array([1,1])\n#jax.device_get('gpu')\n#jax.devices('gpu')\n! nvcc --version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n# TRAINING HYPERPARAMS\neffective_batch_size = 32\nmax_steps = 4000\nlog_steps = 500\n#n_step_examples = 8*500\nbatch_size = 16\ngrad_accumulation = effective_batch_size//batch_size\nlearning_rate = 5e-5\nweight_decay = 0.01\nwarmup_ratio = 0.1\nn_epochs = 3\nmodel_name = model_checkpoint.split(\"/\")[-1]\ntraining_args = TrainingArguments(\n    f\"{model_name}-{task}\",\n    evaluation_strategy = \"steps\",\n    eval_steps = log_steps,\n    logging_strategy = \"steps\",\n    logging_steps = log_steps,\n    save_strategy = \"steps\",\n    save_steps = log_steps,\n    learning_rate = learning_rate,\n    per_device_train_batch_size = batch_size,\n    per_device_eval_batch_size = batch_size,\n    #num_train_epochs = n_epochs,\n    max_steps = max_steps,\n    weight_decay = weight_decay,\n    report_to = 'wandb', \n    gradient_accumulation_steps = grad_accumulation,\n    warmup_steps = int(1.5*(log_steps)),\n    # logging_steps = 100,\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    greater_is_better=True,\n)\n#training_args","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['test']=add_rle_word2(data['test'])\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=chunk_data[\"train\"].remove_columns(['offset', 'text_id']), #.select(range(100)),\n    eval_dataset=chunk_data[\"test\"].remove_columns(['offset', 'text_id']), #.select(range(100)),\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=mk_binary_metric(chunk_ds=chunk_data['test'],\n                                     orig_ds=data['test'])\n    #,\n    #                                 min_word_cnt=[0,10,5,10,3,10,6,6]), #.select(range(100))), \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.save_model(model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wandb.init()\nimport pickle\nfrom feedback2021.postprocess import mk_prediction_transform\nfor k,v in chunk_data.items():\n    predictions = trainer.predict(v.remove_columns(['offset', 'text_id']))\n    prediction_transform = mk_binary_prediction_transform(chunk_ds=v, orig_ds=data[k])\n    predictions = prediction_transform(predictions[0])\n    with open(f'{k}_predictions.pkl','wb') as f:\n        pickle.dump(predictions, f)\n    wandb.save(f'{k}_predictions.pkl','./','now')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! rm longformer-base-4096-token_classification/ -rf\n#!rm distilroberta-base-token_classification -rf\n! ls -sh distilroberta-base-1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# From this point on there is no need to gpu!","metadata":{"execution":{"iopub.execute_input":"2021-12-30T06:52:35.965148Z","iopub.status.busy":"2021-12-30T06:52:35.964896Z","iopub.status.idle":"2021-12-30T06:52:36.089436Z","shell.execute_reply":"2021-12-30T06:52:36.088549Z","shell.execute_reply.started":"2021-12-30T06:52:35.96512Z"}}},{"cell_type":"code","source":"prediction_file = wandb.restore('predictions.pkl', run_path='prvi/huggingface/d17yam8m')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_file_name = 'test_predictions.pkl' #if os.path.exists('test_predictions.pkl') else prediction_file.name\nwith open(prediction_file_name, 'rb') as f:\n    saved_predictions = pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chunk_ds, orig_ds = chunk_data['test'].to_dict(), data['test'].to_dict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter_prediction(prediction, min_word_cnt):\n    return [b for b in prediction if b[2]-b[1]>=min_word_cnt[b[0]]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport pandas as pd\nres = []\nfor mwc in tqdm(range(0,15)):\n#     transform_prediction = mk_prediction_transform(chunk_ds=chunk_ds,\n#                                                    orig_ds=orig_ds, min_word_cnt=mwc)\n#     predictions = transform_prediction(saved_predictions[0])\n    \n    scores = np.array([metric.score_example(y_true=y_true, \n                                            y_pred=filter_prediction(y_pred,mwc)) \n              for y_pred,y_true in zip(saved_predictions,orig_ds['rle_word'])]).sum(axis=0)\n    scores = [metric.f1(*score) for score in scores]\n    f1 = sum(scores)/len(scores)\n    scores = {id2label[i+1]:score for i,score in enumerate(scores)}\n    scores['f1'] = f1\n    scores['min_word_cnt']=mwc\n    res.append(scores)\n\npd.DataFrame(res).set_index('min_word_cnt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mwc =[0, 10, 6, 15, 6, 11, 9, 8]\n\nscores_ = np.array([metric.score_example(y_true=y_true, \n                                        y_pred=filter_prediction(y_pred,mwc)) \n              for y_pred,y_true in zip(saved_predictions,orig_ds['rle_word'])]).sum(axis=0)\nscores = [metric.f1(*score) for score in scores_]\nf1 = sum(scores)/len(scores)\nscores = {id2label[i+1]:score for i,score in enumerate(scores)}\nscores['f1'] = f1\n    \n# transform_prediction = mk_prediction_transform(chunk_ds=chunk_ds,\n#                                                 orig_ds=orig_ds, \n#                                                min_word_cnt=[0, 10, 6, 15, 6, 11, 9, 8])\n# predictions = transform_prediction(saved_predictions[0])\n# scores = np.array([metric.score_example(y_true=y_true, y_pred=y_pred) \n#               for y_true,y_pred in zip(predictions,orig_ds['pred_range'])]).sum(axis=0)\n# scores = [metric.f1(*score) for score in scores]\n# f1 = sum(scores)/len(scores)\n# scores = {id2label[i+1]:score for i,score in enumerate(scores)}\n# scores['f1'] = f1\nscores    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = [ sorted(pred, key=lambda x: x[1]) for pred in saved_predictions]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_result(i=20, orig_ds=data['test'],predictions=predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsaved_predictions[8],data['test'][8]['rle_token']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = [metric.score_example(y_true=y_true, y_pred=y_pred) for y_true,y_pred in zip(predictions,orig_ds['pred_range'])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[metric.f1(*x) for x in np.array(scores).sum(axis=0)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = np.argsort(np.array(scores)[:,:,1:].sum(axis=(1,2)))[::-1]\nidx[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}