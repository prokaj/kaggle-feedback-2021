{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_github = user_secrets.get_secret(\"github\")\n! rm -rf feedback2021\n! git clone https://{secret_github}@github.com/VilmosProkaj/feedback2021.git\n! pip install feedback2021/","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:42:09.881567Z","iopub.execute_input":"2022-03-05T18:42:09.881867Z","iopub.status.idle":"2022-03-05T18:42:35.879886Z","shell.execute_reply.started":"2022-03-05T18:42:09.881826Z","shell.execute_reply":"2022-03-05T18:42:35.878705Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'feedback2021'...\nremote: Enumerating objects: 221, done.\u001b[K\nremote: Counting objects: 100% (221/221), done.\u001b[K\nremote: Compressing objects: 100% (130/130), done.\u001b[K\nremote: Total 221 (delta 108), reused 167 (delta 54), pack-reused 0\u001b[K\nReceiving objects: 100% (221/221), 59.72 KiB | 2.39 MiB/s, done.\nResolving deltas: 100% (108/108), done.\nProcessing ./feedback2021\n\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from feedback2021==0.0.post1.dev31+g4acb08f) (3.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->feedback2021==0.0.post1.dev31+g4acb08f) (3.5.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->feedback2021==0.0.post1.dev31+g4acb08f) (4.1.1)\nBuilding wheels for collected packages: feedback2021\n  Building wheel for feedback2021 (PEP 517) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for feedback2021: filename=feedback2021-0.0.post1.dev31+g4acb08f-py3-none-any.whl size=23539 sha256=5b0b70983273e7c9190d72494db6bcb1b1f20cb131e54152df90f2a95cc64e62\n  Stored in directory: /tmp/pip-ephem-wheel-cache-x7e4t3o3/wheels/58/ad/18/0ce3edd06dac18258cb4965c488a42e46fa829de9c6aa2319e\nSuccessfully built feedback2021\nInstalling collected packages: feedback2021\nSuccessfully installed feedback2021-0.0.post1.dev31+g4acb08f\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install -U jax jaxlib dm_haiku optax\n#!pip install --upgrade pip\n# Installs the wheel compatible with CUDA 11 and cuDNN 8.2 or newer.\n# ! pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html  # Note: wheels only available on linux.\n## !pip install --upgrade jax jaxlib==0.3.0+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n#! pip install dm_haiku","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:42:37.303731Z","iopub.execute_input":"2022-03-05T18:42:37.304342Z","iopub.status.idle":"2022-03-05T18:42:45.644786Z","shell.execute_reply.started":"2022-03-05T18:42:37.304284Z","shell.execute_reply":"2022-03-05T18:42:45.643940Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: jax in /opt/conda/lib/python3.7/site-packages (0.3.1)\nRequirement already satisfied: jaxlib in /opt/conda/lib/python3.7/site-packages (0.3.0)\nRequirement already satisfied: dm_haiku in /opt/conda/lib/python3.7/site-packages (0.0.6)\nRequirement already satisfied: optax in /opt/conda/lib/python3.7/site-packages (0.1.1)\nRequirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from jax) (1.7.1)\nRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.7/site-packages (from jax) (1.19.5)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.7/site-packages (from jax) (3.3.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from jax) (4.1.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from jax) (0.12.0)\nRequirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/conda/lib/python3.7/site-packages (from jaxlib) (1.12)\nRequirement already satisfied: jmp>=0.0.2 in /opt/conda/lib/python3.7/site-packages (from dm_haiku) (0.0.2)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from dm_haiku) (0.8.9)\nRequirement already satisfied: chex>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from optax) (0.1.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py->jax) (1.15.0)\nRequirement already satisfied: dm-tree>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from chex>=0.0.4->optax) (0.1.6)\nRequirement already satisfied: toolz>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from chex>=0.0.4->optax) (0.11.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import kaggle_init","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:42:50.489410Z","iopub.execute_input":"2022-03-05T18:42:50.489703Z","iopub.status.idle":"2022-03-05T18:42:50.497541Z","shell.execute_reply.started":"2022-03-05T18:42:50.489671Z","shell.execute_reply":"2022-03-05T18:42:50.496747Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"kaggle_init.on_kaggle(), kaggle_init.is_cuda_available(), kaggle_init.is_tpu_available()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:42:52.803296Z","iopub.execute_input":"2022-03-05T18:42:52.803580Z","iopub.status.idle":"2022-03-05T18:42:52.812900Z","shell.execute_reply.started":"2022-03-05T18:42:52.803536Z","shell.execute_reply":"2022-03-05T18:42:52.811789Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(True, False, True)"},"metadata":{}}]},{"cell_type":"code","source":"# %env XLA_PYTHON_CLIENT_MEM_FRACTION=.75\ncompute_on_tpu = True\nif compute_on_tpu:\n    if kaggle_init.is_tpu_available():\n        from feedback2021.jax_tpu_init import jax_tpu_init\n        jax_tpu_init()       \n    else:\n        import os\n        os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=2'\n#import jax\n#jax.devices()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:42:55.900112Z","iopub.execute_input":"2022-03-05T18:42:55.900414Z","iopub.status.idle":"2022-03-05T18:43:17.636549Z","shell.execute_reply.started":"2022-03-05T18:42:55.900381Z","shell.execute_reply":"2022-03-05T18:43:17.635390Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# jax_tpu_init??","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.781425Z","iopub.execute_input":"2022-03-02T07:38:34.781825Z","iopub.status.idle":"2022-03-02T07:38:34.79127Z","shell.execute_reply.started":"2022-03-02T07:38:34.781789Z","shell.execute_reply":"2022-03-02T07:38:34.790291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOG_TO_WANDB = False","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.792904Z","iopub.execute_input":"2022-03-02T07:38:34.79366Z","iopub.status.idle":"2022-03-02T07:38:34.801739Z","shell.execute_reply.started":"2022-03-02T07:38:34.793603Z","shell.execute_reply":"2022-03-02T07:38:34.800628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB:\n    !pip install --upgrade wandb -q # experiment tracking","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.803162Z","iopub.execute_input":"2022-03-02T07:38:34.80385Z","iopub.status.idle":"2022-03-02T07:38:34.813683Z","shell.execute_reply.started":"2022-03-02T07:38:34.803809Z","shell.execute_reply":"2022-03-02T07:38:34.812693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB:\n    import wandb\n    import os\n    os.environ[\"WANDB_PROJECT\"] = \"kaggle_feedback\"\n    os.environ[\"WANDB_ENTITY\"] = \"prvi\"\n    os.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n    os.environ[\"WANDB_WATCH\"] = \"gradient\"\n\n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        api_key = user_secrets.get_secret(\"wandb\")\n        os.environ[\"WANDB_API_KEY\"] = api_key\n        wandb.login()\n        wandb.init(dir=\"/tmp/\") \n    except:\n        print('If you want to use your W&B account, '\n              'go to Add-ons -> Secrets and provide your W&B access token.\\n'\n              'Use the Label name `wandb`. \\n'\n              'Get your W&B access token from here: https://wandb.ai/authorize')","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.815238Z","iopub.execute_input":"2022-03-02T07:38:34.815912Z","iopub.status.idle":"2022-03-02T07:38:34.825714Z","shell.execute_reply.started":"2022-03-02T07:38:34.815848Z","shell.execute_reply":"2022-03-02T07:38:34.824605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from feedback2021.helper import id2label, label2id\n\nfrom feedback2021.prepare_data import (create_train_dataset_pd, \n                                       to_chunk_data, \n                                       chunk_mapping,\n                                       add_input_ids, \n                                       add_labels,\n                                       add_rle_word2,\n                                       has_name,\n                                    )\n\nimport feedback2021.metric as metric\n\nfrom feedback2021.postprocess import (mk_metric, \n                                      mk_prediction_transform, \n                                      mk_binary_metric, \n                                      mk_binary_prediction_transform)\n\nfrom feedback2021.visualize import show_result\n\nimport feedback2021.hk_roberta as hk_roberta","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:43:17.638176Z","iopub.execute_input":"2022-03-05T18:43:17.638424Z","iopub.status.idle":"2022-03-05T18:43:17.892070Z","shell.execute_reply.started":"2022-03-05T18:43:17.638394Z","shell.execute_reply":"2022-03-05T18:43:17.891419Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# CONFIG\njust_test = False\nexperiment_id = 1\ntask = \"token_classification\"\nmodel_checkpoint = \"roberta-base\" \n# \"allenai/longformer-base-4096\" \n# \"distilroberta-base\" # \"microsoft/deberta-v3-xsmall\" #\"roberta-base\"\nif just_test:\n    max_length = 128\n    stride = 128\nelse:\n    max_length = 512\n    stride = 128\nmin_tokens = 6\nmodel_path = f'{model_checkpoint.split(\"/\")[-1]}-{experiment_id}'\ndata_from_wandb = False\nsave_to_wandb = False or not data_from_wandb\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-03-05T18:43:37.544373Z","iopub.execute_input":"2022-03-05T18:43:37.544828Z","iopub.status.idle":"2022-03-05T18:43:37.550388Z","shell.execute_reply.started":"2022-03-05T18:43:37.544794Z","shell.execute_reply":"2022-03-05T18:43:37.549509Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:43:41.689236Z","iopub.execute_input":"2022-03-05T18:43:41.690086Z","iopub.status.idle":"2022-03-05T18:43:45.813225Z","shell.execute_reply.started":"2022-03-05T18:43:41.690040Z","shell.execute_reply":"2022-03-05T18:43:45.812193Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6685a68fafd5491fba8afee6a1d8d354"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fd518941fe54bc1b3b26b7083267224"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf63a48c8e3c45b0a5d55c76d8769581"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9f07570c4b94872aa9793a4d44a9e76"}},"metadata":{}}]},{"cell_type":"code","source":"#import tensorflow.config\n#tensorflow.config.experimental.set_visible_devices([], \"GPU\")","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:36.470882Z","iopub.execute_input":"2022-03-02T07:38:36.471881Z","iopub.status.idle":"2022-03-02T07:38:36.478432Z","shell.execute_reply.started":"2022-03-02T07:38:36.471836Z","shell.execute_reply":"2022-03-02T07:38:36.477092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from feedback2021.clean_train_data import mk_clean_train_data\nif just_test:\n    cleaned_train = mk_clean_train_data(num_records=100) #cleaned_train[:100]\nelse:\n    cleaned_train = mk_clean_train_data()\n\ntext_id2idx = dict(zip(cleaned_train.index, range(len(cleaned_train))))\nidx2text_id = {v:k for k,v in text_id2idx.items()}\ncleaned_train.index = range(len(cleaned_train))\n\ndata = create_train_dataset_pd(cleaned_train_df=cleaned_train, \n                               tokenizer=tokenizer, \n                               verbose=True)\n\nfrom sklearn.model_selection import train_test_split\n\ndata = dict(zip(['train','test'], \n                train_test_split(data,\n                                 test_size=0.1, \n                                 shuffle=True, \n                                 random_state=42)))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:43:47.731739Z","iopub.execute_input":"2022-03-05T18:43:47.732052Z","iopub.status.idle":"2022-03-05T18:45:47.426123Z","shell.execute_reply.started":"2022-03-05T18:43:47.732019Z","shell.execute_reply":"2022-03-05T18:45:47.425125Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"2022-03-05 18:43:48.369204: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2022-03-05 18:43:52.523994: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2022-03-05 18:43:52.524069: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"reformat train data:   0%|          | 0/144293 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"951c6f6ebe134f689e3f03840da201d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"reading essays:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43176fa0d6d04185889f07c912af8be4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"searching for disaligned labels:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bf92e4aa9c845ff80abc3afbd31787a"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    word mapping:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b91019f0fa97417d99e3b65192df2c3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adding token rle:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a206521c8b548e8bf45be694812fb1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adding word rle:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52cee2b94a884d0eb73e4be5c71b49e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":" adding label:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af5f5e2f70745e58b0cbf4a9e22aba7"}},"metadata":{}}]},{"cell_type":"code","source":"data['train'].head(), data['test'].head()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:53.414697Z","iopub.execute_input":"2022-03-02T07:39:53.415104Z","iopub.status.idle":"2022-03-02T07:39:54.02743Z","shell.execute_reply.started":"2022-03-02T07:39:53.415062Z","shell.execute_reply":"2022-03-02T07:39:54.026316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB and save_to_wandb:\n    data.remove_columns([#'input_ids', \n                         #'rle_token', \n                         'labels', \n                         #'offset_mapping'\n    ]).save_to_disk('data')\n\n    artifact = wandb.Artifact('data', description='train test split', type='dataset')\n    artifact.add_dir('data')\n    wandb.log_artifact(artifact)\n    !ls -sRh data\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:54.02938Z","iopub.execute_input":"2022-03-02T07:39:54.029701Z","iopub.status.idle":"2022-03-02T07:39:54.039118Z","shell.execute_reply.started":"2022-03-02T07:39:54.029661Z","shell.execute_reply":"2022-03-02T07:39:54.037959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if  not isinstance(data.column_names, dict):\n#     data = data.train_test_split(test_size=0.1, shuffle=True, seed=42)\n    \n# chunk_data = to_chunk_data(data, \n#                            chunk_len=max_length, \n#                            stride=stride, \n#                            prefix=[tokenizer.bos_token_id],\n#                            postfix=[tokenizer.eos_token_id])\n# chunk_data","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:54.040586Z","iopub.execute_input":"2022-03-02T07:39:54.041552Z","iopub.status.idle":"2022-03-02T07:39:54.051163Z","shell.execute_reply.started":"2022-03-02T07:39:54.041489Z","shell.execute_reply":"2022-03-02T07:39:54.050131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def chop_up(data, tokenizer, max_length, stride):\n    examples = {k: list(data[k]) for k in data.columns}\n    examples['labels'] = list(data['labels'])\n    examples['id'] = list(data.index.values)\n    f = chunk_mapping(chunk_len=max_length, \n                      stride=stride, \n                      prefix=[tokenizer.bos_token_id],\n                      postfix=[tokenizer.eos_token_id])\n    return f(examples)\n\ndef to_records(data):\n    return [dict(zip(data.keys(), rec))  for rec in zip(*data.values())]\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:45:47.428179Z","iopub.execute_input":"2022-03-05T18:45:47.428517Z","iopub.status.idle":"2022-03-05T18:45:47.437127Z","shell.execute_reply.started":"2022-03-05T18:45:47.428471Z","shell.execute_reply":"2022-03-05T18:45:47.435958Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"chunk_data = {\n    k: chop_up(v, tokenizer, max_length=max_length, stride=stride)\n    for k,v in data.items()\n}","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:45:47.438399Z","iopub.execute_input":"2022-03-05T18:45:47.439482Z","iopub.status.idle":"2022-03-05T18:45:49.402283Z","shell.execute_reply.started":"2022-03-05T18:45:47.439434Z","shell.execute_reply":"2022-03-05T18:45:49.401276Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import yaml\nprint(yaml.dump(\n    {\n        k: {\n            k0: f'size={len(v0[0])}, type={type(v0[0][0]).__name__}' \n            if isinstance(v0[0], list) else v0[0] \n            for k0, v0 in v.items()\n        } \n     for k,v in chunk_data.items()\n    }\n))","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:45:49.426984Z","iopub.execute_input":"2022-03-05T18:45:49.427301Z","iopub.status.idle":"2022-03-05T18:45:49.436418Z","shell.execute_reply.started":"2022-03-05T18:45:49.427265Z","shell.execute_reply":"2022-03-05T18:45:49.435461Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"test:\n  input_ids: size=216, type=int\n  labels: size=216, type=int\n  offset: 0\n  text_id: !!python/object/apply:numpy.core.multiarray.scalar\n  - &id001 !!python/object/apply:numpy.dtype\n    args:\n    - i8\n    - false\n    - true\n    state: !!python/tuple\n    - 3\n    - <\n    - null\n    - null\n    - null\n    - -1\n    - -1\n    - 0\n  - !!binary |\n    eCgAAAAAAAA=\ntrain:\n  input_ids: size=512, type=int\n  labels: size=512, type=int\n  offset: 0\n  text_id: !!python/object/apply:numpy.core.multiarray.scalar\n  - *id001\n  - !!binary |\n    IR8AAAAAAAA=\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.879094Z","iopub.execute_input":"2022-03-02T07:39:55.87966Z","iopub.status.idle":"2022-03-02T07:39:55.902151Z","shell.execute_reply.started":"2022-03-02T07:39:55.879602Z","shell.execute_reply":"2022-03-02T07:39:55.90108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if not has_name(data, 'rle_word'):\n#     from feedback2021.helper import Block\n#     def add_rle_word2(data):\n#         # assert has_name(data, 'offset_mapping'), 'add input_ids first!'\n#         if not has_name(data,'word_mapping'):\n#             data = add_word_mapping(data)\n#         return data.map(lambda x: {'rle_word': [Block(t).inv_map(x['word_mapping']) \n#                                                  for t in x['rle_char']]},\n#                             desc='rle to word coordinates')\n#     data = add_rle_word2(data)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.903714Z","iopub.execute_input":"2022-03-02T07:39:55.904145Z","iopub.status.idle":"2022-03-02T07:39:55.913411Z","shell.execute_reply.started":"2022-03-02T07:39:55.904101Z","shell.execute_reply":"2022-03-02T07:39:55.91245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from collections import defaultdict\n# import numpy as np\n# word_counts = defaultdict(list)\n# from  datasets import concatenate_datasets\n# all_data = concatenate_datasets(list(data.values()))\n# for x in all_data['rle_word']:\n#     for cls_id, start, end  in x:\n#         word_counts[id2label[cls_id]].append(end-start)\n\n# for k, v in word_counts.items():\n#     plt.hist(v,bins=np.arange(1,max(v)+1)-0.5)\n#     plt.title(f'{k} min:{min(v)} max: {max(v)}, 2%,5%: {np.percentile(v,[2,5])}')\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.916479Z","iopub.execute_input":"2022-03-02T07:39:55.918295Z","iopub.status.idle":"2022-03-02T07:39:55.924707Z","shell.execute_reply.started":"2022-03-02T07:39:55.918253Z","shell.execute_reply":"2022-03-02T07:39:55.923809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model and Training","metadata":{}},{"cell_type":"code","source":"# chunk_data = chunk_data.rename_column('labels','label')\n# DataLoader?","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.926033Z","iopub.execute_input":"2022-03-02T07:39:55.92685Z","iopub.status.idle":"2022-03-02T07:39:55.937142Z","shell.execute_reply.started":"2022-03-02T07:39:55.926809Z","shell.execute_reply":"2022-03-02T07:39:55.936155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# def mk_collate_fn(tokenizer, max_length=512):\n#     def collate_fn(features):\n        \n#         batch ={key: np.array([f[key]+[t]*(max_length-len(f[key])) for f in features], dtype=np.int32)\n#                 for t,key in zip([tokenizer.pad_token_id,-100],['input_ids','labels'])}\n#         return batch\n#     return collate_fn\n# from torch.utils.data import DataLoader\n\n# train_dataset = DataLoader(chunk_data_list, shuffle=True, #.remove_columns(['offset', 'text_id']), \n#                            batch_size=16,\n#                            collate_fn=mk_collate_fn(tokenizer, 512))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.938794Z","iopub.execute_input":"2022-03-02T07:39:55.939108Z","iopub.status.idle":"2022-03-02T07:39:55.951696Z","shell.execute_reply.started":"2022-03-02T07:39:55.93907Z","shell.execute_reply":"2022-03-02T07:39:55.950633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport tensorflow.data as tfdata\n#ds=\nimport numpy as np\n\ndef mk_collate_fn(tokenizer, max_length=512):\n    def collate_fn(features):\n        \n        batch = features.copy()\n        for t, key in zip([tokenizer.pad_token_id,-100], ['input_ids','labels']):\n            batch[key] = np.array([f+[t]*(max_length-len(f)) for f in batch[key]], \n                                  dtype=np.int32)\n        return batch\n    \n    return collate_fn\n\n    \ncollate_fn = mk_collate_fn(tokenizer, max_length)\n\nds ={k: tfdata.Dataset.from_tensor_slices(collate_fn(v)) for k,v in chunk_data.items()}\n#(chunk_data_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:45:49.438218Z","iopub.execute_input":"2022-03-05T18:45:49.438890Z","iopub.status.idle":"2022-03-05T18:46:01.570793Z","shell.execute_reply.started":"2022-03-05T18:45:49.438821Z","shell.execute_reply":"2022-03-05T18:46:01.569921Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"CPU times: user 11.7 s, sys: 414 ms, total: 12.2 s\nWall time: 12.1 s\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 16 if kaggle_init.is_tpu_available() else 2\ndummy_data = tfdata.Dataset.from_tensor_slices(\n    {\n        'input_ids': np.zeros((batch_size, max_length), dtype=np.int32),\n        'labels': -100*np.ones((batch_size, max_length), dtype=np.int32),\n        'text_id': -1*np.ones(batch_size, dtype=np.int32),\n        ## np.array([-1]*batch_size), #np.array(['0'*11]*batch_size),\n        'offset': np.zeros(batch_size, dtype=np.int32)\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:46:01.571992Z","iopub.execute_input":"2022-03-05T18:46:01.572285Z","iopub.status.idle":"2022-03-05T18:46:01.580529Z","shell.execute_reply.started":"2022-03-05T18:46:01.572254Z","shell.execute_reply":"2022-03-05T18:46:01.579917Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"dummy_data","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.146839Z","iopub.execute_input":"2022-03-02T07:40:15.147558Z","iopub.status.idle":"2022-03-02T07:40:15.156918Z","shell.execute_reply.started":"2022-03-02T07:40:15.147513Z","shell.execute_reply":"2022-03-02T07:40:15.155725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jax\njax.devices(), jax.device_count()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:46:01.581726Z","iopub.execute_input":"2022-03-05T18:46:01.582151Z","iopub.status.idle":"2022-03-05T18:46:01.618262Z","shell.execute_reply.started":"2022-03-05T18:46:01.582121Z","shell.execute_reply":"2022-03-05T18:46:01.617321Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"([TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n  TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n  TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n  TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n  TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n  TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n  TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n  TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)],\n 8)"},"metadata":{}}]},{"cell_type":"code","source":"def subset(x):\n    return {k: x[k] for k in ['input_ids', 'labels', 'offset']}\n\ntrain_dataset = (ds['train'].\n                 # map(subset).\n                 repeat().\n                 shuffle(4096).\n                 batch(batch_size=batch_size).\n                 batch(batch_size=jax.device_count()).\n                 prefetch(tfdata.experimental.AUTOTUNE).\n                 as_numpy_iterator())\n\ntest_dataset = (ds['test'].\n                concatenate(dummy_data.repeat(jax.device_count())).\n                #map(subset).\n                batch(batch_size=batch_size, drop_remainder=True).\n                batch(batch_size=jax.device_count(), drop_remainder=True).\n                prefetch(tfdata.experimental.AUTOTUNE)\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:46:46.161906Z","iopub.execute_input":"2022-03-05T18:46:46.162423Z","iopub.status.idle":"2022-03-05T18:46:46.347936Z","shell.execute_reply.started":"2022-03-05T18:46:46.162378Z","shell.execute_reply":"2022-03-05T18:46:46.346829Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"len(ds['test']), len(ds['train'])","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:46:51.169233Z","iopub.execute_input":"2022-03-05T18:46:51.169930Z","iopub.status.idle":"2022-03-05T18:46:51.178742Z","shell.execute_reply.started":"2022-03-05T18:46:51.169877Z","shell.execute_reply":"2022-03-05T18:46:51.177625Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(5116, 43645)"},"metadata":{}}]},{"cell_type":"code","source":"class Metric:\n    def __init__(self):\n        self.reset()\n    def reset(self):\n        self._value = 0\n        self._n = 0\n    def update(self,v):\n        self._n += 1\n        self._value += v\n    def value(self):\n        return self._value/self._n","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.361635Z","iopub.execute_input":"2022-03-02T07:40:15.362448Z","iopub.status.idle":"2022-03-02T07:40:15.372528Z","shell.execute_reply.started":"2022-03-02T07:40:15.362388Z","shell.execute_reply":"2022-03-02T07:40:15.37155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{k: f'shape={v.shape}, dtype={v.dtype}' for k,v in next(iter(train_dataset)).items()}","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:46:56.186714Z","iopub.execute_input":"2022-03-05T18:46:56.187090Z","iopub.status.idle":"2022-03-05T18:46:56.237181Z","shell.execute_reply.started":"2022-03-05T18:46:56.187052Z","shell.execute_reply":"2022-03-05T18:46:56.236116Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'input_ids': 'shape=(8, 16, 512), dtype=int32',\n 'labels': 'shape=(8, 16, 512), dtype=int32',\n 'offset': 'shape=(8, 16), dtype=int32',\n 'text_id': 'shape=(8, 16), dtype=int32'}"},"metadata":{}}]},{"cell_type":"code","source":"local_device_count = jax.device_count()\nlocal_device_count","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.417944Z","iopub.execute_input":"2022-03-02T07:40:15.418445Z","iopub.status.idle":"2022-03-02T07:40:15.425978Z","shell.execute_reply.started":"2022-03-02T07:40:15.418388Z","shell.execute_reply":"2022-03-02T07:40:15.424911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import haiku as hk\nimport jax.numpy as jnp\nimport optax\nimport functools\nfrom typing import Any, Mapping\n\ndef mk_loss_fn(config):\n    \n    def loss_fn(logits, data):\n    #                params,\n    #                rng,\n    #                data: Mapping[str, jnp.ndarray],\n    #                is_training: bool = True) -> jnp.ndarray:\n        \"\"\"Compute the loss on data wrt params.\"\"\"\n\n\n    #     logits = forward_fn(params, rng, data, is_training)\n        targets = jax.nn.one_hot(data['labels'], len(config['id2label']))\n        assert logits.shape == targets.shape\n\n        mask = jnp.not_equal(data['input_ids'], config['pad_token_id'])\n        mask = mask * jnp.greater_equal(data['labels'], 0)\n        loss = -jnp.sum(targets * jax.nn.log_softmax(logits), axis=-1)\n        loss = jnp.sum(loss * mask, axis=-1) / jnp.clip(jnp.sum(mask, axis=-1),1)\n\n        return jnp.mean(loss)\n    \n    return loss_fn\n\nclass Updater:\n    \"\"\"A stateless abstraction around an init_fn/update_fn pair.\n    This extracts some common boilerplate from the training loop.\n    \"\"\"\n\n    def __init__(self, \n                 net, \n                 loss_fn,\n                 optimizer: optax.GradientTransformation):\n        \n        self._net_init = net.init\n        self._loss_fn = lambda params,rng, data: loss_fn(net.apply(params, rng, data, is_training=True), data)\n        self._opt = optimizer\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def init(self, rng, data, pretrained_params=None):\n        \"\"\"Initializes state of the updater.\"\"\"\n        out_rng, init_rng = jax.random.split(rng)\n        params = self._net_init(init_rng, data)\n        if pretrained_params is not None:\n            params = hk.data_structures.merge(params, pretrained_params)\n        #params = hk.data_structures.map(lambda x: jnp.stack([x]*local_device_count), params)\n        opt_state = self._opt.init(params)\n        # rng = jax.random.PRNGKey(FLAGS.train_init_random_seed)\n        #rng = jnp.broadcast_to(rng, (local_device_count,) + rng.shape)\n        out = dict(\n            step=np.array(0),\n            rng=out_rng,\n            opt_state=opt_state,\n            params=params,\n            loss=np.array(0),\n        )\n        return out\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def update(self, state: Mapping[str, Any], data: Mapping[str, jnp.ndarray]):\n        \"\"\"Updates the state using some data and returns metrics.\"\"\"\n        rng, new_rng = jax.random.split(state['rng'])\n        params = state['params']\n        loss, grads = jax.value_and_grad(self._loss_fn)(params, rng, data)\n\n        if compute_on_tpu:\n            grads = jax.lax.pmean(grads, 'i')\n\n\n        updates, opt_state = self._opt.update(grads, state['opt_state'])\n        params = optax.apply_updates(params, updates)\n\n        new_state = {\n            'step': state['step'] + 1,\n            'rng': new_rng,\n            'opt_state': opt_state,\n            'params': params,\n            'loss': state['loss'] + loss\n        }\n\n        return new_state ","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:47:05.364761Z","iopub.execute_input":"2022-03-05T18:47:05.365130Z","iopub.status.idle":"2022-03-05T18:47:05.393894Z","shell.execute_reply.started":"2022-03-05T18:47:05.365091Z","shell.execute_reply":"2022-03-05T18:47:05.392715Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def mk_net_eval(net):\n    def run_net(param, rng, data):\n        return net.apply(param, rng, data, is_training=False)\n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    return run_net\n\ndef predict(net, state, data):\n    predictions = []\n    data = data.map(lambda x: ({'input_ids':x['input_ids']},\n                               x['input_ids'],\n                               x['text_id'], \n                               x['offset'])).as_numpy_iterator()\n    \n    \n    for data, ids, text_id, offset  in data:    \n        logits = net(state['params'], state['rng'], data)\n        logits0 = jax.device_get(logits)\n        del logits\n        logits0 = logits0.reshape((-1,)+logits0.shape[2:])\n        ## 0,1,2 are <s> </s> <pad>!\n        mask = (ids>2).reshape((-1,)+ids.shape[2:])\n        predictions.extend(zip(text_id.reshape(-1), \n                               offset.reshape(-1), \n                               (logit[m] for logit,m in zip(logits0, mask))))\n                               #data['input_ids'].reshape((-1,)+data['input_ids']))\n    return predictions\n\nfrom collections import defaultdict\ndef collect_chunks(raw_predictions):\n    predictions = defaultdict(list)\n    for idx, offset, logit in raw_predictions:\n        predictions[idx].append((offset, logit))\n    return dict(predictions)\n\ndef combine_offset_list(offset_lst):\n    offset_lst = [(offset, np.asarray(c)) for offset, c in offset_lst]\n    total_len = max(offset+len(c) for offset, c in offset_lst)\n    chunk_shape = offset_lst[0][1].shape\n    res = np.zeros((total_len,)+chunk_shape[1:])\n    cnt = np.zeros((total_len,)+(1,)*(len(chunk_shape)-1))\n    for i, (o, c) in enumerate(offset_lst):\n        res[o:o+len(c)] += c\n        cnt[o:o+len(c)] += 1\n    return res/cnt.clip(1)\n\nfrom feedback2021.helper import label2id, id2label, Block\ndef pred_rle(pred):\n    \n    res = []\n    cur_cls = -1\n    min_cls = label2id.get('None',-1)\n    \n    for i, cls_id in enumerate(pred):\n        \n        if (cur_cls>min_cls) and (cur_cls!=cls_id):\n            res.append(Block((cur_cls, start, i)))\n            cur_cls = -1\n        \n        if cls_id>min_cls and cur_cls==-1: \n            cur_cls, start = cls_id, i\n    \n    if cur_cls>min_cls:\n        res.append(Block((cur_cls, start, i+1)))\n    \n    return res\n\n\nimport  feedback2021.metric as metric\n\ndef compute_metric(net, state, chunked_data, raw_df):\n    predictions = predict(net, state, chunked_data)\n    predictions = collect_chunks(predictions)\n    predictions = {k: pred_rle(np.argmax(combine_offset_list(v), axis=-1)) \n                   for k,v in predictions.items()}\n    \n    raw_data = zip(raw_df.index, raw_df['offset_mapping'], raw_df['word_mapping'])\n    predictions = [\n            [b.map(om).inv_map(wm) for b in predictions[idx]]\n            for idx, om, wm in raw_data\n        ]\n\n    scores = np.array([ \n            metric.score_example(y_pred=y_pred, y_true=y_true)\n            for y_pred,y_true in zip(predictions, raw_df['rle_word'])\n        ]).sum(axis=0)\n        \n    res = {id2label[i+1]: metric.f1(*score) for i, score in enumerate(scores)}\n    res['f1'] = sum(res.values())/len(res)\n        \n    return res\n    \n    \n    \n\n## predict(jax.pmap(net.apply, axis_name='i'), state, dataset)\n\n        \ndef get_predictions(net, loss_fn, state, test_ds):\n\n    def run_net(state, data):\n        logits = net.apply(state['params'], state['rng'], data, is_training=False)\n        loss = loss_fn(logits, data)\n        pred = jax.numpy.argmax(logits, axis=-1)\n        state['loss'] = state['loss'] + loss\n        return pred, state\n        \n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    predictions = []\n    for batch in test_ds.as_numpy_iterator():\n        pred, state = run_net(state, batch)\n        predictions.append(pred)\n        \n    predictions = [ pred \n                    for preds in jax.device_get(predictions) \n                    for pred in preds.reshape((-1,) + preds.shape[2:]) ]\n    return predictions, state\n\ndef eval_net(net, loss_fn, state, test_ds):\n\n    def run_net(state, data, loss, cnt):\n        cnt0 = jnp.greater(data['labels'].max(axis=-1),0).sum()\n        logits = net.apply(state['params'], state['rng'], data, is_training=False)\n        loss0 = loss_fn(logits, data) * data['labels'].shape[0]\n        #pred = jax.numpy.argmax(logits, axis=-1)\n        #state['loss'] = state['loss'] + loss\n        return loss + loss0, cnt + cnt0\n        \n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    #predictions = []\n    loss = np.zeros(jax.device_count())\n    cnt = np.zeros(jax.device_count())\n    for batch in test_ds.as_numpy_iterator():\n        loss, cnt = run_net(state, batch, loss, cnt)\n        # predictions.append(pred)\n    return float(loss.sum()/cnt.sum())","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:47:09.479987Z","iopub.execute_input":"2022-03-05T18:47:09.480517Z","iopub.status.idle":"2022-03-05T18:47:09.528572Z","shell.execute_reply.started":"2022-03-05T18:47:09.480470Z","shell.execute_reply":"2022-03-05T18:47:09.527405Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class Log:\n    def __init__(self, step=0):\n        self.step = step\n        self.start_time = self.prev_time = time.time()\n        \n    def update(self, state):\n        step = int(state['step'][0])\n        step_delta, self.step = step-self.step, step\n        \n        c_time = time.time()\n        time_delta, self.prev_time = c_time - self.prev_time, c_time\n        \n        loss = float(state['loss'].mean())/step_delta\n        state['loss'] = 0*state['loss']\n        \n        return {'step': self.step,\n                'loss': loss,\n                'elapsed_time': time_delta,\n                'total_time':   c_time-self.start_time,\n                'iter_per_sec': time_delta/max(1,step_delta),\n                'sec_per_iter': step_delta/max(1,time_delta),\n               }\n\ndef format_log(log):\n    return \"iteration: {step:<5}, loss: {loss:.4f}, elapsed_time:{elapsed_time:.2f}\".format(**log)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:47:14.687819Z","iopub.execute_input":"2022-03-05T18:47:14.688390Z","iopub.status.idle":"2022-03-05T18:47:14.705081Z","shell.execute_reply.started":"2022-03-05T18:47:14.688340Z","shell.execute_reply":"2022-03-05T18:47:14.700719Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import logging\nimport time\nfrom transformers import AutoConfig\nfrom feedback2021.hk_roberta import (build_forward_fn, \n                                     lm_loss_fn, \n                                     # GradientUpdater, \n                                     hk, optax, functools, Mapping, jnp, jax)\n\n## global variables\n# batch_size = 16  # Train batch size per core\ntotal_batch_size = batch_size*jax.device_count()\nlearning_rate = 1.25e-5*(total_batch_size/32) # Max learning-rate\ngrad_clip_value = 0.2  # Gradient norm clip value\n\ncheckpoint_dir = '/jax-transformer'  # Directory to store checkpoints\nif just_test:\n    LOG_EVERY = 2\n    MAX_STEPS = 4\nelse:\n    LOG_EVERY = len(ds['train'])//(2*total_batch_size)\n    MAX_STEPS = (4*len(ds['train']))//total_batch_size+1\n\nconfig = AutoConfig.from_pretrained(model_checkpoint, #'distilroberta-base', \n                                    label2id=label2id, \n                                    id2label=id2label).to_dict()\ntranslation = hk_roberta.weight_name_translation(config=config, prefix='roberta')\npretrained_params = hk_roberta.load_hf_pytorch_weights(model_checkpoint, #'distilroberta-base', \n                                                       translation)\n\nlogging.info = print\nlogging.info('Starting...')\n\nforward_fn = build_forward_fn(config)\n\nforward_fn = hk.transform(forward_fn)\n\n#loss_fn = functools.partial(lm_loss_fn, forward_fn.apply, config)\nloss_fn = mk_loss_fn(config)\n\nlr_schedule=optax.warmup_cosine_decay_schedule(init_value=0, \n                                               peak_value=1, \n                                               warmup_steps=min(50, MAX_STEPS//6), \n                                               decay_steps=MAX_STEPS-min(50,MAX_STEPS//6), \n                                               end_value=1e-4)\n\noptimizer = optax.chain(\n        optax.clip_by_global_norm(grad_clip_value),\n        optax.adam(learning_rate, b1=0.9, b2=0.99),\n        optax.scale_by_schedule(lr_schedule),\n    )\n\nupdater = Updater(forward_fn, loss_fn, optimizer)\n\n# Initialize parameters.\nlogging.info('Initializing parameters...')\nrng = jax.random.PRNGKey(428)\nbatch = next(iter(train_dataset))\nstate = updater.init(rng, #jnp.broadcast_to(rng, (local_device_count,) + rng.shape), \n                     {k:v[0] for k,v in batch.items()},\n                     pretrained_params=pretrained_params)\nif compute_on_tpu:\n    state = jax.device_put_replicated(state, jax.devices())\n    update = jax.pmap(updater.update, axis_name='i')\nelse:\n    update = updater.update\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:47:19.708100Z","iopub.execute_input":"2022-03-05T18:47:19.708614Z","iopub.status.idle":"2022-03-05T18:48:02.352521Z","shell.execute_reply.started":"2022-03-05T18:47:19.708561Z","shell.execute_reply":"2022-03-05T18:48:02.351149Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31c9ee4391cf423f9556b4602184e76f"}},"metadata":{}},{"name":"stdout","text":"unused torch weights: roberta.embeddings.token_type_embeddings.weight,\nroberta.pooler.dense.weight, roberta.pooler.dense.bias, lm_head.bias,\nlm_head.dense.weight, lm_head.dense.bias, lm_head.layer_norm.weight,\nlm_head.layer_norm.bias, lm_head.decoder.weight\nStarting...\nInitializing parameters...\n","output_type":"stream"}]},{"cell_type":"code","source":"learning_rate, 5e-5*(total_batch_size/32)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:35.764593Z","iopub.execute_input":"2022-03-02T07:40:35.765306Z","iopub.status.idle":"2022-03-02T07:40:35.775505Z","shell.execute_reply.started":"2022-03-02T07:40:35.765231Z","shell.execute_reply":"2022-03-02T07:40:35.774366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logging.info('Starting train loop...')\ntrain_iter = train_dataset\nlog = Log()\nnet_eval_fn = mk_net_eval(forward_fn)\nfor step  in range(MAX_STEPS): #enumerate(train_dataset):\n        batch = next(train_iter)\n        state = update(state, batch)\n        # We use JAX runahead to mask data preprocessing and JAX dispatch overheads.\n        # Using values from state/metrics too often will block the runahead and can\n        # cause these overheads to become more prominent.\n        if step % LOG_EVERY == 0 or (step+1)== MAX_STEPS:\n            last_log=log.update(state)\n            logging.info(last_log)\n            print(compute_metric(net_eval_fn, state, test_dataset, data['test']))\n            # test_loss = eval_net(forward_fn, loss_fn, state, test_dataset)\n            # last_log['test_loss'] = test_loss #float(state['loss'].mean())\n            \n            \n\n# logging.info(last_log)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:48:04.857756Z","iopub.execute_input":"2022-03-05T18:48:04.858315Z","iopub.status.idle":"2022-03-05T19:00:08.004433Z","shell.execute_reply.started":"2022-03-05T18:48:04.858269Z","shell.execute_reply":"2022-03-05T19:00:08.003235Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Starting train loop...\n{'step': 1, 'loss': 2.3763298988342285, 'elapsed_time': 66.57657885551453, 'total_time': 66.57657885551453, 'iter_per_sec': 66.57657885551453, 'sec_per_iter': 0.01502029718544437}\n{'Lead': 0.0, 'Position': 0.031406452243143576, 'Evidence': 0.0, 'Claim': 0.00028252578047746857, 'Concluding Statement': 0.0, 'Counterclaim': 0.0, 'Rebuttal': 0.0, 'f1': 0.004526996860517292}\n{'step': 171, 'loss': 0.9224158791934742, 'elapsed_time': 145.8537359237671, 'total_time': 212.43031477928162, 'iter_per_sec': 0.8579631524927476, 'sec_per_iter': 1.1655512210455368}\n{'Lead': 0.35450819672131145, 'Position': 0.3762943379599031, 'Evidence': 0.4096370918800825, 'Claim': 0.32014883118984067, 'Concluding Statement': 0.4590433175939232, 'Counterclaim': 0.26356589147286824, 'Rebuttal': 0.1253731343283582, 'f1': 0.3297958287351839}\n{'step': 341, 'loss': 0.5492260203642003, 'elapsed_time': 71.4648540019989, 'total_time': 283.8951687812805, 'iter_per_sec': 0.4203814941294053, 'sec_per_iter': 2.378791678427623}\n{'Lead': 0.5208262783609888, 'Position': 0.5128205128205128, 'Evidence': 0.5555644579761237, 'Claim': 0.492167326562231, 'Concluding Statement': 0.671879363306339, 'Counterclaim': 0.3236914600550964, 'Rebuttal': 0.17865429234338748, 'f1': 0.465086241632097}\n{'step': 511, 'loss': 0.49089315077837775, 'elapsed_time': 69.77771306037903, 'total_time': 353.67288184165955, 'iter_per_sec': 0.41045713564928843, 'sec_per_iter': 2.4363079921077104}\n{'Lead': 0.49121598346538065, 'Position': 0.49372967951695307, 'Evidence': 0.4853161843515541, 'Claim': 0.46424778761061947, 'Concluding Statement': 0.5723440966231206, 'Counterclaim': 0.33473980309423346, 'Rebuttal': 0.22807017543859648, 'f1': 0.4385233871572082}\n{'step': 681, 'loss': 0.43192255356732534, 'elapsed_time': 71.59539771080017, 'total_time': 425.2682795524597, 'iter_per_sec': 0.42114939829882453, 'sec_per_iter': 2.374454300633845}\n{'Lead': 0.5711199135758013, 'Position': 0.5434669442998439, 'Evidence': 0.535839092956434, 'Claim': 0.5009812387157547, 'Concluding Statement': 0.6899114032580738, 'Counterclaim': 0.3322475570032573, 'Rebuttal': 0.2178988326848249, 'f1': 0.48449499749914143}\n{'step': 851, 'loss': 0.3957637113683364, 'elapsed_time': 70.26987290382385, 'total_time': 495.53815245628357, 'iter_per_sec': 0.413352193551905, 'sec_per_iter': 2.419244449647342}\n{'Lead': 0.5626801152737753, 'Position': 0.5276856340903292, 'Evidence': 0.5762078765732846, 'Claim': 0.5101458997149086, 'Concluding Statement': 0.695161769070941, 'Counterclaim': 0.34073107049608353, 'Rebuttal': 0.2296875, 'f1': 0.4917571236027603}\n{'step': 1021, 'loss': 0.35408343146829047, 'elapsed_time': 71.56494355201721, 'total_time': 567.1030960083008, 'iter_per_sec': 0.42097025618833656, 'sec_per_iter': 2.375464739610043}\n{'Lead': 0.5937984496124031, 'Position': 0.5521276595744681, 'Evidence': 0.5572936734222085, 'Claim': 0.5064447707619514, 'Concluding Statement': 0.6880279638799883, 'Counterclaim': 0.33071988595866003, 'Rebuttal': 0.24311490978157646, 'f1': 0.49593247328446516}\n{'step': 1191, 'loss': 0.3367645263671875, 'elapsed_time': 69.85602927207947, 'total_time': 636.9591252803802, 'iter_per_sec': 0.4109178192475263, 'sec_per_iter': 2.433576625689298}\n{'Lead': 0.5998439937597504, 'Position': 0.544799176107106, 'Evidence': 0.554276442864869, 'Claim': 0.5081098442267544, 'Concluding Statement': 0.6915998812704066, 'Counterclaim': 0.3442838370565046, 'Rebuttal': 0.22462562396006655, 'f1': 0.4953626856064939}\n{'step': 1361, 'loss': 0.32130649791044347, 'elapsed_time': 70.63703513145447, 'total_time': 707.5961604118347, 'iter_per_sec': 0.41551197136149687, 'sec_per_iter': 2.4066695280122183}\n{'Lead': 0.6062745098039216, 'Position': 0.5499738356881214, 'Evidence': 0.5565473880307382, 'Claim': 0.5071360608943863, 'Concluding Statement': 0.6850601702377458, 'Counterclaim': 0.34714003944773175, 'Rebuttal': 0.22715627668659266, 'f1': 0.49704118296989114}\n{'step': 1364, 'loss': 0.29390446345011395, 'elapsed_time': 9.033166646957397, 'total_time': 716.6293270587921, 'iter_per_sec': 3.0110555489857993, 'sec_per_iter': 0.33210944923843255}\n{'Lead': 0.6047786917352135, 'Position': 0.5486818063168886, 'Evidence': 0.5580166316934795, 'Claim': 0.5077777777777778, 'Concluding Statement': 0.6878306878306878, 'Counterclaim': 0.3462295081967213, 'Rebuttal': 0.23163353500432152, 'f1': 0.49784980550787006}\n","output_type":"stream"}]},{"cell_type":"code","source":"net_eval_fn = mk_net_eval(forward_fn)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:50:45.448387Z","iopub.execute_input":"2022-03-02T07:50:45.449598Z","iopub.status.idle":"2022-03-02T07:50:45.45891Z","shell.execute_reply.started":"2022-03-02T07:50:45.449542Z","shell.execute_reply":"2022-03-02T07:50:45.457765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(compute_metric(net_eval_fn, state, test_dataset, data['test']))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:51:22.812991Z","iopub.execute_input":"2022-03-02T07:51:22.813397Z","iopub.status.idle":"2022-03-02T07:51:34.447243Z","shell.execute_reply.started":"2022-03-02T07:51:22.813356Z","shell.execute_reply":"2022-03-02T07:51:34.446075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = get_predictions(forward_fn, loss_fn, state=state, test_ds=test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:35:38.784742Z","iopub.execute_input":"2022-02-25T12:35:38.785273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# next(test_dataset.as_numpy_iterator())\n#next(iter(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:35:26.825227Z","iopub.execute_input":"2022-02-25T12:35:26.825509Z","iopub.status.idle":"2022-02-25T12:35:26.879572Z","shell.execute_reply.started":"2022-02-25T12:35:26.825481Z","shell.execute_reply":"2022-02-25T12:35:26.878887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(pred), pred[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:50:54.188065Z","iopub.execute_input":"2022-02-24T08:50:54.188883Z","iopub.status.idle":"2022-02-24T08:50:54.195233Z","shell.execute_reply.started":"2022-02-24T08:50:54.188841Z","shell.execute_reply":"2022-02-24T08:50:54.19407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = hk.data_structures.map(lambda name,module,x: x[0], state['params'])\nimport pickle\nwith open('params.pkl','wb') as f:\n    pickle.dump(params, f)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T06:13:23.821943Z","iopub.execute_input":"2022-02-23T06:13:23.822508Z","iopub.status.idle":"2022-02-23T06:13:27.022087Z","shell.execute_reply.started":"2022-02-23T06:13:23.822465Z","shell.execute_reply":"2022-02-23T06:13:27.020853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shraded_ds = [list(ds['train'].shard(8, i).as_numpy_iterator()) for i in range(8)]","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:00:08.984632Z","iopub.execute_input":"2022-02-26T06:00:08.985611Z","iopub.status.idle":"2022-02-26T06:00:25.119974Z","shell.execute_reply.started":"2022-02-26T06:00:08.985566Z","shell.execute_reply":"2022-02-26T06:00:25.118793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sharded_ds = jax.device_put_sharded(shards=shraded_ds, devices=jax.devices())","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:01:13.078175Z","iopub.execute_input":"2022-02-26T06:01:13.079144Z","iopub.status.idle":"2022-02-26T06:01:42.867983Z","shell.execute_reply.started":"2022-02-26T06:01:13.079094Z","shell.execute_reply":"2022-02-26T06:01:40.989601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_schedule=optax.warmup_cosine_decay_schedule(init_value=0, \n                                               peak_value=1, \n                                               warmup_steps=500, \n                                               decay_steps=8500, \n                                               end_value=1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:41:44.23837Z","iopub.execute_input":"2022-02-21T06:41:44.238975Z","iopub.status.idle":"2022-02-21T06:41:44.245739Z","shell.execute_reply.started":"2022-02-21T06:41:44.238926Z","shell.execute_reply":"2022-02-21T06:41:44.244518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jaxlib, jax\njaxlib.__version__, jax.__version__, hk.__version__","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:45:48.632171Z","iopub.execute_input":"2022-02-21T06:45:48.632588Z","iopub.status.idle":"2022-02-21T06:45:48.640181Z","shell.execute_reply.started":"2022-02-21T06:45:48.632543Z","shell.execute_reply":"2022-02-21T06:45:48.639215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt = np.arange(0,9000,10)\nlr = [lr_schedule(jnp.array([i])) for i in cnt]\nplt.plot(cnt, lr)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:41:48.464737Z","iopub.execute_input":"2022-02-21T06:41:48.465445Z","iopub.status.idle":"2022-02-21T06:42:26.896087Z","shell.execute_reply.started":"2022-02-21T06:41:48.465381Z","shell.execute_reply":"2022-02-21T06:42:26.893875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{'loss': 2.4778389930725098, 'step': 0.0, 'steps_per_sec': 13.779059174634387}\n{'loss': 1.3683964014053345, 'step': 500.0, 'steps_per_sec': 2.5767113856201855}\n{'loss': 1.6631159782409668, 'step': 1000.0, 'steps_per_sec': 2.57725389686341}\n{'loss': 1.3581798076629639, 'step': 1500.0, 'steps_per_sec': 2.5771785561488483}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{k:v.shape for k,v in data.items()}","metadata":{"execution":{"iopub.status.busy":"2022-02-26T05:57:06.831234Z","iopub.execute_input":"2022-02-26T05:57:06.831874Z","iopub.status.idle":"2022-02-26T05:57:06.840862Z","shell.execute_reply.started":"2022-02-26T05:57:06.831826Z","shell.execute_reply":"2022-02-26T05:57:06.839748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jax.numpy.array([1,1])\n#jax.device_get('gpu')\n#jax.devices('gpu')\n! nvcc --version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n# TRAINING HYPERPARAMS\neffective_batch_size = 32\nmax_steps = 4000\nlog_steps = 500\n#n_step_examples = 8*500\nbatch_size = 16\ngrad_accumulation = effective_batch_size//batch_size\nlearning_rate = 5e-5\nweight_decay = 0.01\nwarmup_ratio = 0.1\nn_epochs = 3\nmodel_name = model_checkpoint.split(\"/\")[-1]\ntraining_args = TrainingArguments(\n    f\"{model_name}-{task}\",\n    evaluation_strategy = \"steps\",\n    eval_steps = log_steps,\n    logging_strategy = \"steps\",\n    logging_steps = log_steps,\n    save_strategy = \"steps\",\n    save_steps = log_steps,\n    learning_rate = learning_rate,\n    per_device_train_batch_size = batch_size,\n    per_device_eval_batch_size = batch_size,\n    #num_train_epochs = n_epochs,\n    max_steps = max_steps,\n    weight_decay = weight_decay,\n    report_to = 'wandb', \n    gradient_accumulation_steps = grad_accumulation,\n    warmup_steps = int(1.5*(log_steps)),\n    # logging_steps = 100,\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    greater_is_better=True,\n)\n#training_args","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['test']=add_rle_word2(data['test'])\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=chunk_data[\"train\"].remove_columns(['offset', 'text_id']), #.select(range(100)),\n    eval_dataset=chunk_data[\"test\"].remove_columns(['offset', 'text_id']), #.select(range(100)),\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=mk_binary_metric(chunk_ds=chunk_data['test'],\n                                     orig_ds=data['test'])\n    #,\n    #                                 min_word_cnt=[0,10,5,10,3,10,6,6]), #.select(range(100))), \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.save_model(model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wandb.init()\nimport pickle\nfrom feedback2021.postprocess import mk_prediction_transform\nfor k,v in chunk_data.items():\n    predictions = trainer.predict(v.remove_columns(['offset', 'text_id']))\n    prediction_transform = mk_binary_prediction_transform(chunk_ds=v, orig_ds=data[k])\n    predictions = prediction_transform(predictions[0])\n    with open(f'{k}_predictions.pkl','wb') as f:\n        pickle.dump(predictions, f)\n    wandb.save(f'{k}_predictions.pkl','./','now')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! rm longformer-base-4096-token_classification/ -rf\n#!rm distilroberta-base-token_classification -rf\n! ls -sh distilroberta-base-1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# From this point on there is no need to gpu!","metadata":{"execution":{"iopub.execute_input":"2021-12-30T06:52:35.965148Z","iopub.status.busy":"2021-12-30T06:52:35.964896Z","iopub.status.idle":"2021-12-30T06:52:36.089436Z","shell.execute_reply":"2021-12-30T06:52:36.088549Z","shell.execute_reply.started":"2021-12-30T06:52:35.96512Z"}}},{"cell_type":"code","source":"prediction_file = wandb.restore('predictions.pkl', run_path='prvi/huggingface/d17yam8m')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_file_name = 'test_predictions.pkl' #if os.path.exists('test_predictions.pkl') else prediction_file.name\nwith open(prediction_file_name, 'rb') as f:\n    saved_predictions = pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chunk_ds, orig_ds = chunk_data['test'].to_dict(), data['test'].to_dict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter_prediction(prediction, min_word_cnt):\n    return [b for b in prediction if b[2]-b[1]>=min_word_cnt[b[0]]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport pandas as pd\nres = []\nfor mwc in tqdm(range(0,15)):\n#     transform_prediction = mk_prediction_transform(chunk_ds=chunk_ds,\n#                                                    orig_ds=orig_ds, min_word_cnt=mwc)\n#     predictions = transform_prediction(saved_predictions[0])\n    \n    scores = np.array([metric.score_example(y_true=y_true, \n                                            y_pred=filter_prediction(y_pred,mwc)) \n              for y_pred,y_true in zip(saved_predictions,orig_ds['rle_word'])]).sum(axis=0)\n    scores = [metric.f1(*score) for score in scores]\n    f1 = sum(scores)/len(scores)\n    scores = {id2label[i+1]:score for i,score in enumerate(scores)}\n    scores['f1'] = f1\n    scores['min_word_cnt']=mwc\n    res.append(scores)\n\npd.DataFrame(res).set_index('min_word_cnt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mwc =[0, 10, 6, 15, 6, 11, 9, 8]\n\nscores_ = np.array([metric.score_example(y_true=y_true, \n                                        y_pred=filter_prediction(y_pred,mwc)) \n              for y_pred,y_true in zip(saved_predictions,orig_ds['rle_word'])]).sum(axis=0)\nscores = [metric.f1(*score) for score in scores_]\nf1 = sum(scores)/len(scores)\nscores = {id2label[i+1]:score for i,score in enumerate(scores)}\nscores['f1'] = f1\n    \n# transform_prediction = mk_prediction_transform(chunk_ds=chunk_ds,\n#                                                 orig_ds=orig_ds, \n#                                                min_word_cnt=[0, 10, 6, 15, 6, 11, 9, 8])\n# predictions = transform_prediction(saved_predictions[0])\n# scores = np.array([metric.score_example(y_true=y_true, y_pred=y_pred) \n#               for y_true,y_pred in zip(predictions,orig_ds['pred_range'])]).sum(axis=0)\n# scores = [metric.f1(*score) for score in scores]\n# f1 = sum(scores)/len(scores)\n# scores = {id2label[i+1]:score for i,score in enumerate(scores)}\n# scores['f1'] = f1\nscores    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = [ sorted(pred, key=lambda x: x[1]) for pred in saved_predictions]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_result(i=20, orig_ds=data['test'],predictions=predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsaved_predictions[8],data['test'][8]['rle_token']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = [metric.score_example(y_true=y_true, y_pred=y_pred) for y_true,y_pred in zip(predictions,orig_ds['pred_range'])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[metric.f1(*x) for x in np.array(scores).sum(axis=0)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = np.argsort(np.array(scores)[:,:,1:].sum(axis=(1,2)))[::-1]\nidx[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}