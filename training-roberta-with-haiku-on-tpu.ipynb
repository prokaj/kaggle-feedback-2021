{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_github = user_secrets.get_secret(\"github\")\n! rm -rf feedback2021\n! git clone https://{secret_github}@github.com/VilmosProkaj/feedback2021.git\n! pip install feedback2021/","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:00:24.913449Z","iopub.execute_input":"2022-03-11T15:00:24.913817Z","iopub.status.idle":"2022-03-11T15:00:51.432344Z","shell.execute_reply.started":"2022-03-11T15:00:24.913726Z","shell.execute_reply":"2022-03-11T15:00:51.431357Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'feedback2021'...\nremote: Enumerating objects: 232, done.\u001b[K\nremote: Counting objects: 100% (232/232), done.\u001b[K\nremote: Compressing objects: 100% (139/139), done.\u001b[K\nremote: Total 232 (delta 115), reused 173 (delta 56), pack-reused 0\u001b[K\nReceiving objects: 100% (232/232), 61.74 KiB | 2.37 MiB/s, done.\nResolving deltas: 100% (115/115), done.\nProcessing ./feedback2021\n\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from feedback2021==0.0.post1.dev33+g874c45e) (3.4.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->feedback2021==0.0.post1.dev33+g874c45e) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->feedback2021==0.0.post1.dev33+g874c45e) (3.5.0)\nBuilding wheels for collected packages: feedback2021\n  Building wheel for feedback2021 (PEP 517) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for feedback2021: filename=feedback2021-0.0.post1.dev33+g874c45e-py3-none-any.whl size=23927 sha256=8f305b2e4f4e9769ea4265b6d699696e5d1bc4f6056595e46a179d7c731142a6\n  Stored in directory: /tmp/pip-ephem-wheel-cache-dytg0cdi/wheels/58/ad/18/0ce3edd06dac18258cb4965c488a42e46fa829de9c6aa2319e\nSuccessfully built feedback2021\nInstalling collected packages: feedback2021\nSuccessfully installed feedback2021-0.0.post1.dev33+g874c45e\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install -U jax jaxlib dm_haiku optax\n#!pip install --upgrade pip\n# Installs the wheel compatible with CUDA 11 and cuDNN 8.2 or newer.\n# ! pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html  # Note: wheels only available on linux.\n## !pip install --upgrade jax jaxlib==0.3.0+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n#! pip install dm_haiku","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:00:54.879761Z","iopub.execute_input":"2022-03-11T15:00:54.880073Z","iopub.status.idle":"2022-03-11T15:01:22.721024Z","shell.execute_reply.started":"2022-03-11T15:00:54.880037Z","shell.execute_reply":"2022-03-11T15:01:22.720051Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: jax in /opt/conda/lib/python3.7/site-packages (0.2.19)\nCollecting jax\n  Downloading jax-0.3.1.tar.gz (912 kB)\n\u001b[K     |████████████████████████████████| 912 kB 1.9 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: jaxlib in /opt/conda/lib/python3.7/site-packages (0.1.70)\nCollecting jaxlib\n  Downloading jaxlib-0.3.0-cp37-none-manylinux2010_x86_64.whl (65.4 MB)\n\u001b[K     |████████████████████████████████| 65.4 MB 65.9 MB/s eta 0:00:01     |█████▍                          | 11.1 MB 63.7 MB/s eta 0:00:01\n\u001b[?25hCollecting dm_haiku\n  Downloading dm_haiku-0.0.6-py3-none-any.whl (309 kB)\n\u001b[K     |████████████████████████████████| 309 kB 71.0 MB/s eta 0:00:01\n\u001b[?25hCollecting optax\n  Downloading optax-0.1.1-py3-none-any.whl (136 kB)\n\u001b[K     |████████████████████████████████| 136 kB 73.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from jax) (0.12.0)\nRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.7/site-packages (from jax) (1.19.5)\nRequirement already satisfied: opt_einsum in /opt/conda/lib/python3.7/site-packages (from jax) (3.3.0)\nRequirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from jax) (1.7.1)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from jax) (3.7.4.3)\nRequirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/conda/lib/python3.7/site-packages (from jaxlib) (1.12)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from dm_haiku) (0.8.9)\nCollecting jmp>=0.0.2\n  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\nCollecting chex>=0.0.4\n  Downloading chex-0.1.1-py3-none-any.whl (70 kB)\n\u001b[K     |████████████████████████████████| 70 kB 6.4 MB/s  eta 0:00:01\n\u001b[?25hCollecting typing_extensions\n  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py->jax) (1.15.0)\nRequirement already satisfied: toolz>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from chex>=0.0.4->optax) (0.11.1)\nRequirement already satisfied: dm-tree>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from chex>=0.0.4->optax) (0.1.6)\nBuilding wheels for collected packages: jax\n  Building wheel for jax (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jax: filename=jax-0.3.1-py3-none-any.whl size=1054277 sha256=40e0ff19720c2c2ce64eff8fdf909565579ca90e6bd1ca05149bb4ef72106f02\n  Stored in directory: /root/.cache/pip/wheels/04/14/e8/ee9de500f173ec900a5167686d9bb17c0171ed678680b96a57\nSuccessfully built jax\nInstalling collected packages: typing-extensions, jaxlib, jax, jmp, chex, optax, dm-haiku\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.7.4.3\n    Uninstalling typing-extensions-3.7.4.3:\n      Successfully uninstalled typing-extensions-3.7.4.3\n  Attempting uninstall: jaxlib\n    Found existing installation: jaxlib 0.1.70\n    Uninstalling jaxlib-0.1.70:\n      Successfully uninstalled jaxlib-0.1.70\n  Attempting uninstall: jax\n    Found existing installation: jax 0.2.19\n    Uninstalling jax-0.2.19:\n      Successfully uninstalled jax-0.2.19\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.4.1 requires typing-extensions~=3.7.4, but you have typing-extensions 4.1.1 which is incompatible.\narviz 0.11.2 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\naiobotocore 1.4.1 requires botocore<1.20.107,>=1.20.106, but you have botocore 1.21.44 which is incompatible.\u001b[0m\nSuccessfully installed chex-0.1.1 dm-haiku-0.0.6 jax-0.3.1 jaxlib-0.3.0 jmp-0.0.2 optax-0.1.1 typing-extensions-4.1.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import kaggle_init","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:01:33.762731Z","iopub.execute_input":"2022-03-11T15:01:33.763010Z","iopub.status.idle":"2022-03-11T15:01:33.771854Z","shell.execute_reply.started":"2022-03-11T15:01:33.762981Z","shell.execute_reply":"2022-03-11T15:01:33.771016Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"kaggle_init.on_kaggle(), kaggle_init.is_cuda_available(), kaggle_init.is_tpu_available()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:01:37.252843Z","iopub.execute_input":"2022-03-11T15:01:37.253137Z","iopub.status.idle":"2022-03-11T15:01:37.263210Z","shell.execute_reply.started":"2022-03-11T15:01:37.253109Z","shell.execute_reply":"2022-03-11T15:01:37.261709Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(True, False, True)"},"metadata":{}}]},{"cell_type":"code","source":"# %env XLA_PYTHON_CLIENT_MEM_FRACTION=.75\ncompute_on_tpu = True\nif compute_on_tpu:\n    if kaggle_init.is_tpu_available():\n        from feedback2021.jax_tpu_init import jax_tpu_init\n        jax_tpu_init()       \n    else:\n        import os\n        os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=2'\n#import jax\n#jax.devices()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:01:42.871457Z","iopub.execute_input":"2022-03-11T15:01:42.871964Z","iopub.status.idle":"2022-03-11T15:02:05.871826Z","shell.execute_reply.started":"2022-03-11T15:01:42.871922Z","shell.execute_reply":"2022-03-11T15:02:05.870923Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# jax_tpu_init??","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.781425Z","iopub.execute_input":"2022-03-02T07:38:34.781825Z","iopub.status.idle":"2022-03-02T07:38:34.79127Z","shell.execute_reply.started":"2022-03-02T07:38:34.781789Z","shell.execute_reply":"2022-03-02T07:38:34.790291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOG_TO_WANDB = False","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.792904Z","iopub.execute_input":"2022-03-02T07:38:34.79366Z","iopub.status.idle":"2022-03-02T07:38:34.801739Z","shell.execute_reply.started":"2022-03-02T07:38:34.793603Z","shell.execute_reply":"2022-03-02T07:38:34.800628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB:\n    !pip install --upgrade wandb -q # experiment tracking","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.803162Z","iopub.execute_input":"2022-03-02T07:38:34.80385Z","iopub.status.idle":"2022-03-02T07:38:34.813683Z","shell.execute_reply.started":"2022-03-02T07:38:34.803809Z","shell.execute_reply":"2022-03-02T07:38:34.812693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB:\n    import wandb\n    import os\n    os.environ[\"WANDB_PROJECT\"] = \"kaggle_feedback\"\n    os.environ[\"WANDB_ENTITY\"] = \"prvi\"\n    os.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n    os.environ[\"WANDB_WATCH\"] = \"gradient\"\n\n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        api_key = user_secrets.get_secret(\"wandb\")\n        os.environ[\"WANDB_API_KEY\"] = api_key\n        wandb.login()\n        wandb.init(dir=\"/tmp/\") \n    except:\n        print('If you want to use your W&B account, '\n              'go to Add-ons -> Secrets and provide your W&B access token.\\n'\n              'Use the Label name `wandb`. \\n'\n              'Get your W&B access token from here: https://wandb.ai/authorize')","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:34.815238Z","iopub.execute_input":"2022-03-02T07:38:34.815912Z","iopub.status.idle":"2022-03-02T07:38:34.825714Z","shell.execute_reply.started":"2022-03-02T07:38:34.815848Z","shell.execute_reply":"2022-03-02T07:38:34.824605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from feedback2021.helper import id2label, label2id\n\nfrom feedback2021.prepare_data import (create_train_dataset_pd, \n                                       to_chunk_data, \n                                       chunk_mapping,\n                                       add_input_ids, \n                                       add_labels,\n                                       add_rle_word2,\n                                       has_name,\n                                    )\n\nimport feedback2021.metric as metric\n\nfrom feedback2021.postprocess import (mk_metric, \n                                      mk_prediction_transform, \n                                      mk_binary_metric, \n                                      mk_binary_prediction_transform)\n\nfrom feedback2021.visualize import show_result\n\nimport feedback2021.hk_roberta as hk_roberta","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:02:10.903393Z","iopub.execute_input":"2022-03-11T15:02:10.903713Z","iopub.status.idle":"2022-03-11T15:02:11.143173Z","shell.execute_reply.started":"2022-03-11T15:02:10.903654Z","shell.execute_reply":"2022-03-11T15:02:11.142304Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# CONFIG\njust_test = False\nexperiment_id = 1\ntask = \"token_classification\"\nmodel_checkpoint = \"distilroberta-base\"\n# \"roberta-base\" \n# \"allenai/longformer-base-4096\" \n# \"distilroberta-base\" # \"microsoft/deberta-v3-xsmall\" #\"roberta-base\"\nif just_test:\n    max_length = 128\n    stride = 64\nelse:\n    max_length = 512\n    stride = 128\nmax_rle_length = 32\nmin_tokens = 6\nmodel_path = f'{model_checkpoint.split(\"/\")[-1]}-{experiment_id}'\ndata_from_wandb = False\nsave_to_wandb = False or not data_from_wandb\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-03-11T15:02:14.814398Z","iopub.execute_input":"2022-03-11T15:02:14.814986Z","iopub.status.idle":"2022-03-11T15:02:14.822194Z","shell.execute_reply.started":"2022-03-11T15:02:14.814952Z","shell.execute_reply":"2022-03-11T15:02:14.820351Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:02:20.504447Z","iopub.execute_input":"2022-03-11T15:02:20.505452Z","iopub.status.idle":"2022-03-11T15:02:24.543881Z","shell.execute_reply.started":"2022-03-11T15:02:20.505392Z","shell.execute_reply":"2022-03-11T15:02:24.542983Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9de3bb34fa840c290686c059813725c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c327297ff30448459f23b3192626a058"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af0ddd014fc949a29e0c0654a8ab42c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"571164ece4ee4ce9bbce0ab1249132ac"}},"metadata":{}}]},{"cell_type":"code","source":"#import tensorflow.config\n#tensorflow.config.experimental.set_visible_devices([], \"GPU\")","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:38:36.470882Z","iopub.execute_input":"2022-03-02T07:38:36.471881Z","iopub.status.idle":"2022-03-02T07:38:36.478432Z","shell.execute_reply.started":"2022-03-02T07:38:36.471836Z","shell.execute_reply":"2022-03-02T07:38:36.477092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from feedback2021.clean_train_data import mk_clean_train_data\nif just_test:\n    cleaned_train = mk_clean_train_data(num_records=100) #cleaned_train[:100]\nelse:\n    cleaned_train = mk_clean_train_data()\n\ntext_id2idx = dict(zip(list(cleaned_train.index.values), range(len(cleaned_train))))\nidx2text_id = {v:k for k,v in text_id2idx.items()}\ncleaned_train.index = range(len(cleaned_train))\n\ndata = create_train_dataset_pd(cleaned_train_df=cleaned_train, \n                               tokenizer=tokenizer, \n                               fields = ['rle_token'],\n                               verbose=True)\n\nfrom sklearn.model_selection import train_test_split\n\ndata = dict(zip(['train','test'], \n                train_test_split(data,\n                                 test_size=0.1, \n                                 shuffle=True, \n                                 random_state=42)))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:02:25.371207Z","iopub.execute_input":"2022-03-11T15:02:25.371567Z","iopub.status.idle":"2022-03-11T15:04:35.147736Z","shell.execute_reply.started":"2022-03-11T15:02:25.371526Z","shell.execute_reply":"2022-03-11T15:04:35.146980Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2022-03-11 15:02:25.972154: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2022-03-11 15:02:30.007837: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2022-03-11 15:02:30.007900: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"reformat train data:   0%|          | 0/144293 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1e7605eb35042909c474609d65bd30c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"reading essays:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71a03e0e536348fd91ffd31f208d32b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"searching for disaligned labels:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2ed5db3672041838b5bbfca38560a8f"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adding token rle:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e42301781a684f5f9daeabd9afa0717a"}},"metadata":{}}]},{"cell_type":"code","source":"data['train'].head(), data['test'].head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T09:48:06.782736Z","iopub.execute_input":"2022-03-11T09:48:06.783047Z","iopub.status.idle":"2022-03-11T09:48:06.995594Z","shell.execute_reply.started":"2022-03-11T09:48:06.783010Z","shell.execute_reply":"2022-03-11T09:48:06.994484Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(                                                 text  \\\n 18  Dear Principal,\\n\\nI think that making someone...   \n 30  Dear Principal,\\n\\nI believe that the best pol...   \n 73  Have you ever been bored in a class room such ...   \n 33  The idea of having cars that can do the drivin...   \n 90  Hey you! Do you need some advice about somethi...   \n \n                                              rle_char  \\\n 18  [(2, 17, 100), (4, 102, 245), (3, 512, 611), (...   \n 30  [(2, 17, 74), (3, 77, 354), (6, 357, 486), (7,...   \n 73  [(1, 0, 328), (2, 330, 473), (4, 476, 540), (3...   \n 33  [(1, 0, 396), (2, 398, 565), (3, 568, 1688), (...   \n 90  [(1, 0, 155), (2, 157, 284), (4, 293, 312), (4...   \n \n                                             input_ids  \\\n 18  [23314, 13619, 6, 50118, 50118, 100, 206, 14, ...   \n 30  [23314, 13619, 6, 50118, 50118, 100, 679, 14, ...   \n 73  [17781, 47, 655, 57, 23809, 11, 10, 1380, 929,...   \n 33  [133, 1114, 9, 519, 1677, 14, 64, 109, 5, 1428...   \n 90  [13368, 47, 328, 1832, 47, 240, 103, 2949, 59,...   \n \n                                        offset_mapping  \\\n 18  [(0, 4), (5, 14), (14, 15), (15, 16), (16, 17)...   \n 30  [(0, 4), (5, 14), (14, 15), (15, 16), (16, 17)...   \n 73  [(0, 4), (5, 8), (9, 13), (14, 18), (19, 24), ...   \n 33  [(0, 3), (4, 8), (9, 11), (12, 18), (19, 23), ...   \n 90  [(0, 3), (4, 7), (7, 8), (9, 11), (12, 15), (1...   \n \n                                             rle_token  \n 18  [(2, 5, 21), (4, 22, 50), (3, 105, 129), (4, 1...  \n 30  [(2, 5, 16), (3, 19, 81), (6, 84, 110), (7, 11...  \n 73  [(1, 0, 78), (2, 79, 103), (4, 106, 120), (3, ...  \n 33  [(1, 0, 81), (2, 82, 113), (3, 116, 339), (4, ...  \n 90  [(1, 0, 34), (2, 35, 58), (4, 59, 63), (4, 64,...  ,\n                                                  text  \\\n 83  You just finished a long, hard day at school. ...   \n 53  dear principle,\\n\\nI believe that we do not ne...   \n 70  TEACHER_NAME\\n\\nSCHOOL_NAME\\n\\nDes Plaines, Il...   \n 45  Should computers read the emotional expression...   \n 44  .\\n\\nSenator i believe the electoral college s...   \n \n                                              rle_char  \\\n 83  [(1, 0, 379), (2, 381, 457), (4, 458, 518), (4...   \n 53  [(2, 17, 101), (4, 103, 204), (6, 206, 272), (...   \n 70  [(2, 95, 165), (4, 168, 382), (3, 385, 930), (...   \n 45  [(1, 0, 74), (2, 76, 131), (4, 133, 270), (3, ...   \n 44  [(2, 3, 164), (3, 166, 664), (3, 668, 784), (4...   \n \n                                             input_ids  \\\n 83  [1185, 95, 1550, 10, 251, 6, 543, 183, 23, 334...   \n 53  [417, 4352, 9322, 6, 50118, 50118, 100, 679, 1...   \n 70  [6433, 11083, 2076, 1215, 48307, 50118, 50118,...   \n 45  [31231, 7796, 1166, 5, 3722, 17528, 9, 521, 11...   \n 44  [4, 50118, 50118, 36328, 939, 679, 5, 7169, 15...   \n \n                                        offset_mapping  \\\n 83  [(0, 3), (4, 8), (9, 17), (18, 19), (20, 24), ...   \n 53  [(0, 1), (1, 4), (5, 14), (14, 15), (15, 16), ...   \n 70  [(0, 2), (2, 5), (5, 7), (7, 8), (8, 12), (12,...   \n 45  [(0, 6), (7, 16), (17, 21), (22, 25), (26, 35)...   \n 44  [(0, 1), (1, 2), (2, 3), (3, 10), (11, 12), (1...   \n \n                                             rle_token  \n 83  [(1, 0, 84), (2, 85, 98), (4, 98, 109), (4, 11...  \n 53  [(2, 6, 21), (4, 22, 41), (6, 42, 55), (7, 55,...  \n 70  [(2, 39, 55), (4, 58, 103), (3, 106, 231), (4,...  \n 45  [(1, 0, 11), (2, 12, 23), (4, 24, 52), (3, 55,...  \n 44  [(2, 3, 30), (3, 31, 134), (3, 137, 162), (4, ...  )"},"metadata":{}}]},{"cell_type":"code","source":"if LOG_TO_WANDB and save_to_wandb:\n    data.remove_columns([#'input_ids', \n                         #'rle_token', \n                         'labels', \n                         #'offset_mapping'\n    ]).save_to_disk('data')\n\n    artifact = wandb.Artifact('data', description='train test split', type='dataset')\n    artifact.add_dir('data')\n    wandb.log_artifact(artifact)\n    !ls -sRh data\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:54.02938Z","iopub.execute_input":"2022-03-02T07:39:54.029701Z","iopub.status.idle":"2022-03-02T07:39:54.039118Z","shell.execute_reply.started":"2022-03-02T07:39:54.029661Z","shell.execute_reply":"2022-03-02T07:39:54.037959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if  not isinstance(data.column_names, dict):\n#     data = data.train_test_split(test_size=0.1, shuffle=True, seed=42)\n    \n# chunk_data = to_chunk_data(data, \n#                            chunk_len=max_length, \n#                            stride=stride, \n#                            prefix=[tokenizer.bos_token_id],\n#                            postfix=[tokenizer.eos_token_id])\n# chunk_data","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:54.040586Z","iopub.execute_input":"2022-03-02T07:39:54.041552Z","iopub.status.idle":"2022-03-02T07:39:54.051163Z","shell.execute_reply.started":"2022-03-02T07:39:54.041489Z","shell.execute_reply":"2022-03-02T07:39:54.050131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n\ndef chunk_mapping(chunk_len=512,\n                  stride=256,\n                  rle_len=None,\n                  prefix=[0], \n                  postfix=[2]):\n    extra_len = len(prefix)+len(postfix)\n    chunk_len = chunk_len-extra_len\n    \n    def f(examples, idx=None):\n        res = dict(input_ids=[], rle_token=[], offset=[], text_id=[])\n        for ids, token_rle, xid in zip(examples['input_ids'], \n                                    examples.get('rle_token', itertools.repeat([])), \n                                    examples['id']):\n            linput = len(ids)\n            offset = 0\n            while linput > offset:\n                offset = max(0, min(offset, linput-chunk_len))\n                end_pos = min(linput, offset+chunk_len)\n                s = slice(offset, end_pos)\n                res['input_ids'].append(prefix+ids[s]+postfix)\n                res['text_id'].append(xid)\n                res['offset'].append(offset)\n                rle = [type(rle)((rle[0], \n                                  max(rle[1]-offset,0) + len(prefix), \n                                  min(rle[2], end_pos) - offset + len(prefix)))\n                       for rle in token_rle if rle[2]>offset and rle[1]<end_pos]\n                if rle_len is not None:\n                    rle=rle[:rle_len]\n                res['rle_token'].append(rle)\n                offset = offset+stride if end_pos<linput else linput\n\n        if not any(res['rle_token']):\n            res.pop('rle_token')\n        return res\n    return f\n\ndef chop_up(data, tokenizer, max_length, stride, max_rle_len=None):\n    examples = {k: list(data[k]) for k in data.columns}\n    examples['id'] = map(int, data.index.values)\n    f = chunk_mapping(chunk_len=max_length, \n                      stride=stride, \n                      rle_len=max_rle_len,\n                      prefix=[tokenizer.bos_token_id],\n                      postfix=[tokenizer.eos_token_id])\n    return f(examples)\n\nimport numpy as np\n\ndef mk_collate_fn(tokenizer, max_length=512, max_rle_length=32):\n    def collate_fn(features):\n        \n        batch = features.copy()\n        p = tokenizer.pad_token_id\n        batch['input_ids'] = np.array([f+[p]*(max_length-len(f)) for f in batch['input_ids']],\n                                      dtype=np.int32)\n        batch['rle_token'] = np.array([f+[(0,-1,-1)]*(max_rle_length-len(f)) for f in batch['rle_token']], \n                                      dtype=np.int32)\n        return batch\n    \n    return collate_fn","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:04:44.228084Z","iopub.execute_input":"2022-03-11T15:04:44.228406Z","iopub.status.idle":"2022-03-11T15:04:44.249895Z","shell.execute_reply.started":"2022-03-11T15:04:44.228368Z","shell.execute_reply":"2022-03-11T15:04:44.248823Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# def chop_up(data, tokenizer, max_length, stride):\n#     examples = {k: list(data[k]) for k in data.columns}\n#     examples['labels'] = list(data['labels'])\n#     examples['id'] = list(data.index.values)\n#     f = chunk_mapping(chunk_len=max_length, \n#                       stride=stride, \n#                       prefix=[tokenizer.bos_token_id],\n#                       postfix=[tokenizer.eos_token_id])\n#     return f(examples)\n\n# def to_records(data):\n#     return [dict(zip(data.keys(), rec))  for rec in zip(*data.values())]\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:45:47.428179Z","iopub.execute_input":"2022-03-05T18:45:47.428517Z","iopub.status.idle":"2022-03-05T18:45:47.437127Z","shell.execute_reply.started":"2022-03-05T18:45:47.428471Z","shell.execute_reply":"2022-03-05T18:45:47.435958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chunk_data = {\n    k: chop_up(v, tokenizer, max_length=max_length, stride=stride, max_rle_len=32)\n    for k,v in data.items()\n}","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:04:50.250015Z","iopub.execute_input":"2022-03-11T15:04:50.250308Z","iopub.status.idle":"2022-03-11T15:04:52.111208Z","shell.execute_reply.started":"2022-03-11T15:04:50.250276Z","shell.execute_reply":"2022-03-11T15:04:52.110418Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import yaml\nprint(yaml.dump(\n    {\n        k: {\n            k0: f'size={len(v0[0])}, type={type(v0[0][0]).__name__}' \n            if isinstance(v0[0], list) else v0[0] \n            for k0, v0 in v.items()\n        } \n     for k,v in chunk_data.items()\n    }\n))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:04:54.564183Z","iopub.execute_input":"2022-03-11T15:04:54.564458Z","iopub.status.idle":"2022-03-11T15:04:54.572274Z","shell.execute_reply.started":"2022-03-11T15:04:54.564431Z","shell.execute_reply":"2022-03-11T15:04:54.571300Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"test:\n  input_ids: size=216, type=int\n  offset: 0\n  rle_token: size=9, type=Block\n  text_id: 10360\ntrain:\n  input_ids: size=512, type=int\n  offset: 0\n  rle_token: size=8, type=Block\n  text_id: 7969\n\n","output_type":"stream"}]},{"cell_type":"code","source":"(data['train'].loc(0)[18]['rle_token'],\n data['train'].loc(0)[18].index.values, #['text_id'][1],\n chunk_data['train']['rle_token'][:4], \n chunk_data['train']['offset'][:4],\n chunk_data['train']['text_id'][:4],\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:47:53.119180Z","iopub.execute_input":"2022-03-11T11:47:53.119500Z","iopub.status.idle":"2022-03-11T11:47:53.131376Z","shell.execute_reply.started":"2022-03-11T11:47:53.119467Z","shell.execute_reply":"2022-03-11T11:47:53.130334Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"([Position(5:21),\n  Claim(22:50),\n  Evidence(105:129),\n  Claim(132:152),\n  Evidence(153:186),\n  Claim(187:199),\n  Evidence(200:252),\n  Concluding Statement(282:383)],\n array(['text', 'rle_char', 'input_ids', 'offset_mapping', 'rle_token'],\n       dtype=object),\n [[Position(6:22), Claim(23:51), Evidence(106:127)],\n  [Evidence(42:66), Claim(69:89), Evidence(90:123), Claim(124:127)],\n  [Evidence(1:2),\n   Claim(5:25),\n   Evidence(26:59),\n   Claim(60:72),\n   Evidence(73:125)],\n  [Claim(1:8), Evidence(9:61), Concluding Statement(91:127)]],\n [0, 64, 128, 192],\n [18, 18, 18, 18])"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.879094Z","iopub.execute_input":"2022-03-02T07:39:55.87966Z","iopub.status.idle":"2022-03-02T07:39:55.902151Z","shell.execute_reply.started":"2022-03-02T07:39:55.879602Z","shell.execute_reply":"2022-03-02T07:39:55.90108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if not has_name(data, 'rle_word'):\n#     from feedback2021.helper import Block\n#     def add_rle_word2(data):\n#         # assert has_name(data, 'offset_mapping'), 'add input_ids first!'\n#         if not has_name(data,'word_mapping'):\n#             data = add_word_mapping(data)\n#         return data.map(lambda x: {'rle_word': [Block(t).inv_map(x['word_mapping']) \n#                                                  for t in x['rle_char']]},\n#                             desc='rle to word coordinates')\n#     data = add_rle_word2(data)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.903714Z","iopub.execute_input":"2022-03-02T07:39:55.904145Z","iopub.status.idle":"2022-03-02T07:39:55.913411Z","shell.execute_reply.started":"2022-03-02T07:39:55.904101Z","shell.execute_reply":"2022-03-02T07:39:55.91245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from collections import defaultdict\n# import numpy as np\n# word_counts = defaultdict(list)\n# from  datasets import concatenate_datasets\n# all_data = concatenate_datasets(list(data.values()))\n# for x in all_data['rle_word']:\n#     for cls_id, start, end  in x:\n#         word_counts[id2label[cls_id]].append(end-start)\n\n# for k, v in word_counts.items():\n#     plt.hist(v,bins=np.arange(1,max(v)+1)-0.5)\n#     plt.title(f'{k} min:{min(v)} max: {max(v)}, 2%,5%: {np.percentile(v,[2,5])}')\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.916479Z","iopub.execute_input":"2022-03-02T07:39:55.918295Z","iopub.status.idle":"2022-03-02T07:39:55.924707Z","shell.execute_reply.started":"2022-03-02T07:39:55.918253Z","shell.execute_reply":"2022-03-02T07:39:55.923809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model and Training","metadata":{}},{"cell_type":"code","source":"# chunk_data = chunk_data.rename_column('labels','label')\n# DataLoader?","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.926033Z","iopub.execute_input":"2022-03-02T07:39:55.92685Z","iopub.status.idle":"2022-03-02T07:39:55.937142Z","shell.execute_reply.started":"2022-03-02T07:39:55.926809Z","shell.execute_reply":"2022-03-02T07:39:55.936155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# def mk_collate_fn(tokenizer, max_length=512):\n#     def collate_fn(features):\n        \n#         batch ={key: np.array([f[key]+[t]*(max_length-len(f[key])) for f in features], dtype=np.int32)\n#                 for t,key in zip([tokenizer.pad_token_id,-100],['input_ids','labels'])}\n#         return batch\n#     return collate_fn\n# from torch.utils.data import DataLoader\n\n# train_dataset = DataLoader(chunk_data_list, shuffle=True, #.remove_columns(['offset', 'text_id']), \n#                            batch_size=16,\n#                            collate_fn=mk_collate_fn(tokenizer, 512))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:39:55.938794Z","iopub.execute_input":"2022-03-02T07:39:55.939108Z","iopub.status.idle":"2022-03-02T07:39:55.951696Z","shell.execute_reply.started":"2022-03-02T07:39:55.93907Z","shell.execute_reply":"2022-03-02T07:39:55.950633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport tensorflow.data as tfdata\n#ds=\n# import numpy as np\n\n# def mk_collate_fn(tokenizer, max_length=512):\n#     def collate_fn(features):\n        \n#         batch = features.copy()\n#         for t, key in zip([tokenizer.pad_token_id,-100], ['input_ids','labels']):\n#             batch[key] = np.array([f+[t]*(max_length-len(f)) for f in batch[key]], \n#                                   dtype=np.int32)\n#         return batch\n    \n#     return collate_fn\n\n    \ncollate_fn = mk_collate_fn(tokenizer, max_length, max_rle_length=32)\n\nds ={k: tfdata.Dataset.from_tensor_slices(collate_fn(v)) for k,v in chunk_data.items()}\n#(chunk_data_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:05:06.442082Z","iopub.execute_input":"2022-03-11T15:05:06.442354Z","iopub.status.idle":"2022-03-11T15:05:13.861696Z","shell.execute_reply.started":"2022-03-11T15:05:06.442327Z","shell.execute_reply":"2022-03-11T15:05:13.860839Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"CPU times: user 7.3 s, sys: 133 ms, total: 7.43 s\nWall time: 7.41 s\n","output_type":"stream"}]},{"cell_type":"code","source":"ds['train']","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:05:26.666008Z","iopub.execute_input":"2022-03-11T15:05:26.666553Z","iopub.status.idle":"2022-03-11T15:05:26.673707Z","shell.execute_reply.started":"2022-03-11T15:05:26.666520Z","shell.execute_reply":"2022-03-11T15:05:26.672736Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<TensorSliceDataset shapes: {input_ids: (512,), rle_token: (32, 3), offset: (), text_id: ()}, types: {input_ids: tf.int32, rle_token: tf.int32, offset: tf.int32, text_id: tf.int32}>"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 16 if kaggle_init.is_tpu_available() else 2\ndummy_data = tfdata.Dataset.from_tensor_slices(\n    {\n        'input_ids': np.zeros((batch_size, max_length), dtype=np.int32),\n        'rle_token': np.array([[(0,-1,-1)]*max_rle_length]*batch_size, dtype=np.int32),\n        # 'labels': -100*np.ones((batch_size, max_length), dtype=np.int32),\n        'text_id': -1*np.ones(batch_size, dtype=np.int32),\n        ## np.array([-1]*batch_size), #np.array(['0'*11]*batch_size),\n        'offset': np.zeros(batch_size, dtype=np.int32)\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:05:32.201989Z","iopub.execute_input":"2022-03-11T15:05:32.202278Z","iopub.status.idle":"2022-03-11T15:05:32.212588Z","shell.execute_reply.started":"2022-03-11T15:05:32.202246Z","shell.execute_reply":"2022-03-11T15:05:32.211933Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"dummy_data","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:05:36.390909Z","iopub.execute_input":"2022-03-11T15:05:36.391198Z","iopub.status.idle":"2022-03-11T15:05:36.397877Z","shell.execute_reply.started":"2022-03-11T15:05:36.391168Z","shell.execute_reply":"2022-03-11T15:05:36.397032Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<TensorSliceDataset shapes: {input_ids: (512,), rle_token: (32, 3), text_id: (), offset: ()}, types: {input_ids: tf.int32, rle_token: tf.int32, text_id: tf.int32, offset: tf.int32}>"},"metadata":{}}]},{"cell_type":"code","source":"import jax\njax.devices(), jax.device_count()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:05:39.076006Z","iopub.execute_input":"2022-03-11T15:05:39.076714Z","iopub.status.idle":"2022-03-11T15:05:39.110646Z","shell.execute_reply.started":"2022-03-11T15:05:39.076655Z","shell.execute_reply":"2022-03-11T15:05:39.109649Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"([TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n  TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n  TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n  TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n  TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n  TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n  TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n  TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)],\n 8)"},"metadata":{}}]},{"cell_type":"code","source":"def subset(x):\n    return {k: x[k] for k in ['input_ids', 'labels', 'offset']}\n\ntrain_dataset = (ds['train'].\n                 # map(subset).\n                 repeat().\n                 shuffle(4096).\n                 batch(batch_size=batch_size).\n                 batch(batch_size=jax.device_count()).\n                 prefetch(tfdata.experimental.AUTOTUNE).\n                 as_numpy_iterator())\n\ntest_dataset = (ds['test'].\n                concatenate(dummy_data.repeat(jax.device_count())).\n                #map(subset).\n                batch(batch_size=batch_size, drop_remainder=True).\n                batch(batch_size=jax.device_count(), drop_remainder=True).\n                prefetch(tfdata.experimental.AUTOTUNE)\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:05:42.866017Z","iopub.execute_input":"2022-03-11T15:05:42.866500Z","iopub.status.idle":"2022-03-11T15:05:42.949694Z","shell.execute_reply.started":"2022-03-11T15:05:42.866460Z","shell.execute_reply":"2022-03-11T15:05:42.948611Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"len(ds['test']), len(ds['train'])","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:05:47.951610Z","iopub.execute_input":"2022-03-11T15:05:47.952826Z","iopub.status.idle":"2022-03-11T15:05:47.962129Z","shell.execute_reply.started":"2022-03-11T15:05:47.952768Z","shell.execute_reply":"2022-03-11T15:05:47.960881Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(2904, 25681)"},"metadata":{}}]},{"cell_type":"code","source":"class Metric:\n    def __init__(self):\n        self.reset()\n    def reset(self):\n        self._value = 0\n        self._n = 0\n    def update(self,v):\n        self._n += 1\n        self._value += v\n    def value(self):\n        return self._value/self._n","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.361635Z","iopub.execute_input":"2022-03-02T07:40:15.362448Z","iopub.status.idle":"2022-03-02T07:40:15.372528Z","shell.execute_reply.started":"2022-03-02T07:40:15.362388Z","shell.execute_reply":"2022-03-02T07:40:15.37155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{k: f'shape={v.shape}, dtype={v.dtype}' for k,v in next(iter(train_dataset)).items()}","metadata":{"execution":{"iopub.status.busy":"2022-03-11T10:01:13.715886Z","iopub.execute_input":"2022-03-11T10:01:13.716223Z","iopub.status.idle":"2022-03-11T10:01:13.748783Z","shell.execute_reply.started":"2022-03-11T10:01:13.716188Z","shell.execute_reply":"2022-03-11T10:01:13.747746Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"{'input_ids': 'shape=(2, 2, 128), dtype=int32',\n 'rle_token': 'shape=(2, 2, 32, 3), dtype=int32',\n 'offset': 'shape=(2, 2), dtype=int32',\n 'text_id': 'shape=(2, 2), dtype=int32'}"},"metadata":{}}]},{"cell_type":"code","source":"local_device_count = jax.device_count()\nlocal_device_count","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:40:15.417944Z","iopub.execute_input":"2022-03-02T07:40:15.418445Z","iopub.status.idle":"2022-03-02T07:40:15.425978Z","shell.execute_reply.started":"2022-03-02T07:40:15.418388Z","shell.execute_reply":"2022-03-02T07:40:15.424911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# jnp.broadcast_to(jnp.array([[1,2],[3,4]]), (3,2,2))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T13:30:31.490958Z","iopub.execute_input":"2022-03-11T13:30:31.491910Z","iopub.status.idle":"2022-03-11T13:30:31.536797Z","shell.execute_reply.started":"2022-03-11T13:30:31.491854Z","shell.execute_reply":"2022-03-11T13:30:31.535829Z"},"trusted":true},"execution_count":102,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"DeviceArray([[[1, 2],\n              [3, 4]],\n\n             [[1, 2],\n              [3, 4]],\n\n             [[1, 2],\n              [3, 4]]], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"from feedback2021.hk_roberta import *\n\nclass DecoderLayer(hk.Module):\n    def __init__(self, config, name=None):\n        super().__init__(name=name)\n        self._config = config \n    \n    def __call__(self, features, hidden, mask, is_training):\n        config = self._config\n        \n        init_scale = 2. / config['num_hidden_layers']\n        attn_dropout_rate = config['attention_probs_dropout_prob'] if is_training else 0.\n        hidden_dropout_rate = config['hidden_dropout_prob'] if is_training else 0.\n        ln_kwargs = {} if 'layer_norm_eps' not in config else {'eps': config['layer_norm_eps']}\n        \n        \n        cross_attn = hk.MultiHeadAttention(\n                num_heads=config['num_attention_heads'],\n                key_size=config['hidden_size']//config['num_attention_heads'],\n                w_init_scale=init_scale,\n                name='cross_attention')(hidden, features, features, mask=mask)\n\n        cross_attn = hk.dropout(hk.next_rng_key(), attn_dropout_rate, cross_attn)\n        hidden = hidden + cross_attn\n        hidden = layer_norm(hidden, name='cross_attention_layernorm', **ln_kwargs)\n        \n        h_attn = hk.MultiHeadAttention(\n                num_heads = config['num_attention_heads'],\n                key_size  = config['hidden_size']//config['num_attention_heads'],\n                w_init_scale = init_scale,\n                name='self_attention')(hidden, hidden, hidden, mask=None)\n\n        h_attn = hk.dropout(hk.next_rng_key(), attn_dropout_rate, h_attn)\n        hidden = hidden + h_attn\n        hidden = layer_norm(hidden, name='self_attention_layernorm', **ln_kwargs)\n        \n        \n        h_dense = DenseBlock(config, name='mlp')(hidden)\n        \n        h_dense = hk.dropout(hk.next_rng_key(), hidden_dropout_rate, h_dense)\n        hidden = hidden + h_dense\n        hidden = layer_norm(hidden, name='layernorm', **ln_kwargs)\n        \n        return hidden\n\nclass Decoder(hk.Module):\n    \"\"\"A transformer stack.\"\"\"\n\n    def __init__(self, config, name=None):\n        super().__init__(name=name)\n        self._config = config \n        \n    def __call__(self, \n                 features: jnp.ndarray,\n                 mask: Optional[jnp.ndarray],\n                 is_training: bool) -> jnp.ndarray:\n        \"\"\"Connects the transformer.\n        Args:\n          h: Inputs, [B, T, H].\n          mask: Padding mask, [B, T].\n          is_training: Whether we're training or not.\n        Returns:\n          Array of shape [B, T, H].\n        \"\"\"\n        config = self._config\n        \n        hidden_size = config['hidden_size']\n        num_token = config['num_token']\n        init_scale = config['initializer_range']\n        \n        if mask is not None:\n            mask = mask[:, None, None, :]\n\n        hidden = hk.get_parameter('hidden', \n                                  [num_token, hidden_size], \n                                  init=hk.initializers.TruncatedNormal(init_scale))\n        \n        hidden = jnp.broadcast_to(hidden, features.shape[:1]+hidden.shape)\n        \n        for i in range(config['num_hidden_layers']):\n            hidden = DecoderLayer(config, name=f'layer_{i}')(features, hidden, mask, is_training=is_training)\n                             \n        return hidden\n\nclass FinalAttention(hk.Module):\n    \"\"\"\n        It takes te hidden vectors and the feature vectors and computes for each hidden vector \n        two probability distribution over the feature vector positions.\n        # Multi-headed attention mechanism.\n\n        # As described in the vanilla Transformer paper:\n        # \"Attention is all you need\" https://arxiv.org/abs/1706.03762\n    \"\"\"\n\n    def __init__(\n          self,\n          config,\n          name=None,\n    ):\n    #       num_heads: int,\n    #       key_size: int,\n    #       w_init_scale: float,\n    #       value_size: Optional[int] = None,\n    #       model_size: Optional[int] = None,\n    #       name: Optional[str] = None,\n    # ):\n    #     \n        super().__init__(name=name)\n        self._config = config\n        self.num_heads = config['num_attention_heads']\n        self.key_size = config['key_size']\n        # self.value_size = value_size or key_size\n        # self.model_size = model_size or key_size * num_heads\n        self.w_init = hk.initializers.VarianceScaling(config['initializer_range'])\n\n    def __call__(\n          self,\n          features: jnp.ndarray,\n          hidden: jnp.ndarray,\n          # value: jnp.ndarray,\n          mask: Optional[jnp.ndarray] = None,\n    ) -> jnp.ndarray:\n        \"\"\"Compute (optionally masked) MHA with queries, keys & values.\"\"\"\n        \n        config = self._config\n        \n        query_heads = self._linear_projection(features, \"query\")\n        key_heads = self._linear_projection(hidden, \"key\")\n        #value_heads = self._linear_projection(value, self.value_size, \"value\")\n\n        attn_logits = jnp.einsum(\"...thd,...Thd->...tTh\", query_heads, key_heads)\n        sqrt_key_size = np.sqrt(self.key_size).astype(hidden.dtype)\n        attn_logits = attn_logits / sqrt_key_size\n        if mask is not None:\n            mask = mask[:, :,  None, None]\n            assert len(mask.shape) == len(attn_logits.shape)\n            attn_logits = jnp.where(mask, attn_logits, -1e30)\n\n        return attn_logits\n        # attn_weights = jax.nn.softmax(attn_logits)\n        # attn = jnp.einsum(\"...htT,...Thd->...thd\", attn_weights, value_heads)\n        # Concatenate attention matrix of all heads into a single vector.\n        # attn_vec = jnp.reshape(attn, (*query.shape[:-1], -1))\n\n        # return hk.Linear(self.model_size, w_init=self.w_init)(attn_vec)\n\n    @hk.transparent\n    def _linear_projection(\n          self,\n          x: jnp.ndarray,\n          # head_size: int,\n          name: Optional[str] = None\n    ) -> jnp.ndarray:\n        y = hk.Linear(self.num_heads * self.key_size, w_init=self.w_init, name=name)(x)\n        return y.reshape((*x.shape[:-1], self.num_heads, self.key_size))\n\n# class FinalAttention(hk.Module):\n#     \"\"\"A transformer stack.\"\"\"\n\n#     def __init__(self, config, name=None):\n#         super().__init__(name=name)\n#         self._config = config \n\n#     def __call__(self, features, hidden, mask=None, is_training=False):\n#         config = self._config\n#         init_scale = config['initializer_range']\n        \n#         if mask is not None:\n#             mask = mask[:, :,  None]\n\n        \n#         output = hk.MultiHeadAttention(\n#                 num_heads=config['num_attention_heads'],\n#                 key_size=config['hidden_size']//config['num_attention_heads'],\n#                 model_size=config['output_size'],\n#                 w_init_scale=init_scale,\n#                 name='final_attention')(features, hidden, hidden, mask=None)\n\n#         if mask is not None:\n#             assert len(mask.shape) == len(output.shape), \"mask shape=%s output shape= %s\" % (mask.shape,output.shape)\n#             output = jnp.where(mask, output, -1e30)\n            \n#         return output\n    \ndef check_config(config):\n    return config\n    \ndef mk_decoder_fn(config):\n    \n    config = check_config(config)\n    \n    def fn(features, mask, is_training=True):\n        \n        #input_embeddings, input_mask = Embedding(config)(data, is_training)\n        \n        \n        decoder = Decoder(config['decoder'], name='decoder')\n        hidden = decoder(features, mask, is_training=is_training)\n        final_attn = FinalAttention(config['final_attn'], name='final_attn')\n        pos_logits = final_attn(features, hidden, mask) #, is_training=is_training)\n        logits = hk.Linear(len(config['id2label']))(hidden)\n        #print(pos_logits.shape, logits.shape, hidden.shape)\n        return pos_logits, logits\n    \n    return fn\n\ndef mk_feature_fn(config):\n\n    config = check_config(config)\n    \n    def fn(data, is_training=True):\n        \n        embeddings, mask = Embedding(config)(data, is_training)\n        transformer = Transformer(config, name='encoder')\n        features = transformer(embeddings, mask, is_training)\n        #print(features.shape, mask.shape)\n        return features, mask\n    \n    return fn\n    \ndef mk_loss_fn(config):\n    \n    def loss_fn(pos_logits, logits, data):\n    #                params,\n    #                rng,\n    #                data: Mapping[str, jnp.ndarray],\n    #                is_training: bool = True) -> jnp.ndarray:\n        \"\"\"Compute the loss on data wrt params.\"\"\"\n\n\n    #     logits = forward_fn(params, rng, data, is_training)\n        cls_target = data['rle_token'][...,0]\n        pos_target = data['rle_token'][...,1:]\n        \n        cls_onehot = jax.nn.one_hot(cls_target, len(config['id2label']))\n        assert logits.shape == cls_onehot.shape, \"shape mismatch: %s !=  %s\" %(logits.shape, \n                                                                               cls_onehot.shape)\n        \n        cls_loss = -jnp.mean(cls_onehot * jax.nn.log_softmax(logits))\n        # cls_loss = cls_loss/jnp.clip(jnp.sum(mask), 1)\n\n        mask = jnp.greater(cls_target, 0)\n\n        \n        # pos_logits shape: batch_size x seq_len x num_pred x 2\n        # pos_target shape: batch_size x num_pred x 2\n        # mask shape: batch_size x num_pred \n        # pos_mask.shape = batch_size x seq_len\n\n        pos = jnp.arange(pos_logits.shape[-3])[:, None, None]\n        pos_target = pos_target[:, None, :, :]\n        weights = 1/(jnp.diff(pos_target, axis=-1)+1)\n        dist = jnp.abs(pos-pos_target)*weights\n        \n        mask = mask[:,None,:,None]\n        pos_mask = jnp.greater(data['input_ids'], max(config['pad_token_id'], \n                                                      config['bos_token_id'],\n                                                      config['eos_token_id']))\n        # print(pos_mask.shape, mask.shape, pos_logits.shape)\n        pos_mask = pos_mask[:, :, None, None]*mask\n        \n        pos_loss = -jnp.mean(pos_mask*dist*jax.nn.log_softmax(pos_logits, axis=-3))\n        pos_loss = pos_loss/jnp.clip(jnp.mean(pos_mask),1e-8)\n\n        return cls_loss+pos_loss\n    \n    return loss_fn\n\n    \ndef mk_train_forward_fn(backbone, net, loss_fn):\n    \n    def fn(params, backbone_params, rng, data, is_training=True):\n        rng1, rng2 = jax.random.split(rng)\n        feature, mask = backbone.apply(backbone_params, rng1, data, is_training=is_training)\n        pos_logits, logits = net.apply(params, rng2, feature, mask, is_training=is_training)\n        return loss_fn(pos_logits, logits, data)\n        \n    return fn\n\nclass Updater2:\n    \"\"\"A stateless abstraction around an init_fn/update_fn pair.\n    This extracts some common boilerplate from the training loop.\n    \"\"\"\n\n    def __init__(self, \n                 backbone,\n                 net,\n                 loss_fn,\n                 optimizer: optax.GradientTransformation):\n        \n        self._net_init = net.init\n        self.backbone = backbone\n        self._loss_fn = mk_train_forward_fn(backbone, net, loss_fn)\n        # lambda params,rng, data: loss_fn(net.apply(params, rng, data, is_training=True), data)\n        self._opt = optimizer\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def init(self, rng, data, pretrained_params):\n        \"\"\"Initializes state of the updater.\"\"\"\n        out_rng, init_rng = jax.random.split(rng)\n        features, mask = self.backbone.apply(pretrained_params, init_rng, data)\n        params = self._net_init(init_rng, features, mask)\n#         if pretrained_params is not None:\n#             params = hk.data_structures.merge(params, pretrained_params)\n#         #params = hk.data_structures.map(lambda x: jnp.stack([x]*local_device_count), params)\n        opt_state = self._opt.init(params)\n        # rng = jax.random.PRNGKey(FLAGS.train_init_random_seed)\n        #rng = jnp.broadcast_to(rng, (local_device_count,) + rng.shape)\n        out = dict(\n            step = np.array(0),\n            rng = out_rng,\n            opt_state = opt_state,\n            params = params,\n            backbone_params = pretrained_params,\n            loss = np.array(0),\n        )\n        return out\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def update(self, state: Mapping[str, Any], data: Mapping[str, jnp.ndarray]):\n        \"\"\"Updates the state using some data and returns metrics.\"\"\"\n        rng, new_rng = jax.random.split(state['rng'])\n        params = state['params']\n        backbone_params = state['backbone_params']\n        loss, grads = jax.value_and_grad(self._loss_fn)(params, backbone_params, rng, data)\n\n        if compute_on_tpu:\n            grads = jax.lax.pmean(grads, 'i')\n\n\n        updates, opt_state = self._opt.update(grads, state['opt_state'])\n        params = optax.apply_updates(params, updates)\n\n        new_state = {\n            'step': state['step'] + 1,\n            'rng': new_rng,\n            'opt_state': opt_state,\n            'params': params,\n            'backbone_params': backbone_params,\n            'loss': state['loss'] + loss\n        }\n\n        return new_state \n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:10:36.959703Z","iopub.execute_input":"2022-03-11T15:10:36.960308Z","iopub.status.idle":"2022-03-11T15:10:37.052127Z","shell.execute_reply.started":"2022-03-11T15:10:36.960246Z","shell.execute_reply":"2022-03-11T15:10:37.050696Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def mk_net_eval2(net, backbone):\n    def run_net(params, backbone_params, rng, data):\n        rng1, rng2 = jax.random.split(rng)\n        feature, mask = backbone.apply(backbone_params, rng1, data, is_training=False)\n        pos_logits, logits = net.apply(params, rng2, feature, mask, is_training=False)\n        return pos_logits, logits\n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    return run_net\n\ndef predict2(net, state, data):\n    predictions = []\n    data = data.map(lambda x: ({'input_ids':x['input_ids']},\n                               x['input_ids'],\n                               x['text_id'], \n                               x['offset'])).as_numpy_iterator()\n    \n    params = state['params']\n    backbone_params=state['backbone_params']\n    rng = state['rng']\n    \n    for data, ids, text_id, offset  in data:   \n        # feature, mask = backbone.apply(backbone_params, rng1, data, is_training=False)\n        pos_logits, logits = net(params, backbone_params, rng, data) \n        #feature, mask, is_training=False)\n        pos = jnp.arange(pos_logits.shape[-3])[:, None, None]\n        pos = jnp.round(jnp.sum(jax.nn.softmax(pos_logits, axis=-3)*pos, axis=-3))\n        cls_pred = jax.device_get(jnp.argmax(logits, axis=-1))\n        cls_pred = cls_pred.reshape((-1,)+cls_pred.shape[2:])\n        del logits\n        pos0 = jax.device_get(pos)\n        pos0 = pos0.reshape((-1,)+pos0.shape[2:])\n        del pos\n        preds = [[tuple((cls_id, start, end)) for cls_id,(start,end) in zip(cls_ids,pos) if cls_id>0]\n                 for cls_ids, pos in zip(cls_pred, pos0)]\n        ## logits0 = logits0.reshape((-1,)+logits0.shape[2:])\n        ## 0,1,2 are <s> </s> <pad>!\n        # mask = (ids>2).reshape((-1,)+ids.shape[2:])\n        predictions.extend(zip(text_id.reshape(-1), \n                               offset.reshape(-1), \n                               preds))\n                               # (logit[m] for logit,m in zip(logits0, mask))))\n                               # data['input_ids'].reshape((-1,)+data['input_ids']))\n    return predictions\n\nfrom collections import defaultdict\n\n\ndef collect_chunks2(raw_predictions):\n    predictions = defaultdict(set)\n    for idx, offset, pred in raw_predictions:\n        predictions[idx].update([(cls_id, start-1+offset, end-1+offset) \n                                 for cls_id, start, end in pred])\n    return dict(predictions)\n\n# def combine_offset_list(offset_lst):\n#     offset_lst = [(offset, np.asarray(c)) for offset, c in offset_lst]\n#     total_len = max(offset+len(c) for offset, c in offset_lst)\n#     chunk_shape = offset_lst[0][1].shape\n#     res = np.zeros((total_len,)+chunk_shape[1:])\n#     cnt = np.zeros((total_len,)+(1,)*(len(chunk_shape)-1))\n#     for i, (o, c) in enumerate(offset_lst):\n#         res[o:o+len(c)] += c\n#         cnt[o:o+len(c)] += 1\n#     return res/cnt.clip(1)\n\nfrom feedback2021.helper import label2id, id2label, Block\n# def pred_rle(pred):\n    \n#     res = []\n#     cur_cls = -1\n#     min_cls = label2id.get('None',-1)\n    \n#     for i, cls_id in enumerate(pred):\n        \n#         if (cur_cls>min_cls) and (cur_cls!=cls_id):\n#             res.append(Block((cur_cls, start, i)))\n#             cur_cls = -1\n        \n#         if cls_id>min_cls and cur_cls==-1: \n#             cur_cls, start = cls_id, i\n    \n#     if cur_cls>min_cls:\n#         res.append(Block((cur_cls, start, i+1)))\n    \n#     return res\n\n\nimport  feedback2021.metric as metric\n\ndef compute_metric2(eval_net, state, chunked_data, raw_df):\n    predictions = predict2(eval_net, state, chunked_data)\n    predictions = collect_chunks2(predictions)\n#     predictions = {k: pred_rle(np.argmax(combine_offset_list(v), axis=-1)) \n#                    for k,v in predictions.items()}\n    \n    raw_data = zip(raw_df.index, raw_df['rle_token']) #offset_mapping'], raw_df['word_mapping'])\n#     predictions = [\n#             [b.map(om).inv_map(wm) for b in predictions[idx]]\n#             for idx, om, wm in raw_data\n#         ]\n\n    scores = np.array([ \n            metric.score_example(y_pred=predictions[idx], y_true=y_true)\n            for idx,y_true in raw_data #zip(predictions, raw_df['rle_word'])\n        ]).sum(axis=0)\n        \n    res = {id2label[i+1]: metric.f1(*score) for i, score in enumerate(scores)}\n    res['f1'] = sum(res.values())/len(res)\n        \n    return res\n    \n    \n    \n\n## predict(jax.pmap(net.apply, axis_name='i'), state, dataset)\n\n        \n# def get_predictions(net, loss_fn, state, test_ds):\n\n#     def run_net(state, data):\n#         logits = net.apply(state['params'], state['rng'], data, is_training=False)\n#         loss = loss_fn(logits, data)\n#         pred = jax.numpy.argmax(logits, axis=-1)\n#         state['loss'] = state['loss'] + loss\n#         return pred, state\n        \n    \n#     run_net = jax.pmap(run_net, axis_name='i')\n#     predictions = []\n#     for batch in test_ds.as_numpy_iterator():\n#         pred, state = run_net(state, batch)\n#         predictions.append(pred)\n        \n#     predictions = [ pred \n#                     for preds in jax.device_get(predictions) \n#                     for pred in preds.reshape((-1,) + preds.shape[2:]) ]\n#     return predictions, state\n\n# def eval_net(net, loss_fn, state, test_ds):\n\n#     def run_net(state, data, loss, cnt):\n#         cnt0 = jnp.greater(data['labels'].max(axis=-1),0).sum()\n#         logits = net.apply(state['params'], state['rng'], data, is_training=False)\n#         loss0 = loss_fn(logits, data) * data['labels'].shape[0]\n#         #pred = jax.numpy.argmax(logits, axis=-1)\n#         #state['loss'] = state['loss'] + loss\n#         return loss + loss0, cnt + cnt0\n        \n    \n#     run_net = jax.pmap(run_net, axis_name='i')\n#     #predictions = []\n#     loss = np.zeros(jax.device_count())\n#     cnt = np.zeros(jax.device_count())\n#     for batch in test_ds.as_numpy_iterator():\n#         loss, cnt = run_net(state, batch, loss, cnt)\n#         # predictions.append(pred)\n#     return float(loss.sum()/cnt.sum())","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:06:08.339557Z","iopub.execute_input":"2022-03-11T15:06:08.340892Z","iopub.status.idle":"2022-03-11T15:06:08.374727Z","shell.execute_reply.started":"2022-03-11T15:06:08.340782Z","shell.execute_reply":"2022-03-11T15:06:08.373523Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"config=dict(\n    decoder = dict(\n        num_token = max_rle_length,\n        hidden_size = 64*12,\n        initializer_range=0.02,\n        hidden_dropout_prob = 0.1,\n        attention_probs_dropout_prob=0.1,\n        #layer_norm_eps = 1e-5,\n        intermediate_size = 4*64*12\n        hidden_act = 'gelu',\n        num_hidden_layers = 12, # 6,12,24,32?\n        num_attention_heads = 12,\n        ),\n    final_attn = dict(\n        key_size = 64, #16,#64*12,\n        initializer_range=0.02,\n        # hidden_dropout_prob = 0.1,\n        # attention_probs_dropout_prob=0.1,\n        # layer_norm_eps = 1e-5,\n        # intermediate_size = 64, # 4*64*12\n        # hidden_act = 'gelu',\n        # num_hidden_layers = 3, # 6,12,24,32?\n        num_attention_heads = 2,\n        output_size = 2\n    ),\n    pad_token_id =1,\n    vocab_size = 10, #52000\n    max_position_embeddings = 32, # 514\n    \n    hidden_size = 6*16,#64*12,\n    initializer_range=0.02,\n    hidden_dropout_prob = 0.1,\n    attention_probs_dropout_prob=0.1,\n    #layer_norm_eps = 1e-5,\n    intermediate_size = 64, # 4*64*12\n    hidden_act = 'gelu',\n    num_hidden_layers = 2, # 6,12,24,32?\n    num_attention_heads = 6,\n    id2label = id2label,\n)\nconfig","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import haiku as hk\nimport jax.numpy as jnp\nimport optax\nimport functools\nfrom typing import Any, Mapping\n\ndef mk_loss_fn(config):\n    \n    def loss_fn(logits, data):\n    #                params,\n    #                rng,\n    #                data: Mapping[str, jnp.ndarray],\n    #                is_training: bool = True) -> jnp.ndarray:\n        \"\"\"Compute the loss on data wrt params.\"\"\"\n\n\n    #     logits = forward_fn(params, rng, data, is_training)\n        targets = jax.nn.one_hot(data['labels'], len(config['id2label']))\n        assert logits.shape == targets.shape\n\n        mask = jnp.not_equal(data['input_ids'], config['pad_token_id'])\n        mask = mask * jnp.greater_equal(data['labels'], 0)\n        loss = -jnp.sum(targets * jax.nn.log_softmax(logits), axis=-1)\n        loss = jnp.sum(loss * mask, axis=-1) / jnp.clip(jnp.sum(mask, axis=-1),1)\n\n        return jnp.mean(loss)\n    \n    return loss_fn\n\nclass Updater:\n    \"\"\"A stateless abstraction around an init_fn/update_fn pair.\n    This extracts some common boilerplate from the training loop.\n    \"\"\"\n\n    def __init__(self, \n                 net, \n                 loss_fn,\n                 optimizer: optax.GradientTransformation):\n        \n        self._net_init = net.init\n        self._loss_fn = lambda params,rng, data: loss_fn(net.apply(params, rng, data, is_training=True), data)\n        self._opt = optimizer\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def init(self, rng, data, pretrained_params=None):\n        \"\"\"Initializes state of the updater.\"\"\"\n        out_rng, init_rng = jax.random.split(rng)\n        params = self._net_init(init_rng, data)\n        if pretrained_params is not None:\n            params = hk.data_structures.merge(params, pretrained_params)\n        #params = hk.data_structures.map(lambda x: jnp.stack([x]*local_device_count), params)\n        opt_state = self._opt.init(params)\n        # rng = jax.random.PRNGKey(FLAGS.train_init_random_seed)\n        #rng = jnp.broadcast_to(rng, (local_device_count,) + rng.shape)\n        out = dict(\n            step=np.array(0),\n            rng=out_rng,\n            opt_state=opt_state,\n            params=params,\n            loss=np.array(0),\n        )\n        return out\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def update(self, state: Mapping[str, Any], data: Mapping[str, jnp.ndarray]):\n        \"\"\"Updates the state using some data and returns metrics.\"\"\"\n        rng, new_rng = jax.random.split(state['rng'])\n        params = state['params']\n        loss, grads = jax.value_and_grad(self._loss_fn)(params, rng, data)\n\n        if compute_on_tpu:\n            grads = jax.lax.pmean(grads, 'i')\n\n\n        updates, opt_state = self._opt.update(grads, state['opt_state'])\n        params = optax.apply_updates(params, updates)\n\n        new_state = {\n            'step': state['step'] + 1,\n            'rng': new_rng,\n            'opt_state': opt_state,\n            'params': params,\n            'loss': state['loss'] + loss\n        }\n\n        return new_state \n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:07:34.485535Z","iopub.execute_input":"2022-03-11T15:07:34.486587Z","iopub.status.idle":"2022-03-11T15:07:34.520311Z","shell.execute_reply.started":"2022-03-11T15:07:34.486523Z","shell.execute_reply":"2022-03-11T15:07:34.519016Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def mk_net_eval(net):\n    def run_net(param, rng, data):\n        return net.apply(param, rng, data, is_training=False)\n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    return run_net\n\ndef predict(net, state, data):\n    predictions = []\n    data = data.map(lambda x: ({'input_ids':x['input_ids']},\n                               x['input_ids'],\n                               x['text_id'], \n                               x['offset'])).as_numpy_iterator()\n    \n    \n    for data, ids, text_id, offset  in data:    \n        logits = net(state['params'], state['rng'], data)\n        logits0 = jax.device_get(logits)\n        del logits\n        logits0 = logits0.reshape((-1,)+logits0.shape[2:])\n        ## 0,1,2 are <s> </s> <pad>!\n        mask = (ids>2).reshape((-1,)+ids.shape[2:])\n        predictions.extend(zip(text_id.reshape(-1), \n                               offset.reshape(-1), \n                               (logit[m] for logit,m in zip(logits0, mask))))\n                               #data['input_ids'].reshape((-1,)+data['input_ids']))\n    return predictions\n\nfrom collections import defaultdict\ndef collect_chunks(raw_predictions):\n    predictions = defaultdict(list)\n    for idx, offset, logit in raw_predictions:\n        predictions[idx].append((offset, logit))\n    return dict(predictions)\n\ndef combine_offset_list(offset_lst):\n    offset_lst = [(offset, np.asarray(c)) for offset, c in offset_lst]\n    total_len = max(offset+len(c) for offset, c in offset_lst)\n    chunk_shape = offset_lst[0][1].shape\n    res = np.zeros((total_len,)+chunk_shape[1:])\n    cnt = np.zeros((total_len,)+(1,)*(len(chunk_shape)-1))\n    for i, (o, c) in enumerate(offset_lst):\n        res[o:o+len(c)] += c\n        cnt[o:o+len(c)] += 1\n    return res/cnt.clip(1)\n\nfrom feedback2021.helper import label2id, id2label, Block\ndef pred_rle(pred):\n    \n    res = []\n    cur_cls = -1\n    min_cls = label2id.get('None',-1)\n    \n    for i, cls_id in enumerate(pred):\n        \n        if (cur_cls>min_cls) and (cur_cls!=cls_id):\n            res.append(Block((cur_cls, start, i)))\n            cur_cls = -1\n        \n        if cls_id>min_cls and cur_cls==-1: \n            cur_cls, start = cls_id, i\n    \n    if cur_cls>min_cls:\n        res.append(Block((cur_cls, start, i+1)))\n    \n    return res\n\n\nimport  feedback2021.metric as metric\n\ndef compute_metric(net, state, chunked_data, raw_df):\n    predictions = predict(net, state, chunked_data)\n    predictions = collect_chunks(predictions)\n    predictions = {k: pred_rle(np.argmax(combine_offset_list(v), axis=-1)) \n                   for k,v in predictions.items()}\n    \n    raw_data = zip(raw_df.index, raw_df['offset_mapping'], raw_df['word_mapping'])\n    predictions = [\n            [b.map(om).inv_map(wm) for b in predictions[idx]]\n            for idx, om, wm in raw_data\n        ]\n\n    scores = np.array([ \n            metric.score_example(y_pred=y_pred, y_true=y_true)\n            for y_pred,y_true in zip(predictions, raw_df['rle_word'])\n        ]).sum(axis=0)\n        \n    res = {id2label[i+1]: metric.f1(*score) for i, score in enumerate(scores)}\n    res['f1'] = sum(res.values())/len(res)\n        \n    return res\n    \n    \n    \n\n## predict(jax.pmap(net.apply, axis_name='i'), state, dataset)\n\n        \ndef get_predictions(net, loss_fn, state, test_ds):\n\n    def run_net(state, data):\n        logits = net.apply(state['params'], state['rng'], data, is_training=False)\n        loss = loss_fn(logits, data)\n        pred = jax.numpy.argmax(logits, axis=-1)\n        state['loss'] = state['loss'] + loss\n        return pred, state\n        \n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    predictions = []\n    for batch in test_ds.as_numpy_iterator():\n        pred, state = run_net(state, batch)\n        predictions.append(pred)\n        \n    predictions = [ pred \n                    for preds in jax.device_get(predictions) \n                    for pred in preds.reshape((-1,) + preds.shape[2:]) ]\n    return predictions, state\n\ndef eval_net(net, loss_fn, state, test_ds):\n\n    def run_net(state, data, loss, cnt):\n        cnt0 = jnp.greater(data['labels'].max(axis=-1),0).sum()\n        logits = net.apply(state['params'], state['rng'], data, is_training=False)\n        loss0 = loss_fn(logits, data) * data['labels'].shape[0]\n        #pred = jax.numpy.argmax(logits, axis=-1)\n        #state['loss'] = state['loss'] + loss\n        return loss + loss0, cnt + cnt0\n        \n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    #predictions = []\n    loss = np.zeros(jax.device_count())\n    cnt = np.zeros(jax.device_count())\n    for batch in test_ds.as_numpy_iterator():\n        loss, cnt = run_net(state, batch, loss, cnt)\n        # predictions.append(pred)\n    return float(loss.sum()/cnt.sum())","metadata":{"execution":{"iopub.status.busy":"2022-03-05T18:47:09.479987Z","iopub.execute_input":"2022-03-05T18:47:09.480517Z","iopub.status.idle":"2022-03-05T18:47:09.528572Z","shell.execute_reply.started":"2022-03-05T18:47:09.48047Z","shell.execute_reply":"2022-03-05T18:47:09.527405Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Log:\n    def __init__(self, step=0):\n        self.step = step\n        self.start_time = self.prev_time = time.time()\n        \n    def update(self, state):\n        step = int(state['step'][0])\n        step_delta, self.step = step-self.step, step\n        \n        c_time = time.time()\n        time_delta, self.prev_time = c_time - self.prev_time, c_time\n        \n        loss = float(state['loss'].mean())/step_delta\n        state['loss'] = 0*state['loss']\n        \n        return {'step': self.step,\n                'loss': loss,\n                'elapsed_time': time_delta,\n                'total_time':   c_time-self.start_time,\n                'iter_per_sec': time_delta/max(1,step_delta),\n                'sec_per_iter': step_delta/max(1,time_delta),\n               }\n\ndef format_log(log):\n    return \"iteration: {step:<5}, loss: {loss:.4f}, elapsed_time:{elapsed_time:.2f}\".format(**log)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:07:44.446254Z","iopub.execute_input":"2022-03-11T15:07:44.446639Z","iopub.status.idle":"2022-03-11T15:07:44.459169Z","shell.execute_reply.started":"2022-03-11T15:07:44.446598Z","shell.execute_reply":"2022-03-11T15:07:44.458291Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoConfig\n\nconfig = AutoConfig.from_pretrained(model_checkpoint, #'distilroberta-base', \n                                    label2id=label2id, \n                                    id2label=id2label).to_dict()\n\nconfig['decoder']= dict(\n        num_token = max_rle_length,\n        hidden_size = 64*12,\n        initializer_range=0.02,\n        hidden_dropout_prob = 0.1,\n        attention_probs_dropout_prob=0.1,\n        #layer_norm_eps = 1e-5,\n        intermediate_size = 4*64*12,\n        hidden_act = 'gelu',\n        num_hidden_layers = 12, # 6,12,24,32?\n        num_attention_heads = 12,\n        )\n\nconfig['final_attn'] = dict(\n        key_size = 64, #16,#64*12,\n        initializer_range=0.02,\n        # hidden_dropout_prob = 0.1,\n        # attention_probs_dropout_prob=0.1,\n        # layer_norm_eps = 1e-5,\n        # intermediate_size = 64, # 4*64*12\n        # hidden_act = 'gelu',\n        # num_hidden_layers = 3, # 6,12,24,32?\n        num_attention_heads = 2,\n        output_size = 2\n    )\n    \n# config=dict(\n#     decoder = dict(\n#         num_token = 16,\n#         hidden_size = 6*16,#64*12,\n#         initializer_range=0.02,\n#         hidden_dropout_prob = 0.1,\n#         attention_probs_dropout_prob=0.1,\n#         #layer_norm_eps = 1e-5,\n#         intermediate_size = 64, # 4*64*12\n#         hidden_act = 'gelu',\n#         num_hidden_layers = 2, # 6,12,24,32?\n#         num_attention_heads = 6,\n#         ),\n#     final_attn = dict(\n#         key_size = 16,#64*12,\n#         initializer_range=0.02,\n#         # hidden_dropout_prob = 0.1,\n#         # attention_probs_dropout_prob=0.1,\n#         # layer_norm_eps = 1e-5,\n#         # intermediate_size = 64, # 4*64*12\n#         # hidden_act = 'gelu',\n#         # num_hidden_layers = 3, # 6,12,24,32?\n#         num_attention_heads = 2,\n#         output_size = 2\n#     ),\n#     pad_token_id =1,\n#     vocab_size = 10, #52000\n#     max_position_embeddings = 32, # 514\n    \n#     hidden_size = 6*16,#64*12,\n#     initializer_range=0.02,\n#     hidden_dropout_prob = 0.1,\n#     attention_probs_dropout_prob=0.1,\n#     #layer_norm_eps = 1e-5,\n#     intermediate_size = 64, # 4*64*12\n#     hidden_act = 'gelu',\n#     num_hidden_layers = 2, # 6,12,24,32?\n#     num_attention_heads = 6,\n#     id2label = id2label,\n# )\nconfig","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:08:28.871157Z","iopub.execute_input":"2022-03-11T15:08:28.871708Z","iopub.status.idle":"2022-03-11T15:08:29.087883Z","shell.execute_reply.started":"2022-03-11T15:08:28.871648Z","shell.execute_reply":"2022-03-11T15:08:29.086799Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'return_dict': True,\n 'output_hidden_states': False,\n 'output_attentions': False,\n 'torchscript': False,\n 'use_bfloat16': False,\n 'pruned_heads': {},\n 'tie_word_embeddings': True,\n 'is_encoder_decoder': False,\n 'is_decoder': False,\n 'add_cross_attention': False,\n 'tie_encoder_decoder': False,\n 'max_length': 20,\n 'min_length': 0,\n 'do_sample': False,\n 'early_stopping': False,\n 'num_beams': 1,\n 'num_beam_groups': 1,\n 'diversity_penalty': 0.0,\n 'temperature': 1.0,\n 'top_k': 50,\n 'top_p': 1.0,\n 'repetition_penalty': 1.0,\n 'length_penalty': 1.0,\n 'no_repeat_ngram_size': 0,\n 'encoder_no_repeat_ngram_size': 0,\n 'bad_words_ids': None,\n 'num_return_sequences': 1,\n 'chunk_size_feed_forward': 0,\n 'output_scores': False,\n 'return_dict_in_generate': False,\n 'forced_bos_token_id': None,\n 'forced_eos_token_id': None,\n 'remove_invalid_values': False,\n 'architectures': ['RobertaForMaskedLM'],\n 'finetuning_task': None,\n 'id2label': {0: 'None',\n  1: 'Lead',\n  2: 'Position',\n  3: 'Evidence',\n  4: 'Claim',\n  5: 'Concluding Statement',\n  6: 'Counterclaim',\n  7: 'Rebuttal'},\n 'label2id': {'None': 0,\n  'Lead': 1,\n  'Position': 2,\n  'Evidence': 3,\n  'Claim': 4,\n  'Concluding Statement': 5,\n  'Counterclaim': 6,\n  'Rebuttal': 7},\n 'tokenizer_class': None,\n 'prefix': None,\n 'bos_token_id': 0,\n 'pad_token_id': 1,\n 'eos_token_id': 2,\n 'sep_token_id': None,\n 'decoder_start_token_id': None,\n 'task_specific_params': None,\n '_name_or_path': '',\n 'model_type': 'roberta',\n 'vocab_size': 50265,\n 'hidden_size': 768,\n 'num_hidden_layers': 6,\n 'num_attention_heads': 12,\n 'hidden_act': 'gelu',\n 'intermediate_size': 3072,\n 'hidden_dropout_prob': 0.1,\n 'attention_probs_dropout_prob': 0.1,\n 'max_position_embeddings': 514,\n 'type_vocab_size': 1,\n 'initializer_range': 0.02,\n 'layer_norm_eps': 1e-05,\n 'gradient_checkpointing': False,\n 'position_embedding_type': 'absolute',\n 'use_cache': True,\n 'transformers_version': '4.5.1',\n 'decoder': {'num_token': 32,\n  'hidden_size': 768,\n  'initializer_range': 0.02,\n  'hidden_dropout_prob': 0.1,\n  'attention_probs_dropout_prob': 0.1,\n  'intermediate_size': 3072,\n  'hidden_act': 'gelu',\n  'num_hidden_layers': 12,\n  'num_attention_heads': 12},\n 'final_attn': {'key_size': 64,\n  'initializer_range': 0.02,\n  'num_attention_heads': 2,\n  'output_size': 2}}"},"metadata":{}}]},{"cell_type":"code","source":"import logging\nimport time\nfrom transformers import AutoConfig\nfrom feedback2021.hk_roberta import (build_forward_fn, \n                                     lm_loss_fn, \n                                     # GradientUpdater, \n                                     hk, optax, functools, Mapping, jnp, jax)\n\n## global variables\n# batch_size = 16  # Train batch size per core\ntotal_batch_size = batch_size*jax.device_count()\nlearning_rate = 1.25e-5*(total_batch_size/32) # Max learning-rate\ngrad_clip_value = 0.2  # Gradient norm clip value\n\ncheckpoint_dir = '/jax-transformer'  # Directory to store checkpoints\nif just_test:\n    LOG_EVERY = 2\n    MAX_STEPS = 4\nelse:\n    LOG_EVERY = len(ds['train'])//(2*total_batch_size)\n    MAX_STEPS = (4*len(ds['train']))//total_batch_size+1\n\n# config = AutoConfig.from_pretrained(model_checkpoint, #'distilroberta-base', \n#                                     label2id=label2id, \n#                                     id2label=id2label).to_dict()\ntranslation = hk_roberta.weight_name_translation(config=config, prefix='roberta')\npretrained_params = hk_roberta.load_hf_pytorch_weights(model_checkpoint, #'distilroberta-base', \n                                                       translation)\n\nlogging.info = print\nlogging.info('Starting...')\n\nbackbone = hk.transform(mk_feature_fn(config))\nnet = hk.transform(mk_decoder_fn(config))\n\n# forward_fn = build_forward_fn(config)\n# forward_fn = hk.transform(forward_fn)\n\n#loss_fn = functools.partial(lm_loss_fn, forward_fn.apply, config)\nloss_fn = mk_loss_fn(config)\n\nlr_schedule=optax.warmup_cosine_decay_schedule(init_value=0, \n                                               peak_value=1, \n                                               warmup_steps=min(50, MAX_STEPS//6), \n                                               decay_steps=MAX_STEPS-min(50,MAX_STEPS//6), \n                                               end_value=1e-4)\n\noptimizer = optax.chain(\n        optax.clip_by_global_norm(grad_clip_value),\n        optax.adam(learning_rate, b1=0.9, b2=0.99),\n        optax.scale_by_schedule(lr_schedule),\n    )\n\nupdater = Updater2(backbone=backbone, \n                   net=net, \n                   loss_fn=loss_fn, \n                   optimizer=optimizer)\n\n# Initialize parameters.\nlogging.info('Initializing parameters...')\nrng = jax.random.PRNGKey(428)\nbatch = next(iter(train_dataset))\nstate = updater.init(rng, #jnp.broadcast_to(rng, (local_device_count,) + rng.shape), \n                     {k:v[0] for k,v in batch.items()},\n                     pretrained_params=pretrained_params)\nif compute_on_tpu:\n    state = jax.device_put_replicated(state, jax.devices())\n    update = jax.pmap(updater.update, axis_name='i')\nelse:\n    update = updater.update\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:10:43.706651Z","iopub.execute_input":"2022-03-11T15:10:43.707413Z","iopub.status.idle":"2022-03-11T15:11:44.619189Z","shell.execute_reply.started":"2022-03-11T15:10:43.707353Z","shell.execute_reply":"2022-03-11T15:11:44.618100Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"unused torch weights: roberta.embeddings.token_type_embeddings.weight,\nroberta.pooler.dense.weight, roberta.pooler.dense.bias, lm_head.bias,\nlm_head.dense.weight, lm_head.dense.bias, lm_head.layer_norm.weight,\nlm_head.layer_norm.bias, lm_head.decoder.weight\nStarting...\nInitializing parameters...\n","output_type":"stream"}]},{"cell_type":"code","source":"logging.info('Starting train loop...')\ntrain_iter = train_dataset\nlog = Log()\nnet_eval_fn = mk_net_eval2(net, backbone)\nfor step  in range(MAX_STEPS): #enumerate(train_dataset):\n        batch = next(train_iter)\n        state = update(state, batch)\n        # We use JAX runahead to mask data preprocessing and JAX dispatch overheads.\n        # Using values from state/metrics too often will block the runahead and can\n        # cause these overheads to become more prominent.\n        if step % LOG_EVERY == 0 or (step+1)== MAX_STEPS:\n            last_log=log.update(state)\n            logging.info(last_log)\n            print(compute_metric2(net_eval_fn, state, test_dataset, data['test']))\n            # test_loss = eval_net(forward_fn, loss_fn, state, test_dataset)\n            # last_log['test_loss'] = test_loss #float(state['loss'].mean())\n            \n            \n\n# logging.info(last_log)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T15:11:44.621137Z","iopub.execute_input":"2022-03-11T15:11:44.621697Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Starting train loop...\n{'step': 1, 'loss': 47.71409225463867, 'elapsed_time': 94.47561693191528, 'total_time': 94.47561693191528, 'iter_per_sec': 94.47561693191528, 'sec_per_iter': 0.01058474167700497}\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nnet_eval_fn = mk_net_eval2(net, backbone)\n#raw_pred = predict2(net_eval, state, test_dataset)\n#collect_chunks2(raw_pred)\nprint(compute_metric2(net_eval_fn, state, test_dataset, data['test']))\n# data = test_dataset.map(lambda x: ({'input_ids':x['input_ids']},\n#                                x['input_ids'],\n#                                x['text_id'], \n#                                x['offset'])).as_numpy_iterator()\n    \n# params = state['params']\n# backbone_params=state['backbone_params']\n# rng = state['rng']\n    \n# for data, ids, text_id, offset  in data:   \n#     # feature, mask = backbone.apply(backbone_params, rng1, data, is_training=False)\n#     pos_logits, logits = net_eval(params, backbone_params, rng, data) \n#     break","metadata":{"execution":{"iopub.status.busy":"2022-03-11T14:58:51.885330Z","iopub.execute_input":"2022-03-11T14:58:51.885926Z","iopub.status.idle":"2022-03-11T14:59:12.408446Z","shell.execute_reply.started":"2022-03-11T14:58:51.885871Z","shell.execute_reply":"2022-03-11T14:59:12.407482Z"},"trusted":true},"execution_count":158,"outputs":[{"name":"stdout","text":"{'Lead': 0.0, 'Position': 0.0, 'Evidence': 0.0, 'Claim': 0.0, 'Concluding Statement': 0.0, 'Counterclaim': 0.0, 'Rebuttal': 0.0, 'f1': 0.0}\nCPU times: user 30.1 s, sys: 142 ms, total: 30.2 s\nWall time: 20.5 s\n","output_type":"stream"}]},{"cell_type":"code","source":"collect_chunks2(raw_pred)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T14:52:09.281453Z","iopub.execute_input":"2022-03-11T14:52:09.282556Z","iopub.status.idle":"2022-03-11T14:52:09.302488Z","shell.execute_reply.started":"2022-03-11T14:52:09.282507Z","shell.execute_reply":"2022-03-11T14:52:09.300998Z"},"trusted":true},"execution_count":153,"outputs":[{"execution_count":153,"output_type":"execute_result","data":{"text/plain":"{83: {(1, 190.0, 190.0),\n  (4, 62.0, 63.0),\n  (4, 190.0, 190.0),\n  (4, 318.0, 319.0),\n  (4, 446.0, 446.0),\n  (4, 574.0, 575.0),\n  (4, 902.0, 902.0)},\n 53: {(1, 62.0, 63.0), (4, 62.0, 63.0)},\n 70: {(4, 62.0, 62.0),\n  (4, 190.0, 191.0),\n  (4, 318.0, 318.0),\n  (4, 446.0, 446.0),\n  (4, 574.0, 574.0),\n  (4, 623.0, 623.0)},\n 45: {(4, 62.0, 63.0), (4, 190.0, 191.0)},\n 44: {(4, 62.0, 62.0),\n  (4, 190.0, 190.0),\n  (5, 318.0, 319.0),\n  (5, 362.0, 362.0)},\n 39: {(4, 62.0, 63.0), (4, 190.0, 191.0), (4, 318.0, 318.0)},\n 22: {(4, 62.0, 62.0),\n  (4, 190.0, 190.0),\n  (4, 318.0, 318.0),\n  (4, 318.0, 319.0),\n  (4, 385.0, 385.0),\n  (4, 385.0, 386.0)},\n 80: {(1, 62.0, 63.0)},\n 10: set(),\n 0: set(),\n -1: {(4, 62.0, 62.0)}}"},"metadata":{}}]},{"cell_type":"code","source":"(jax.nn.softmax(pos_logits.reshape(-1,*pos_logits.shape[2:]),axis=-3)[0,:,0,0]*jnp.arange(128)).sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T14:41:24.408136Z","iopub.execute_input":"2022-03-11T14:41:24.408479Z","iopub.status.idle":"2022-03-11T14:41:24.453445Z","shell.execute_reply.started":"2022-03-11T14:41:24.408434Z","shell.execute_reply":"2022-03-11T14:41:24.452578Z"},"trusted":true},"execution_count":145,"outputs":[{"execution_count":145,"output_type":"execute_result","data":{"text/plain":"DeviceArray(63.480347, dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"jax.nn.one_hot(jnp.array([1,2]),3)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T13:34:23.895421Z","iopub.execute_input":"2022-03-11T13:34:23.897490Z","iopub.status.idle":"2022-03-11T13:34:23.944703Z","shell.execute_reply.started":"2022-03-11T13:34:23.897415Z","shell.execute_reply":"2022-03-11T13:34:23.943795Z"},"trusted":true},"execution_count":106,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"DeviceArray([[0., 1., 0.],\n             [0., 0., 1.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"net_eval_fn = mk_net_eval(forward_fn)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:50:45.448387Z","iopub.execute_input":"2022-03-02T07:50:45.449598Z","iopub.status.idle":"2022-03-02T07:50:45.45891Z","shell.execute_reply.started":"2022-03-02T07:50:45.449542Z","shell.execute_reply":"2022-03-02T07:50:45.457765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(compute_metric(net_eval_fn, state, test_dataset, data['test']))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T07:51:22.812991Z","iopub.execute_input":"2022-03-02T07:51:22.813397Z","iopub.status.idle":"2022-03-02T07:51:34.447243Z","shell.execute_reply.started":"2022-03-02T07:51:22.813356Z","shell.execute_reply":"2022-03-02T07:51:34.446075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = get_predictions(forward_fn, loss_fn, state=state, test_ds=test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:35:38.784742Z","iopub.execute_input":"2022-02-25T12:35:38.785273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# next(test_dataset.as_numpy_iterator())\n#next(iter(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:35:26.825227Z","iopub.execute_input":"2022-02-25T12:35:26.825509Z","iopub.status.idle":"2022-02-25T12:35:26.879572Z","shell.execute_reply.started":"2022-02-25T12:35:26.825481Z","shell.execute_reply":"2022-02-25T12:35:26.878887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(pred), pred[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:50:54.188065Z","iopub.execute_input":"2022-02-24T08:50:54.188883Z","iopub.status.idle":"2022-02-24T08:50:54.195233Z","shell.execute_reply.started":"2022-02-24T08:50:54.188841Z","shell.execute_reply":"2022-02-24T08:50:54.19407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = hk.data_structures.map(lambda name,module,x: x[0], state['params'])\nimport pickle\nwith open('params.pkl','wb') as f:\n    pickle.dump(params, f)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T06:13:23.821943Z","iopub.execute_input":"2022-02-23T06:13:23.822508Z","iopub.status.idle":"2022-02-23T06:13:27.022087Z","shell.execute_reply.started":"2022-02-23T06:13:23.822465Z","shell.execute_reply":"2022-02-23T06:13:27.020853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shraded_ds = [list(ds['train'].shard(8, i).as_numpy_iterator()) for i in range(8)]","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:00:08.984632Z","iopub.execute_input":"2022-02-26T06:00:08.985611Z","iopub.status.idle":"2022-02-26T06:00:25.119974Z","shell.execute_reply.started":"2022-02-26T06:00:08.985566Z","shell.execute_reply":"2022-02-26T06:00:25.118793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sharded_ds = jax.device_put_sharded(shards=shraded_ds, devices=jax.devices())","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:01:13.078175Z","iopub.execute_input":"2022-02-26T06:01:13.079144Z","iopub.status.idle":"2022-02-26T06:01:42.867983Z","shell.execute_reply.started":"2022-02-26T06:01:13.079094Z","shell.execute_reply":"2022-02-26T06:01:40.989601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_schedule=optax.warmup_cosine_decay_schedule(init_value=0, \n                                               peak_value=1, \n                                               warmup_steps=500, \n                                               decay_steps=8500, \n                                               end_value=1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:41:44.23837Z","iopub.execute_input":"2022-02-21T06:41:44.238975Z","iopub.status.idle":"2022-02-21T06:41:44.245739Z","shell.execute_reply.started":"2022-02-21T06:41:44.238926Z","shell.execute_reply":"2022-02-21T06:41:44.244518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jaxlib, jax\njaxlib.__version__, jax.__version__, hk.__version__","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:45:48.632171Z","iopub.execute_input":"2022-02-21T06:45:48.632588Z","iopub.status.idle":"2022-02-21T06:45:48.640181Z","shell.execute_reply.started":"2022-02-21T06:45:48.632543Z","shell.execute_reply":"2022-02-21T06:45:48.639215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt = np.arange(0,9000,10)\nlr = [lr_schedule(jnp.array([i])) for i in cnt]\nplt.plot(cnt, lr)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:41:48.464737Z","iopub.execute_input":"2022-02-21T06:41:48.465445Z","iopub.status.idle":"2022-02-21T06:42:26.896087Z","shell.execute_reply.started":"2022-02-21T06:41:48.465381Z","shell.execute_reply":"2022-02-21T06:42:26.893875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{'loss': 2.4778389930725098, 'step': 0.0, 'steps_per_sec': 13.779059174634387}\n{'loss': 1.3683964014053345, 'step': 500.0, 'steps_per_sec': 2.5767113856201855}\n{'loss': 1.6631159782409668, 'step': 1000.0, 'steps_per_sec': 2.57725389686341}\n{'loss': 1.3581798076629639, 'step': 1500.0, 'steps_per_sec': 2.5771785561488483}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{k:v.shape for k,v in data.items()}","metadata":{"execution":{"iopub.status.busy":"2022-02-26T05:57:06.831234Z","iopub.execute_input":"2022-02-26T05:57:06.831874Z","iopub.status.idle":"2022-02-26T05:57:06.840862Z","shell.execute_reply.started":"2022-02-26T05:57:06.831826Z","shell.execute_reply":"2022-02-26T05:57:06.839748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jax.numpy.array([1,1])\n#jax.device_get('gpu')\n#jax.devices('gpu')\n! nvcc --version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n# TRAINING HYPERPARAMS\neffective_batch_size = 32\nmax_steps = 4000\nlog_steps = 500\n#n_step_examples = 8*500\nbatch_size = 16\ngrad_accumulation = effective_batch_size//batch_size\nlearning_rate = 5e-5\nweight_decay = 0.01\nwarmup_ratio = 0.1\nn_epochs = 3\nmodel_name = model_checkpoint.split(\"/\")[-1]\ntraining_args = TrainingArguments(\n    f\"{model_name}-{task}\",\n    evaluation_strategy = \"steps\",\n    eval_steps = log_steps,\n    logging_strategy = \"steps\",\n    logging_steps = log_steps,\n    save_strategy = \"steps\",\n    save_steps = log_steps,\n    learning_rate = learning_rate,\n    per_device_train_batch_size = batch_size,\n    per_device_eval_batch_size = batch_size,\n    #num_train_epochs = n_epochs,\n    max_steps = max_steps,\n    weight_decay = weight_decay,\n    report_to = 'wandb', \n    gradient_accumulation_steps = grad_accumulation,\n    warmup_steps = int(1.5*(log_steps)),\n    # logging_steps = 100,\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    greater_is_better=True,\n)\n#training_args","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['test']=add_rle_word2(data['test'])\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=chunk_data[\"train\"].remove_columns(['offset', 'text_id']), #.select(range(100)),\n    eval_dataset=chunk_data[\"test\"].remove_columns(['offset', 'text_id']), #.select(range(100)),\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=mk_binary_metric(chunk_ds=chunk_data['test'],\n                                     orig_ds=data['test'])\n    #,\n    #                                 min_word_cnt=[0,10,5,10,3,10,6,6]), #.select(range(100))), \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.save_model(model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wandb.init()\nimport pickle\nfrom feedback2021.postprocess import mk_prediction_transform\nfor k,v in chunk_data.items():\n    predictions = trainer.predict(v.remove_columns(['offset', 'text_id']))\n    prediction_transform = mk_binary_prediction_transform(chunk_ds=v, orig_ds=data[k])\n    predictions = prediction_transform(predictions[0])\n    with open(f'{k}_predictions.pkl','wb') as f:\n        pickle.dump(predictions, f)\n    wandb.save(f'{k}_predictions.pkl','./','now')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! rm longformer-base-4096-token_classification/ -rf\n#!rm distilroberta-base-token_classification -rf\n! ls -sh distilroberta-base-1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# From this point on there is no need to gpu!","metadata":{"execution":{"iopub.execute_input":"2021-12-30T06:52:35.965148Z","iopub.status.busy":"2021-12-30T06:52:35.964896Z","iopub.status.idle":"2021-12-30T06:52:36.089436Z","shell.execute_reply":"2021-12-30T06:52:36.088549Z","shell.execute_reply.started":"2021-12-30T06:52:35.96512Z"}}},{"cell_type":"code","source":"prediction_file = wandb.restore('predictions.pkl', run_path='prvi/huggingface/d17yam8m')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_file_name = 'test_predictions.pkl' #if os.path.exists('test_predictions.pkl') else prediction_file.name\nwith open(prediction_file_name, 'rb') as f:\n    saved_predictions = pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chunk_ds, orig_ds = chunk_data['test'].to_dict(), data['test'].to_dict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter_prediction(prediction, min_word_cnt):\n    return [b for b in prediction if b[2]-b[1]>=min_word_cnt[b[0]]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport pandas as pd\nres = []\nfor mwc in tqdm(range(0,15)):\n#     transform_prediction = mk_prediction_transform(chunk_ds=chunk_ds,\n#                                                    orig_ds=orig_ds, min_word_cnt=mwc)\n#     predictions = transform_prediction(saved_predictions[0])\n    \n    scores = np.array([metric.score_example(y_true=y_true, \n                                            y_pred=filter_prediction(y_pred,mwc)) \n              for y_pred,y_true in zip(saved_predictions,orig_ds['rle_word'])]).sum(axis=0)\n    scores = [metric.f1(*score) for score in scores]\n    f1 = sum(scores)/len(scores)\n    scores = {id2label[i+1]:score for i,score in enumerate(scores)}\n    scores['f1'] = f1\n    scores['min_word_cnt']=mwc\n    res.append(scores)\n\npd.DataFrame(res).set_index('min_word_cnt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mwc =[0, 10, 6, 15, 6, 11, 9, 8]\n\nscores_ = np.array([metric.score_example(y_true=y_true, \n                                        y_pred=filter_prediction(y_pred,mwc)) \n              for y_pred,y_true in zip(saved_predictions,orig_ds['rle_word'])]).sum(axis=0)\nscores = [metric.f1(*score) for score in scores_]\nf1 = sum(scores)/len(scores)\nscores = {id2label[i+1]:score for i,score in enumerate(scores)}\nscores['f1'] = f1\n    \n# transform_prediction = mk_prediction_transform(chunk_ds=chunk_ds,\n#                                                 orig_ds=orig_ds, \n#                                                min_word_cnt=[0, 10, 6, 15, 6, 11, 9, 8])\n# predictions = transform_prediction(saved_predictions[0])\n# scores = np.array([metric.score_example(y_true=y_true, y_pred=y_pred) \n#               for y_true,y_pred in zip(predictions,orig_ds['pred_range'])]).sum(axis=0)\n# scores = [metric.f1(*score) for score in scores]\n# f1 = sum(scores)/len(scores)\n# scores = {id2label[i+1]:score for i,score in enumerate(scores)}\n# scores['f1'] = f1\nscores    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = [ sorted(pred, key=lambda x: x[1]) for pred in saved_predictions]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_result(i=20, orig_ds=data['test'],predictions=predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsaved_predictions[8],data['test'][8]['rle_token']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = [metric.score_example(y_true=y_true, y_pred=y_pred) for y_true,y_pred in zip(predictions,orig_ds['pred_range'])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[metric.f1(*x) for x in np.array(scores).sum(axis=0)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = np.argsort(np.array(scores)[:,:,1:].sum(axis=(1,2)))[::-1]\nidx[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}