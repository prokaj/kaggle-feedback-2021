{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_github = user_secrets.get_secret(\"github\")\n! rm -rf feedback2021\n! git clone https://{secret_github}@github.com/VilmosProkaj/feedback2021.git\n! pip install feedback2021/","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:37:40.059273Z","iopub.execute_input":"2022-02-26T04:37:40.059984Z","iopub.status.idle":"2022-02-26T04:38:07.248396Z","shell.execute_reply.started":"2022-02-26T04:37:40.059846Z","shell.execute_reply":"2022-02-26T04:38:07.247144Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'feedback2021'...\nremote: Enumerating objects: 216, done.\u001b[K\nremote: Counting objects: 100% (216/216), done.\u001b[K\nremote: Compressing objects: 100% (127/127), done.\u001b[K\nremote: Total 216 (delta 105), reused 163 (delta 52), pack-reused 0\u001b[K\nReceiving objects: 100% (216/216), 59.29 KiB | 2.47 MiB/s, done.\nResolving deltas: 100% (105/105), done.\nProcessing ./feedback2021\n\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from feedback2021==0.0.post1.dev30+g983bd4b) (3.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->feedback2021==0.0.post1.dev30+g983bd4b) (3.5.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->feedback2021==0.0.post1.dev30+g983bd4b) (3.7.4.3)\nBuilding wheels for collected packages: feedback2021\n  Building wheel for feedback2021 (PEP 517) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for feedback2021: filename=feedback2021-0.0.post1.dev30+g983bd4b-py3-none-any.whl size=23561 sha256=9f98a36142dcdd5bd696fc67f52d7a378f22a091f5652487765366e96c1de6c4\n  Stored in directory: /tmp/pip-ephem-wheel-cache-a0xczoc8/wheels/58/ad/18/0ce3edd06dac18258cb4965c488a42e46fa829de9c6aa2319e\nSuccessfully built feedback2021\nInstalling collected packages: feedback2021\nSuccessfully installed feedback2021-0.0.post1.dev30+g983bd4b\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install -U jax jaxlib dm_haiku optax\n#!pip install --upgrade pip\n# Installs the wheel compatible with CUDA 11 and cuDNN 8.2 or newer.\n# ! pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html  # Note: wheels only available on linux.\n## !pip install --upgrade jax jaxlib==0.3.0+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n#! pip install dm_haiku","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:38:07.251990Z","iopub.execute_input":"2022-02-26T04:38:07.252355Z","iopub.status.idle":"2022-02-26T04:38:37.709062Z","shell.execute_reply.started":"2022-02-26T04:38:07.252304Z","shell.execute_reply":"2022-02-26T04:38:37.707952Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: jax in /opt/conda/lib/python3.7/site-packages (0.2.19)\nCollecting jax\n  Downloading jax-0.3.1.tar.gz (912 kB)\n\u001b[K     |████████████████████████████████| 912 kB 2.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: jaxlib in /opt/conda/lib/python3.7/site-packages (0.1.70)\nCollecting jaxlib\n  Downloading jaxlib-0.3.0-cp37-none-manylinux2010_x86_64.whl (65.4 MB)\n\u001b[K     |████████████████████████████████| 65.4 MB 101 kB/s  eta 0:00:01\n\u001b[?25hCollecting dm_haiku\n  Downloading dm_haiku-0.0.6-py3-none-any.whl (309 kB)\n\u001b[K     |████████████████████████████████| 309 kB 71.1 MB/s eta 0:00:01\n\u001b[?25hCollecting optax\n  Downloading optax-0.1.1-py3-none-any.whl (136 kB)\n\u001b[K     |████████████████████████████████| 136 kB 68.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from jax) (0.12.0)\nRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.7/site-packages (from jax) (1.19.5)\nRequirement already satisfied: opt_einsum in /opt/conda/lib/python3.7/site-packages (from jax) (3.3.0)\nRequirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from jax) (1.7.1)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from jax) (3.7.4.3)\nRequirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/conda/lib/python3.7/site-packages (from jaxlib) (1.12)\nCollecting jmp>=0.0.2\n  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from dm_haiku) (0.8.9)\nCollecting chex>=0.0.4\n  Downloading chex-0.1.1-py3-none-any.whl (70 kB)\n\u001b[K     |████████████████████████████████| 70 kB 6.5 MB/s  eta 0:00:01\n\u001b[?25hCollecting typing_extensions\n  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py->jax) (1.15.0)\nRequirement already satisfied: toolz>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from chex>=0.0.4->optax) (0.11.1)\nRequirement already satisfied: dm-tree>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from chex>=0.0.4->optax) (0.1.6)\nBuilding wheels for collected packages: jax\n  Building wheel for jax (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jax: filename=jax-0.3.1-py3-none-any.whl size=1054277 sha256=8231389b0c076a1ad64df0231f73faff2edda1698e613665c853b61367700685\n  Stored in directory: /root/.cache/pip/wheels/04/14/e8/ee9de500f173ec900a5167686d9bb17c0171ed678680b96a57\nSuccessfully built jax\nInstalling collected packages: typing-extensions, jaxlib, jax, jmp, chex, optax, dm-haiku\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.7.4.3\n    Uninstalling typing-extensions-3.7.4.3:\n      Successfully uninstalled typing-extensions-3.7.4.3\n  Attempting uninstall: jaxlib\n    Found existing installation: jaxlib 0.1.70\n    Uninstalling jaxlib-0.1.70:\n      Successfully uninstalled jaxlib-0.1.70\n  Attempting uninstall: jax\n    Found existing installation: jax 0.2.19\n    Uninstalling jax-0.2.19:\n      Successfully uninstalled jax-0.2.19\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.4.1 requires typing-extensions~=3.7.4, but you have typing-extensions 4.1.1 which is incompatible.\narviz 0.11.2 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\naiobotocore 1.4.1 requires botocore<1.20.107,>=1.20.106, but you have botocore 1.21.44 which is incompatible.\u001b[0m\nSuccessfully installed chex-0.1.1 dm-haiku-0.0.6 jax-0.3.1 jaxlib-0.3.0 jmp-0.0.2 optax-0.1.1 typing-extensions-4.1.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import kaggle_init","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:38:37.711450Z","iopub.execute_input":"2022-02-26T04:38:37.711875Z","iopub.status.idle":"2022-02-26T04:38:37.721999Z","shell.execute_reply.started":"2022-02-26T04:38:37.711823Z","shell.execute_reply":"2022-02-26T04:38:37.720790Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"kaggle_init.on_kaggle(), kaggle_init.is_cuda_available(), kaggle_init.is_tpu_available()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:38:37.724055Z","iopub.execute_input":"2022-02-26T04:38:37.724342Z","iopub.status.idle":"2022-02-26T04:38:37.747277Z","shell.execute_reply.started":"2022-02-26T04:38:37.724306Z","shell.execute_reply":"2022-02-26T04:38:37.746621Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(True, False, True)"},"metadata":{}}]},{"cell_type":"code","source":"# %env XLA_PYTHON_CLIENT_MEM_FRACTION=.75\ncompute_on_tpu = True\nif compute_on_tpu:\n    if kaggle_init.is_tpu_available():\n        from feedback2021.jax_tpu_init import jax_tpu_init\n        jax_tpu_init()       \n    else:\n        import os\n        os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=2'\n#import jax\n#jax.devices()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:38:37.748225Z","iopub.execute_input":"2022-02-26T04:38:37.748468Z","iopub.status.idle":"2022-02-26T04:38:59.217871Z","shell.execute_reply.started":"2022-02-26T04:38:37.748439Z","shell.execute_reply":"2022-02-26T04:38:59.216902Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# jax_tpu_init??","metadata":{"execution":{"iopub.status.busy":"2022-02-21T12:46:26.782749Z","iopub.execute_input":"2022-02-21T12:46:26.783173Z","iopub.status.idle":"2022-02-21T12:46:26.789086Z","shell.execute_reply.started":"2022-02-21T12:46:26.783134Z","shell.execute_reply":"2022-02-21T12:46:26.787885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOG_TO_WANDB = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB:\n    !pip install --upgrade wandb -q # experiment tracking","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB:\n    import wandb\n    import os\n    os.environ[\"WANDB_PROJECT\"] = \"kaggle_feedback\"\n    os.environ[\"WANDB_ENTITY\"] = \"prvi\"\n    os.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n    os.environ[\"WANDB_WATCH\"] = \"gradient\"\n\n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        api_key = user_secrets.get_secret(\"wandb\")\n        os.environ[\"WANDB_API_KEY\"] = api_key\n        wandb.login()\n        wandb.init(dir=\"/tmp/\") \n    except:\n        print('If you want to use your W&B account, '\n              'go to Add-ons -> Secrets and provide your W&B access token.\\n'\n              'Use the Label name `wandb`. \\n'\n              'Get your W&B access token from here: https://wandb.ai/authorize')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from feedback2021.helper import id2label, label2id\n\nfrom feedback2021.prepare_data import (create_train_dataset_pd, \n                                       to_chunk_data, \n                                       chunk_mapping,\n                                       add_input_ids, \n                                       add_labels,\n                                       add_rle_word2,\n                                       has_name,\n                                    )\n\nimport feedback2021.metric as metric\n\nfrom feedback2021.postprocess import (mk_metric, \n                                      mk_prediction_transform, \n                                      mk_binary_metric, \n                                      mk_binary_prediction_transform)\n\nfrom feedback2021.visualize import show_result\n\nimport feedback2021.hk_roberta as hk_roberta","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:38:59.219172Z","iopub.execute_input":"2022-02-26T04:38:59.219400Z","iopub.status.idle":"2022-02-26T04:38:59.474210Z","shell.execute_reply.started":"2022-02-26T04:38:59.219374Z","shell.execute_reply":"2022-02-26T04:38:59.473317Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# CONFIG\njust_test = False\nexperiment_id = 1\ntask = \"token_classification\"\nmodel_checkpoint = \"roberta-large\" \n# \"allenai/longformer-base-4096\" \n# \"distilroberta-base\" # \"microsoft/deberta-v3-xsmall\" #\"roberta-base\"\nif just_test:\n    max_length = 128\n    stride = 128\nelse:\n    max_length = 512\n    stride = 128\nmin_tokens = 6\nmodel_path = f'{model_checkpoint.split(\"/\")[-1]}-{experiment_id}'\ndata_from_wandb = False\nsave_to_wandb = False or not data_from_wandb\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-02-26T04:38:59.475732Z","iopub.execute_input":"2022-02-26T04:38:59.476064Z","iopub.status.idle":"2022-02-26T04:38:59.482574Z","shell.execute_reply.started":"2022-02-26T04:38:59.476022Z","shell.execute_reply":"2022-02-26T04:38:59.481566Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:38:59.483713Z","iopub.execute_input":"2022-02-26T04:38:59.484018Z","iopub.status.idle":"2022-02-26T04:39:03.569050Z","shell.execute_reply.started":"2022-02-26T04:38:59.483967Z","shell.execute_reply":"2022-02-26T04:39:03.568105Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91480c50f0c340829a109894419ee7bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efe9f9907a4844eda02c89cf6eb30def"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee464437774f4b69b6a1737dc433e138"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba3a3a39f7414abc99ca8101aa9db29a"}},"metadata":{}}]},{"cell_type":"code","source":"#import tensorflow.config\n#tensorflow.config.experimental.set_visible_devices([], \"GPU\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:07:43.463027Z","iopub.execute_input":"2022-02-18T16:07:43.463293Z","iopub.status.idle":"2022-02-18T16:07:43.466366Z","shell.execute_reply.started":"2022-02-18T16:07:43.463265Z","shell.execute_reply":"2022-02-18T16:07:43.465714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from feedback2021.clean_train_data import mk_clean_train_data\nif just_test:\n    cleaned_train = mk_clean_train_data(num_records=100) #cleaned_train[:100]\nelse:\n    cleaned_train = mk_clean_train_data()\n\ndata = create_train_dataset_pd(cleaned_train_df=cleaned_train, \n                               tokenizer=tokenizer, \n                               verbose=True)\n\nfrom sklearn.model_selection import train_test_split\n\ndata = dict(zip(['train','test'], \n                train_test_split(data,\n                                 test_size=0.1, \n                                 shuffle=True, \n                                 random_state=42)))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:39:03.570541Z","iopub.execute_input":"2022-02-26T04:39:03.570817Z","iopub.status.idle":"2022-02-26T04:41:00.601542Z","shell.execute_reply.started":"2022-02-26T04:39:03.570785Z","shell.execute_reply":"2022-02-26T04:41:00.600519Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2022-02-26 04:39:04.191960: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2022-02-26 04:39:08.509334: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2022-02-26 04:39:08.509403: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"reformat train data:   0%|          | 0/144293 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8080f1174300455889e47aad74992ca4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"reading essays:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6439271f74b74cbba2fc45a2618dce56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"searching for disaligned labels:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b3c45a3bb78452997fdc202d83ed7d2"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    word mapping:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"888492f8f2444094a73fb4b2f443f239"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adding token rle:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd7455f0aff04cbe9963d6608795edf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":" adding label:   0%|          | 0/15594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99075815ca7b4b94946aa58697f3b2b4"}},"metadata":{}}]},{"cell_type":"code","source":"data['train'].head(), data['test'].head()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:40:33.107165Z","iopub.execute_input":"2022-02-25T12:40:33.107452Z","iopub.status.idle":"2022-02-25T12:40:33.47606Z","shell.execute_reply.started":"2022-02-25T12:40:33.107422Z","shell.execute_reply":"2022-02-25T12:40:33.475208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB and save_to_wandb:\n    data.remove_columns([#'input_ids', \n                         #'rle_token', \n                         'labels', \n                         #'offset_mapping'\n    ]).save_to_disk('data')\n\n    artifact = wandb.Artifact('data', description='train test split', type='dataset')\n    artifact.add_dir('data')\n    wandb.log_artifact(artifact)\n    !ls -sRh data\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if  not isinstance(data.column_names, dict):\n#     data = data.train_test_split(test_size=0.1, shuffle=True, seed=42)\n    \n# chunk_data = to_chunk_data(data, \n#                            chunk_len=max_length, \n#                            stride=stride, \n#                            prefix=[tokenizer.bos_token_id],\n#                            postfix=[tokenizer.eos_token_id])\n# chunk_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def chop_up(data, tokenizer, max_length, stride):\n    examples = {k: list(data[k]) for k in data.columns}\n    examples['labels'] = list(data['labels'])\n    examples['id'] = list(data.index.values)\n    f = chunk_mapping(chunk_len=max_length, \n                      stride=stride, \n                      prefix=[tokenizer.bos_token_id],\n                      postfix=[tokenizer.eos_token_id])\n    return f(examples)\n\ndef to_records(data):\n    return [dict(zip(data.keys(), rec))  for rec in zip(*data.values())]\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:41:00.604122Z","iopub.execute_input":"2022-02-26T04:41:00.604418Z","iopub.status.idle":"2022-02-26T04:41:00.613006Z","shell.execute_reply.started":"2022-02-26T04:41:00.604386Z","shell.execute_reply":"2022-02-26T04:41:00.612035Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"chunk_data = {\n    k: chop_up(v, tokenizer, max_length=max_length, stride=stride)\n    for k,v in data.items()\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:41:00.614084Z","iopub.execute_input":"2022-02-26T04:41:00.614429Z","iopub.status.idle":"2022-02-26T04:41:02.661146Z","shell.execute_reply.started":"2022-02-26T04:41:00.614398Z","shell.execute_reply":"2022-02-26T04:41:02.660407Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import yaml\nprint(yaml.dump(\n    {\n        k: {\n            k0: f'size={len(v0[0])}, type={type(v0[0][0]).__name__}' \n            if isinstance(v0[0], list) else v0[0] \n            for k0, v0 in v.items()\n        } \n     for k,v in chunk_data.items()\n    }\n))","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:41:02.662196Z","iopub.execute_input":"2022-02-26T04:41:02.662885Z","iopub.status.idle":"2022-02-26T04:41:02.672946Z","shell.execute_reply.started":"2022-02-26T04:41:02.662847Z","shell.execute_reply":"2022-02-26T04:41:02.671844Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"test:\n  input_ids: size=216, type=int\n  labels: size=216, type=int\n  offset: 0\n  text_id: AA0B42CF00A6\ntrain:\n  input_ids: size=512, type=int\n  labels: size=512, type=int\n  offset: 0\n  text_id: 838AA0C9A269\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-18T20:40:22.999032Z","iopub.execute_input":"2022-02-18T20:40:22.999325Z","iopub.status.idle":"2022-02-18T20:40:23.005487Z","shell.execute_reply.started":"2022-02-18T20:40:22.999294Z","shell.execute_reply":"2022-02-18T20:40:23.004696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if not has_name(data, 'rle_word'):\n#     from feedback2021.helper import Block\n#     def add_rle_word2(data):\n#         # assert has_name(data, 'offset_mapping'), 'add input_ids first!'\n#         if not has_name(data,'word_mapping'):\n#             data = add_word_mapping(data)\n#         return data.map(lambda x: {'rle_word': [Block(t).inv_map(x['word_mapping']) \n#                                                  for t in x['rle_char']]},\n#                             desc='rle to word coordinates')\n#     data = add_rle_word2(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from collections import defaultdict\n# import numpy as np\n# word_counts = defaultdict(list)\n# from  datasets import concatenate_datasets\n# all_data = concatenate_datasets(list(data.values()))\n# for x in all_data['rle_word']:\n#     for cls_id, start, end  in x:\n#         word_counts[id2label[cls_id]].append(end-start)\n\n# for k, v in word_counts.items():\n#     plt.hist(v,bins=np.arange(1,max(v)+1)-0.5)\n#     plt.title(f'{k} min:{min(v)} max: {max(v)}, 2%,5%: {np.percentile(v,[2,5])}')\n#     plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model and Training","metadata":{}},{"cell_type":"code","source":"# chunk_data = chunk_data.rename_column('labels','label')\n# DataLoader?","metadata":{"execution":{"iopub.status.busy":"2022-02-18T18:13:53.277895Z","iopub.execute_input":"2022-02-18T18:13:53.278471Z","iopub.status.idle":"2022-02-18T18:13:53.338729Z","shell.execute_reply.started":"2022-02-18T18:13:53.278431Z","shell.execute_reply":"2022-02-18T18:13:53.337945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# def mk_collate_fn(tokenizer, max_length=512):\n#     def collate_fn(features):\n        \n#         batch ={key: np.array([f[key]+[t]*(max_length-len(f[key])) for f in features], dtype=np.int32)\n#                 for t,key in zip([tokenizer.pad_token_id,-100],['input_ids','labels'])}\n#         return batch\n#     return collate_fn\n# from torch.utils.data import DataLoader\n\n# train_dataset = DataLoader(chunk_data_list, shuffle=True, #.remove_columns(['offset', 'text_id']), \n#                            batch_size=16,\n#                            collate_fn=mk_collate_fn(tokenizer, 512))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T19:05:29.59293Z","iopub.execute_input":"2022-02-18T19:05:29.593448Z","iopub.status.idle":"2022-02-18T19:05:29.602207Z","shell.execute_reply.started":"2022-02-18T19:05:29.59341Z","shell.execute_reply":"2022-02-18T19:05:29.601535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport tensorflow.data as tfdata\n#ds=\nimport numpy as np\n\ndef mk_collate_fn(tokenizer, max_length=512):\n    def collate_fn(features):\n        \n        batch = features.copy()\n        for t, key in zip([tokenizer.pad_token_id,-100], ['input_ids','labels']):\n            batch[key] = np.array([f+[t]*(max_length-len(f)) for f in batch[key]], \n                                  dtype=np.int32)\n        return batch\n    \n    return collate_fn\n\n    \ncollate_fn = mk_collate_fn(tokenizer, max_length)\n\nds ={k: tfdata.Dataset.from_tensor_slices(collate_fn(v)) for k,v in chunk_data.items()}\n#(chunk_data_list)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:41:02.674367Z","iopub.execute_input":"2022-02-26T04:41:02.674673Z","iopub.status.idle":"2022-02-26T04:41:15.309382Z","shell.execute_reply.started":"2022-02-26T04:41:02.674643Z","shell.execute_reply":"2022-02-26T04:41:15.308380Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"CPU times: user 12.1 s, sys: 540 ms, total: 12.7 s\nWall time: 12.6 s\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 8 if kaggle_init.is_tpu_available() else 2\ndummy_data = tfdata.Dataset.from_tensor_slices(\n    {\n        'input_ids': np.zeros((batch_size, max_length), dtype=np.int32),\n        'labels': -100*np.ones((batch_size, max_length), dtype=np.int32),\n        'text_id': np.array(['0'*11]*batch_size),\n        'offset': np.array(np.zeros(batch_size, dtype=np.int32))\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:41:15.311103Z","iopub.execute_input":"2022-02-26T04:41:15.311420Z","iopub.status.idle":"2022-02-26T04:41:15.321125Z","shell.execute_reply.started":"2022-02-26T04:41:15.311386Z","shell.execute_reply":"2022-02-26T04:41:15.320223Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"dummy_data","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:56:43.980698Z","iopub.execute_input":"2022-02-24T07:56:43.981196Z","iopub.status.idle":"2022-02-24T07:56:43.990582Z","shell.execute_reply.started":"2022-02-24T07:56:43.981126Z","shell.execute_reply":"2022-02-24T07:56:43.989179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jax\njax.devices(), jax.device_count()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:41:15.322601Z","iopub.execute_input":"2022-02-26T04:41:15.322945Z","iopub.status.idle":"2022-02-26T04:41:15.366603Z","shell.execute_reply.started":"2022-02-26T04:41:15.322913Z","shell.execute_reply":"2022-02-26T04:41:15.365254Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"([TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n  TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n  TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n  TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n  TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n  TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n  TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n  TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)],\n 8)"},"metadata":{}}]},{"cell_type":"code","source":"def subset(x):\n    return {k: x[k] for k in ['input_ids', 'labels', 'offset']}\n\ntrain_dataset = (ds['train'].\n                 map(subset).\n                 repeat().\n                 shuffle(4096).\n                 batch(batch_size=batch_size).\n                 batch(batch_size=jax.device_count()).as_numpy_iterator())\n\ntest_dataset = (ds['test'].\n                concatenate(dummy_data.repeat(jax.device_count())).\n                map(subset).batch(batch_size=batch_size, drop_remainder=True).\n                batch(batch_size=jax.device_count(), drop_remainder=True))","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:41:15.368127Z","iopub.execute_input":"2022-02-26T04:41:15.368909Z","iopub.status.idle":"2022-02-26T04:41:15.649739Z","shell.execute_reply.started":"2022-02-26T04:41:15.368854Z","shell.execute_reply":"2022-02-26T04:41:15.648825Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"len(ds['test']), len(ds['train'])","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:41:15.651703Z","iopub.execute_input":"2022-02-26T04:41:15.652860Z","iopub.status.idle":"2022-02-26T04:41:15.663694Z","shell.execute_reply.started":"2022-02-26T04:41:15.652812Z","shell.execute_reply":"2022-02-26T04:41:15.662575Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(5116, 43645)"},"metadata":{}}]},{"cell_type":"code","source":"class Metric:\n    def __init__(self):\n        self.reset()\n    def reset(self):\n        self._value = 0\n        self._n = 0\n    def update(self,v):\n        self._n += 1\n        self._value += v\n    def value(self):\n        return self._value/self._n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T12:51:18.38627Z","iopub.execute_input":"2022-02-21T12:51:18.386819Z","iopub.status.idle":"2022-02-21T12:51:18.396472Z","shell.execute_reply.started":"2022-02-21T12:51:18.386763Z","shell.execute_reply":"2022-02-21T12:51:18.394711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{k: f'shape={v.shape}, dtype={v.dtype}' for k,v in next(iter(train_dataset)).items()}","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:09:59.057770Z","iopub.execute_input":"2022-02-26T04:09:59.058420Z","iopub.status.idle":"2022-02-26T04:09:59.109943Z","shell.execute_reply.started":"2022-02-26T04:09:59.058367Z","shell.execute_reply":"2022-02-26T04:09:59.108636Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"{'input_ids': 'shape=(8, 16, 512), dtype=int32',\n 'labels': 'shape=(8, 16, 512), dtype=int32',\n 'offset': 'shape=(8, 16), dtype=int32'}"},"metadata":{}}]},{"cell_type":"code","source":"local_device_count = jax.device_count()\nlocal_device_count","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:57:00.978749Z","iopub.execute_input":"2022-02-24T07:57:00.979077Z","iopub.status.idle":"2022-02-24T07:57:00.985938Z","shell.execute_reply.started":"2022-02-24T07:57:00.97904Z","shell.execute_reply":"2022-02-24T07:57:00.984821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import haiku as hk\nimport jax.numpy as jnp\nimport optax\nimport functools\nfrom typing import Any, Mapping\n\ndef mk_loss_fn(config):\n    \n    def loss_fn(logits, data):\n    #                params,\n    #                rng,\n    #                data: Mapping[str, jnp.ndarray],\n    #                is_training: bool = True) -> jnp.ndarray:\n        \"\"\"Compute the loss on data wrt params.\"\"\"\n\n\n    #     logits = forward_fn(params, rng, data, is_training)\n        targets = jax.nn.one_hot(data['labels'], len(config['id2label']))\n        assert logits.shape == targets.shape\n\n        mask = jnp.not_equal(data['input_ids'], config['pad_token_id'])\n        mask = mask * jnp.greater_equal(data['labels'], 0)\n        loss = -jnp.sum(targets * jax.nn.log_softmax(logits), axis=-1)\n        loss = jnp.sum(loss * mask) / jnp.clip(jnp.sum(mask),1)\n\n        return loss\n    \n    return loss_fn\n\nclass Updater:\n    \"\"\"A stateless abstraction around an init_fn/update_fn pair.\n    This extracts some common boilerplate from the training loop.\n    \"\"\"\n\n    def __init__(self, \n                 net, \n                 loss_fn,\n                 optimizer: optax.GradientTransformation):\n        \n        self._net_init = net.init\n        self._loss_fn = lambda params,rng, data: loss_fn(net.apply(params, rng, data, is_training=True), data)\n        self._opt = optimizer\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def init(self, rng, data, pretrained_params=None):\n        \"\"\"Initializes state of the updater.\"\"\"\n        out_rng, init_rng = jax.random.split(rng)\n        params = self._net_init(init_rng, data)\n        if pretrained_params is not None:\n            params = hk.data_structures.merge(params, pretrained_params)\n        #params = hk.data_structures.map(lambda x: jnp.stack([x]*local_device_count), params)\n        opt_state = self._opt.init(params)\n        # rng = jax.random.PRNGKey(FLAGS.train_init_random_seed)\n        #rng = jnp.broadcast_to(rng, (local_device_count,) + rng.shape)\n        out = dict(\n            step=np.array(0),\n            rng=out_rng,\n            opt_state=opt_state,\n            params=params,\n            loss=np.array(0),\n        )\n        return out\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def update(self, state: Mapping[str, Any], data: Mapping[str, jnp.ndarray]):\n        \"\"\"Updates the state using some data and returns metrics.\"\"\"\n        rng, new_rng = jax.random.split(state['rng'])\n        params = state['params']\n        loss, grads = jax.value_and_grad(self._loss_fn)(params, rng, data)\n\n        if compute_on_tpu:\n            grads = jax.lax.pmean(grads, 'i')\n\n\n        updates, opt_state = self._opt.update(grads, state['opt_state'])\n        params = optax.apply_updates(params, updates)\n\n        new_state = {\n            'step': state['step'] + 1,\n            'rng': new_rng,\n            'opt_state': opt_state,\n            'params': params,\n            'loss': state['loss'] + loss\n        }\n\n        return new_state ","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:42:38.024451Z","iopub.execute_input":"2022-02-26T04:42:38.025051Z","iopub.status.idle":"2022-02-26T04:42:38.053038Z","shell.execute_reply.started":"2022-02-26T04:42:38.025004Z","shell.execute_reply":"2022-02-26T04:42:38.051906Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def get_predictions(net, loss_fn, state, test_ds):\n\n    def run_net(state, data):\n        logits = net.apply(state['params'], state['rng'], data, is_training=False)\n        loss = loss_fn(logits, data)\n        pred = jax.numpy.argmax(logits, axis=-1)\n        state['loss'] = state['loss'] + loss\n        return pred, state\n        \n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    predictions = []\n    for batch in test_ds.as_numpy_iterator():\n        pred, state = run_net(state, batch)\n        predictions.append(pred)\n        \n    predictions = [ pred \n                    for preds in jax.device_get(predictions) \n                    for pred in preds.reshape((-1,) + preds.shape[2:]) ]\n    return predictions, state\n\ndef eval_net(net, loss_fn, state, test_ds):\n\n    def run_net(state, data, loss, cnt):\n        cnt = cnt + jnp.greater(data['labels'].max(axis=-1),0).sum()\n        logits = net.apply(state['params'], state['rng'], data, is_training=False)\n        loss = loss + loss_fn(logits, data)\n        #pred = jax.numpy.argmax(logits, axis=-1)\n        #state['loss'] = state['loss'] + loss\n        return loss, cnt\n        \n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    #predictions = []\n    loss = np.zeros(jax.device_count())\n    cnt = np.zeros(jax.device_count())\n    for batch in test_ds.as_numpy_iterator():\n        loss, cnt = run_net(state, batch, loss, cnt)\n        # predictions.append(pred)\n    return float(loss.sum()/cnt.sum())\n\n#     predictions = [ pred \n#                     for preds in jax.device_get(predictions) \n#                     for pred in preds.reshape((-1,) + preds.shape[2:]) ]\n#     return predictions, state\n\n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:42:41.305559Z","iopub.execute_input":"2022-02-26T04:42:41.305979Z","iopub.status.idle":"2022-02-26T04:42:41.330552Z","shell.execute_reply.started":"2022-02-26T04:42:41.305936Z","shell.execute_reply":"2022-02-26T04:42:41.329242Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class Log:\n    def __init__(self, step=0):\n        self.step = step\n        self.start_time = self.prev_time = time.time()\n        \n    def update(self, state):\n        step = int(state['step'][0])\n        step_delta, self.step = step-self.step, step\n        \n        c_time = time.time()\n        time_delta, self.prev_time = c_time - self.prev_time, c_time\n        \n        loss = float(state['loss'].mean())/step_delta\n        state['loss'] = 0*state['loss']\n        \n        return {'step': self.step,\n                'loss': loss,\n                'elapsed_time': time_delta,\n                'total_time':   c_time-self.start_time,\n                'iter_per_sec': time_delta/max(1,step_delta),\n                'sec_per_iter': step_delta/max(1,time_delta),\n               }\n\ndef format_log(log):\n    return \"iteration: {step:<5}, loss: {loss:.4f}, elapsed_time:{elapsed_time:.2f}\".format(**log)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:42:56.994654Z","iopub.execute_input":"2022-02-26T04:42:56.995492Z","iopub.status.idle":"2022-02-26T04:42:57.011154Z","shell.execute_reply.started":"2022-02-26T04:42:56.995437Z","shell.execute_reply":"2022-02-26T04:42:57.010016Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import logging\nimport time\nfrom transformers import AutoConfig\nfrom feedback2021.hk_roberta import (build_forward_fn, \n                                     lm_loss_fn, \n                                     # GradientUpdater, \n                                     hk, optax, functools, Mapping, jnp, jax)\n\n## global variables\n# batch_size = 16  # Train batch size per core\ntotal_batch_size = batch_size*jax.device_count()\nlearning_rate = 2.5e-5*(total_batch_size/32) # Max learning-rate\ngrad_clip_value = 0.15  # Gradient norm clip value\n\ncheckpoint_dir = '/jax-transformer'  # Directory to store checkpoints\nif just_test:\n    LOG_EVERY = 2\n    MAX_STEPS = 4\nelse:\n    LOG_EVERY = len(ds['train'])//(2*total_batch_size)\n    MAX_STEPS = (3*len(ds['train']))//total_batch_size+1\n\nconfig = AutoConfig.from_pretrained(model_checkpoint, #'distilroberta-base', \n                                    label2id=label2id, \n                                    id2label=id2label).to_dict()\ntranslation = hk_roberta.weight_name_translation(config=config, prefix='roberta')\npretrained_params = hk_roberta.load_hf_pytorch_weights(model_checkpoint, #'distilroberta-base', \n                                                       translation)\n\nlogging.info = print\nlogging.info('Starting...')\n\nforward_fn = build_forward_fn(config)\n\nforward_fn = hk.transform(forward_fn)\n\n#loss_fn = functools.partial(lm_loss_fn, forward_fn.apply, config)\nloss_fn = mk_loss_fn(config)\n\nlr_schedule=optax.warmup_cosine_decay_schedule(init_value=0, \n                                               peak_value=1, \n                                               warmup_steps=min(50, MAX_STEPS//6), \n                                               decay_steps=MAX_STEPS-min(50,MAX_STEPS//6), \n                                               end_value=1e-4)\n\noptimizer = optax.chain(\n        optax.clip_by_global_norm(grad_clip_value),\n        optax.adam(learning_rate, b1=0.9, b2=0.99),\n        optax.scale_by_schedule(lr_schedule),\n    )\n\nupdater = Updater(forward_fn, loss_fn, optimizer)\n\n# Initialize parameters.\nlogging.info('Initializing parameters...')\nrng = jax.random.PRNGKey(428)\ndata = next(iter(train_dataset))\nstate = updater.init(rng, #jnp.broadcast_to(rng, (local_device_count,) + rng.shape), \n                     {k:v[0] for k,v in data.items()},\n                     pretrained_params=pretrained_params)\nif compute_on_tpu:\n    state = jax.device_put_replicated(state, jax.devices())\n    update = jax.pmap(updater.update, axis_name='i')\nelse:\n    update = updater.update\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:43:01.682074Z","iopub.execute_input":"2022-02-26T04:43:01.682603Z","iopub.status.idle":"2022-02-26T04:44:52.209271Z","shell.execute_reply.started":"2022-02-26T04:43:01.682556Z","shell.execute_reply":"2022-02-26T04:44:52.207978Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.43G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"415393816c6e4830a4989dc8165bed66"}},"metadata":{}},{"name":"stdout","text":"unused torch weights: roberta.embeddings.token_type_embeddings.weight,\nroberta.pooler.dense.weight, roberta.pooler.dense.bias, lm_head.bias,\nlm_head.dense.weight, lm_head.dense.bias, lm_head.layer_norm.weight,\nlm_head.layer_norm.bias, lm_head.decoder.weight\nStarting...\nInitializing parameters...\n","output_type":"stream"}]},{"cell_type":"code","source":"logging.info('Starting train loop...')\ntrain_iter = iter(train_dataset)\nlog = Log()\nfor step  in range(MAX_STEPS): #enumerate(train_dataset):\n        data = next(train_iter)\n        state = update(state, data)\n        # We use JAX runahead to mask data preprocessing and JAX dispatch overheads.\n        # Using values from state/metrics too often will block the runahead and can\n        # cause these overheads to become more prominent.\n        if step % LOG_EVERY == 0 or (step+1)== MAX_STEPS:\n            last_log=log.update(state)\n            test_loss = eval_net(forward_fn, loss_fn, state, test_dataset)\n            last_log['test_loss'] = test_loss #float(state['loss'].mean())\n            # state['loss'] = 0*state['loss']\n            logging.info(last_log)\n\n# logging.info(last_log)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:45:40.308778Z","iopub.execute_input":"2022-02-26T04:45:40.310136Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Starting train loop...\n{'step': 1, 'loss': 2.5538339614868164, 'elapsed_time': 114.75881576538086, 'total_time': 114.75881576538086, 'iter_per_sec': 114.75881576538086, 'sec_per_iter': 0.008713927495073269, 'test_loss': 411.80169677734375}\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = get_predictions(forward_fn, loss_fn, state=state, test_ds=test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:35:38.784742Z","iopub.execute_input":"2022-02-25T12:35:38.785273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# next(test_dataset.as_numpy_iterator())\n#next(iter(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:35:26.825227Z","iopub.execute_input":"2022-02-25T12:35:26.825509Z","iopub.status.idle":"2022-02-25T12:35:26.879572Z","shell.execute_reply.started":"2022-02-25T12:35:26.825481Z","shell.execute_reply":"2022-02-25T12:35:26.878887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(pred), pred[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:50:54.188065Z","iopub.execute_input":"2022-02-24T08:50:54.188883Z","iopub.status.idle":"2022-02-24T08:50:54.195233Z","shell.execute_reply.started":"2022-02-24T08:50:54.188841Z","shell.execute_reply":"2022-02-24T08:50:54.19407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = hk.data_structures.map(lambda name,module,x: x[0], state['params'])\nimport pickle\nwith open('params.pkl','wb') as f:\n    pickle.dump(params, f)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T06:13:23.821943Z","iopub.execute_input":"2022-02-23T06:13:23.822508Z","iopub.status.idle":"2022-02-23T06:13:27.022087Z","shell.execute_reply.started":"2022-02-23T06:13:23.822465Z","shell.execute_reply":"2022-02-23T06:13:27.020853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-23T06:13:31.428136Z","iopub.execute_input":"2022-02-23T06:13:31.428826Z","iopub.status.idle":"2022-02-23T06:13:32.394128Z","shell.execute_reply.started":"2022-02-23T06:13:31.428764Z","shell.execute_reply":"2022-02-23T06:13:32.39248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_schedule=optax.warmup_cosine_decay_schedule(init_value=0, \n                                               peak_value=1, \n                                               warmup_steps=500, \n                                               decay_steps=8500, \n                                               end_value=1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:41:44.23837Z","iopub.execute_input":"2022-02-21T06:41:44.238975Z","iopub.status.idle":"2022-02-21T06:41:44.245739Z","shell.execute_reply.started":"2022-02-21T06:41:44.238926Z","shell.execute_reply":"2022-02-21T06:41:44.244518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jaxlib, jax\njaxlib.__version__, jax.__version__, hk.__version__","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:45:48.632171Z","iopub.execute_input":"2022-02-21T06:45:48.632588Z","iopub.status.idle":"2022-02-21T06:45:48.640181Z","shell.execute_reply.started":"2022-02-21T06:45:48.632543Z","shell.execute_reply":"2022-02-21T06:45:48.639215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt = np.arange(0,9000,10)\nlr = [lr_schedule(jnp.array([i])) for i in cnt]\nplt.plot(cnt, lr)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:41:48.464737Z","iopub.execute_input":"2022-02-21T06:41:48.465445Z","iopub.status.idle":"2022-02-21T06:42:26.896087Z","shell.execute_reply.started":"2022-02-21T06:41:48.465381Z","shell.execute_reply":"2022-02-21T06:42:26.893875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{'loss': 2.4778389930725098, 'step': 0.0, 'steps_per_sec': 13.779059174634387}\n{'loss': 1.3683964014053345, 'step': 500.0, 'steps_per_sec': 2.5767113856201855}\n{'loss': 1.6631159782409668, 'step': 1000.0, 'steps_per_sec': 2.57725389686341}\n{'loss': 1.3581798076629639, 'step': 1500.0, 'steps_per_sec': 2.5771785561488483}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jax.core.gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T18:59:27.862142Z","iopub.execute_input":"2022-02-18T18:59:27.862405Z","iopub.status.idle":"2022-02-18T18:59:29.421439Z","shell.execute_reply.started":"2022-02-18T18:59:27.862376Z","shell.execute_reply":"2022-02-18T18:59:29.420597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jax.numpy.array([1,1])\n#jax.device_get('gpu')\n#jax.devices('gpu')\n! nvcc --version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n# TRAINING HYPERPARAMS\neffective_batch_size = 32\nmax_steps = 4000\nlog_steps = 500\n#n_step_examples = 8*500\nbatch_size = 16\ngrad_accumulation = effective_batch_size//batch_size\nlearning_rate = 5e-5\nweight_decay = 0.01\nwarmup_ratio = 0.1\nn_epochs = 3\nmodel_name = model_checkpoint.split(\"/\")[-1]\ntraining_args = TrainingArguments(\n    f\"{model_name}-{task}\",\n    evaluation_strategy = \"steps\",\n    eval_steps = log_steps,\n    logging_strategy = \"steps\",\n    logging_steps = log_steps,\n    save_strategy = \"steps\",\n    save_steps = log_steps,\n    learning_rate = learning_rate,\n    per_device_train_batch_size = batch_size,\n    per_device_eval_batch_size = batch_size,\n    #num_train_epochs = n_epochs,\n    max_steps = max_steps,\n    weight_decay = weight_decay,\n    report_to = 'wandb', \n    gradient_accumulation_steps = grad_accumulation,\n    warmup_steps = int(1.5*(log_steps)),\n    # logging_steps = 100,\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    greater_is_better=True,\n)\n#training_args","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['test']=add_rle_word2(data['test'])\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=chunk_data[\"train\"].remove_columns(['offset', 'text_id']), #.select(range(100)),\n    eval_dataset=chunk_data[\"test\"].remove_columns(['offset', 'text_id']), #.select(range(100)),\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=mk_binary_metric(chunk_ds=chunk_data['test'],\n                                     orig_ds=data['test'])\n    #,\n    #                                 min_word_cnt=[0,10,5,10,3,10,6,6]), #.select(range(100))), \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.save_model(model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wandb.init()\nimport pickle\nfrom feedback2021.postprocess import mk_prediction_transform\nfor k,v in chunk_data.items():\n    predictions = trainer.predict(v.remove_columns(['offset', 'text_id']))\n    prediction_transform = mk_binary_prediction_transform(chunk_ds=v, orig_ds=data[k])\n    predictions = prediction_transform(predictions[0])\n    with open(f'{k}_predictions.pkl','wb') as f:\n        pickle.dump(predictions, f)\n    wandb.save(f'{k}_predictions.pkl','./','now')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! rm longformer-base-4096-token_classification/ -rf\n#!rm distilroberta-base-token_classification -rf\n! ls -sh distilroberta-base-1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# From this point on there is no need to gpu!","metadata":{"execution":{"iopub.execute_input":"2021-12-30T06:52:35.965148Z","iopub.status.busy":"2021-12-30T06:52:35.964896Z","iopub.status.idle":"2021-12-30T06:52:36.089436Z","shell.execute_reply":"2021-12-30T06:52:36.088549Z","shell.execute_reply.started":"2021-12-30T06:52:35.96512Z"}}},{"cell_type":"code","source":"prediction_file = wandb.restore('predictions.pkl', run_path='prvi/huggingface/d17yam8m')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_file_name = 'test_predictions.pkl' #if os.path.exists('test_predictions.pkl') else prediction_file.name\nwith open(prediction_file_name, 'rb') as f:\n    saved_predictions = pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chunk_ds, orig_ds = chunk_data['test'].to_dict(), data['test'].to_dict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter_prediction(prediction, min_word_cnt):\n    return [b for b in prediction if b[2]-b[1]>=min_word_cnt[b[0]]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport pandas as pd\nres = []\nfor mwc in tqdm(range(0,15)):\n#     transform_prediction = mk_prediction_transform(chunk_ds=chunk_ds,\n#                                                    orig_ds=orig_ds, min_word_cnt=mwc)\n#     predictions = transform_prediction(saved_predictions[0])\n    \n    scores = np.array([metric.score_example(y_true=y_true, \n                                            y_pred=filter_prediction(y_pred,mwc)) \n              for y_pred,y_true in zip(saved_predictions,orig_ds['rle_word'])]).sum(axis=0)\n    scores = [metric.f1(*score) for score in scores]\n    f1 = sum(scores)/len(scores)\n    scores = {id2label[i+1]:score for i,score in enumerate(scores)}\n    scores['f1'] = f1\n    scores['min_word_cnt']=mwc\n    res.append(scores)\n\npd.DataFrame(res).set_index('min_word_cnt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mwc =[0, 10, 6, 15, 6, 11, 9, 8]\n\nscores_ = np.array([metric.score_example(y_true=y_true, \n                                        y_pred=filter_prediction(y_pred,mwc)) \n              for y_pred,y_true in zip(saved_predictions,orig_ds['rle_word'])]).sum(axis=0)\nscores = [metric.f1(*score) for score in scores_]\nf1 = sum(scores)/len(scores)\nscores = {id2label[i+1]:score for i,score in enumerate(scores)}\nscores['f1'] = f1\n    \n# transform_prediction = mk_prediction_transform(chunk_ds=chunk_ds,\n#                                                 orig_ds=orig_ds, \n#                                                min_word_cnt=[0, 10, 6, 15, 6, 11, 9, 8])\n# predictions = transform_prediction(saved_predictions[0])\n# scores = np.array([metric.score_example(y_true=y_true, y_pred=y_pred) \n#               for y_true,y_pred in zip(predictions,orig_ds['pred_range'])]).sum(axis=0)\n# scores = [metric.f1(*score) for score in scores]\n# f1 = sum(scores)/len(scores)\n# scores = {id2label[i+1]:score for i,score in enumerate(scores)}\n# scores['f1'] = f1\nscores    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = [ sorted(pred, key=lambda x: x[1]) for pred in saved_predictions]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_result(i=20, orig_ds=data['test'],predictions=predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsaved_predictions[8],data['test'][8]['rle_token']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = [metric.score_example(y_true=y_true, y_pred=y_pred) for y_true,y_pred in zip(predictions,orig_ds['pred_range'])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[metric.f1(*x) for x in np.array(scores).sum(axis=0)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = np.argsort(np.array(scores)[:,:,1:].sum(axis=(1,2)))[::-1]\nidx[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}