{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_github = user_secrets.get_secret(\"github\")\n! rm -rf feedback2021\n! git clone https://{secret_github}@github.com/VilmosProkaj/feedback2021.git\n! pip install feedback2021/","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:31:58.655583Z","iopub.execute_input":"2022-02-24T08:31:58.656064Z","iopub.status.idle":"2022-02-24T08:32:29.850009Z","shell.execute_reply.started":"2022-02-24T08:31:58.655971Z","shell.execute_reply":"2022-02-24T08:32:29.849156Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'feedback2021'...\nremote: Enumerating objects: 216, done.\u001b[K\nremote: Counting objects: 100% (216/216), done.\u001b[K\nremote: Compressing objects: 100% (127/127), done.\u001b[K\nremote: Total 216 (delta 105), reused 163 (delta 52), pack-reused 0\u001b[K\nReceiving objects: 100% (216/216), 59.29 KiB | 639.00 KiB/s, done.\nResolving deltas: 100% (105/105), done.\nProcessing ./feedback2021\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from feedback2021==0.0.post1.dev30+g983bd4b) (4.10.1)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->feedback2021==0.0.post1.dev30+g983bd4b) (4.0.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->feedback2021==0.0.post1.dev30+g983bd4b) (3.6.0)\nBuilding wheels for collected packages: feedback2021\n  Building wheel for feedback2021 (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for feedback2021: filename=feedback2021-0.0.post1.dev30+g983bd4b-py3-none-any.whl size=23561 sha256=f214aeeb1a716c77a92d483752c3f8c0dccca0273cc12e7e0374025d24886311\n  Stored in directory: /tmp/pip-ephem-wheel-cache-8_q0ztol/wheels/58/ad/18/0ce3edd06dac18258cb4965c488a42e46fa829de9c6aa2319e\nSuccessfully built feedback2021\nInstalling collected packages: feedback2021\nSuccessfully installed feedback2021-0.0.post1.dev30+g983bd4b\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install -U jax jaxlib dm_haiku optax\n#!pip install --upgrade pip\n# Installs the wheel compatible with CUDA 11 and cuDNN 8.2 or newer.\n# ! pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html  # Note: wheels only available on linux.\n## !pip install --upgrade jax jaxlib==0.3.0+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n#! pip install dm_haiku","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:32:38.959183Z","iopub.execute_input":"2022-02-24T08:32:38.959491Z","iopub.status.idle":"2022-02-24T08:32:59.941293Z","shell.execute_reply.started":"2022-02-24T08:32:38.959460Z","shell.execute_reply":"2022-02-24T08:32:59.940207Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: jax in /opt/conda/lib/python3.7/site-packages (0.2.28)\nCollecting jax\n  Downloading jax-0.3.1.tar.gz (912 kB)\n     |████████████████████████████████| 912 kB 599 kB/s            \n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: jaxlib in /opt/conda/lib/python3.7/site-packages (0.1.76)\nCollecting jaxlib\n  Downloading jaxlib-0.3.0-cp37-none-manylinux2010_x86_64.whl (65.4 MB)\n     |████████████████████████████████| 65.4 MB 111 kB/s             \n\u001b[?25hCollecting dm_haiku\n  Downloading dm_haiku-0.0.6-py3-none-any.whl (309 kB)\n     |████████████████████████████████| 309 kB 43.7 MB/s            \n\u001b[?25hRequirement already satisfied: optax in /opt/conda/lib/python3.7/site-packages (0.1.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from jax) (0.15.0)\nRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.7/site-packages (from jax) (1.20.3)\nRequirement already satisfied: opt_einsum in /opt/conda/lib/python3.7/site-packages (from jax) (3.3.0)\nRequirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from jax) (1.7.3)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from jax) (4.0.1)\nRequirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/conda/lib/python3.7/site-packages (from jaxlib) (1.12)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from dm_haiku) (0.8.9)\nCollecting jmp>=0.0.2\n  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\nRequirement already satisfied: chex>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from optax) (0.1.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py->jax) (1.16.0)\nRequirement already satisfied: dm-tree>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from chex>=0.0.4->optax) (0.1.6)\nRequirement already satisfied: toolz>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from chex>=0.0.4->optax) (0.11.2)\nBuilding wheels for collected packages: jax\n  Building wheel for jax (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jax: filename=jax-0.3.1-py3-none-any.whl size=1054277 sha256=0dcc0b1e8336f5925ac91f42f5a0dfd2f0395f5b72112f89464ba6ad0f5ac0e9\n  Stored in directory: /root/.cache/pip/wheels/04/14/e8/ee9de500f173ec900a5167686d9bb17c0171ed678680b96a57\nSuccessfully built jax\nInstalling collected packages: jaxlib, jax, jmp, dm-haiku\n  Attempting uninstall: jaxlib\n    Found existing installation: jaxlib 0.1.76\n    Uninstalling jaxlib-0.1.76:\n      Successfully uninstalled jaxlib-0.1.76\n  Attempting uninstall: jax\n    Found existing installation: jax 0.2.28\n    Uninstalling jax-0.2.28:\n      Successfully uninstalled jax-0.2.28\nSuccessfully installed dm-haiku-0.0.6 jax-0.3.1 jaxlib-0.3.0 jmp-0.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import kaggle_init","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:34:21.734138Z","iopub.execute_input":"2022-02-24T08:34:21.734978Z","iopub.status.idle":"2022-02-24T08:34:21.744008Z","shell.execute_reply.started":"2022-02-24T08:34:21.734935Z","shell.execute_reply":"2022-02-24T08:34:21.743151Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"kaggle_init.on_kaggle(), kaggle_init.is_cuda_available(), kaggle_init.is_tpu_available()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:34:23.553998Z","iopub.execute_input":"2022-02-24T08:34:23.554708Z","iopub.status.idle":"2022-02-24T08:34:23.564569Z","shell.execute_reply.started":"2022-02-24T08:34:23.554657Z","shell.execute_reply":"2022-02-24T08:34:23.563548Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(True, False, False)"},"metadata":{}}]},{"cell_type":"code","source":"import os\nos.environ","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:55:13.282127Z","iopub.execute_input":"2022-02-23T08:55:13.282678Z","iopub.status.idle":"2022-02-23T08:55:13.289041Z","shell.execute_reply.started":"2022-02-23T08:55:13.282643Z","shell.execute_reply":"2022-02-23T08:55:13.288273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %env XLA_PYTHON_CLIENT_MEM_FRACTION=.75\ncompute_on_tpu = True\nif compute_on_tpu:\n    if kaggle_init.is_tpu_available():\n        from feedback2021.jax_tpu_init import jax_tpu_init\n        jax_tpu_init()       \n    else:\n        import os\n        os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=2'\n#import jax\n#jax.devices()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:34:27.096906Z","iopub.execute_input":"2022-02-24T08:34:27.097284Z","iopub.status.idle":"2022-02-24T08:34:27.102687Z","shell.execute_reply.started":"2022-02-24T08:34:27.097221Z","shell.execute_reply":"2022-02-24T08:34:27.101721Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# jax_tpu_init??","metadata":{"execution":{"iopub.status.busy":"2022-02-21T12:46:26.782749Z","iopub.execute_input":"2022-02-21T12:46:26.783173Z","iopub.status.idle":"2022-02-21T12:46:26.789086Z","shell.execute_reply.started":"2022-02-21T12:46:26.783134Z","shell.execute_reply":"2022-02-21T12:46:26.787885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOG_TO_WANDB = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB:\n    !pip install --upgrade wandb -q # experiment tracking","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOG_TO_WANDB:\n    import wandb\n    import os\n    os.environ[\"WANDB_PROJECT\"] = \"kaggle_feedback\"\n    os.environ[\"WANDB_ENTITY\"] = \"prvi\"\n    os.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n    os.environ[\"WANDB_WATCH\"] = \"gradient\"\n\n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        api_key = user_secrets.get_secret(\"wandb\")\n        os.environ[\"WANDB_API_KEY\"] = api_key\n        wandb.login()\n        wandb.init(dir=\"/tmp/\") \n    except:\n        print('If you want to use your W&B account, '\n              'go to Add-ons -> Secrets and provide your W&B access token.\\n'\n              'Use the Label name `wandb`. \\n'\n              'Get your W&B access token from here: https://wandb.ai/authorize')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from feedback2021.helper import id2label, label2id\n\nfrom feedback2021.prepare_data import (create_train_dataset_pd, \n                                       to_chunk_data, \n                                       chunk_mapping,\n                                       add_input_ids, \n                                       add_labels,\n                                       add_rle_word2,\n                                       has_name,\n                                    )\n\nimport feedback2021.metric as metric\n\nfrom feedback2021.postprocess import (mk_metric, \n                                      mk_prediction_transform, \n                                      mk_binary_metric, \n                                      mk_binary_prediction_transform)\n\nfrom feedback2021.visualize import show_result\n\nimport feedback2021.hk_roberta as hk_roberta","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:34:31.486115Z","iopub.execute_input":"2022-02-24T08:34:31.486452Z","iopub.status.idle":"2022-02-24T08:34:33.320417Z","shell.execute_reply.started":"2022-02-24T08:34:31.486416Z","shell.execute_reply":"2022-02-24T08:34:33.319498Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# CONFIG\njust_test = True\nexperiment_id = 1\ntask = \"token_classification\"\nmodel_checkpoint = \"distilroberta-base\" \n# \"allenai/longformer-base-4096\" \n# \"distilroberta-base\" # \"microsoft/deberta-v3-xsmall\" #\"roberta-base\"\nif just_test:\n    max_length = 128\n    stride = 128\nelse:\n    max_length = 512\n    stride = 128\nmin_tokens = 6\nmodel_path = f'{model_checkpoint.split(\"/\")[-1]}-{experiment_id}'\ndata_from_wandb = False\nsave_to_wandb = False or not data_from_wandb\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-02-24T08:34:34.789122Z","iopub.execute_input":"2022-02-24T08:34:34.789417Z","iopub.status.idle":"2022-02-24T08:34:34.797685Z","shell.execute_reply.started":"2022-02-24T08:34:34.789384Z","shell.execute_reply":"2022-02-24T08:34:34.795769Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:34:38.857509Z","iopub.execute_input":"2022-02-24T08:34:38.857977Z","iopub.status.idle":"2022-02-24T08:34:49.476530Z","shell.execute_reply.started":"2022-02-24T08:34:38.857942Z","shell.execute_reply":"2022-02-24T08:34:49.475512Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"314d3b3d4d214d61b2c1405e8bccfab4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11725f0f9df84a0dac563c3b213ae030"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fd98e3701604323bba919824ca4d246"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cc619f21ce74ec8825564dd9de8ac26"}},"metadata":{}}]},{"cell_type":"code","source":"#import tensorflow.config\n#tensorflow.config.experimental.set_visible_devices([], \"GPU\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:07:43.463027Z","iopub.execute_input":"2022-02-18T16:07:43.463293Z","iopub.status.idle":"2022-02-18T16:07:43.466366Z","shell.execute_reply.started":"2022-02-18T16:07:43.463265Z","shell.execute_reply":"2022-02-18T16:07:43.465714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from feedback2021.clean_train_data import mk_clean_train_data\nif just_test:\n    cleaned_train = mk_clean_train_data(num_records=100) #cleaned_train[:100]\nelse:\n    cleaned_train = mk_clean_train_data()\n\ndata = create_train_dataset_pd(cleaned_train_df=cleaned_train, \n                               tokenizer=tokenizer, \n                               verbose=True)\n\nfrom sklearn.model_selection import train_test_split\n\ndata = dict(zip(['train','test'], \n                train_test_split(data,\n                                 test_size=0.1, \n                                 shuffle=True, \n                                 random_state=42)))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:34:49.478604Z","iopub.execute_input":"2022-02-24T08:34:49.478939Z","iopub.status.idle":"2022-02-24T08:35:00.691136Z","shell.execute_reply.started":"2022-02-24T08:34:49.478893Z","shell.execute_reply":"2022-02-24T08:35:00.690158Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"reformat train data:   0%|          | 0/144293 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ac2914b792e4be1a0dd8db4b7e70a48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"reading essays:   0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a36653601dc488abbd575e360e91e21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"searching for disaligned labels:   0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4428c03d94204773a9aded19be123e34"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    word mapping:   0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d1ea10eda8c4c0bb7cc1543cdfc1217"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adding token rle:   0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dac3722aa9b4ca9a22aab88c3b73123"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":" adding label:   0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f264f6bbfb3c4909b0659f8e1f8aceea"}},"metadata":{}}]},{"cell_type":"code","source":"data['train'].head(), data['test'].head()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:40:38.835258Z","iopub.execute_input":"2022-02-24T07:40:38.835555Z","iopub.status.idle":"2022-02-24T07:40:39.107891Z","shell.execute_reply.started":"2022-02-24T07:40:38.835522Z","shell.execute_reply":"2022-02-24T07:40:39.107267Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(                                                           text  \\\n id                                                                \n 004EA492DA04  Dear Principal,\\n\\nI think that making someone...   \n 0083B82A9C6F  Dear Principal,\\n\\nI believe that the best pol...   \n 015BB7DA58EE  Have you ever been bored in a class room such ...   \n 00885C23A764  The idea of having cars that can do the drivin...   \n 019B73E2A599  Hey you! Do you need some advice about somethi...   \n \n                                                        rle_char  \\\n id                                                                \n 004EA492DA04  [(2, 17, 100), (4, 102, 245), (3, 512, 611), (...   \n 0083B82A9C6F  [(2, 17, 74), (3, 77, 354), (6, 357, 486), (7,...   \n 015BB7DA58EE  [(1, 0, 328), (2, 330, 473), (4, 476, 540), (3...   \n 00885C23A764  [(1, 0, 396), (2, 398, 565), (3, 568, 1688), (...   \n 019B73E2A599  [(1, 0, 155), (2, 157, 284), (4, 293, 312), (4...   \n \n                                                       input_ids  \\\n id                                                                \n 004EA492DA04  [23314, 13619, 6, 50118, 50118, 100, 206, 14, ...   \n 0083B82A9C6F  [23314, 13619, 6, 50118, 50118, 100, 679, 14, ...   \n 015BB7DA58EE  [17781, 47, 655, 57, 23809, 11, 10, 1380, 929,...   \n 00885C23A764  [133, 1114, 9, 519, 1677, 14, 64, 109, 5, 1428...   \n 019B73E2A599  [13368, 47, 328, 1832, 47, 240, 103, 2949, 59,...   \n \n                                                  offset_mapping  \\\n id                                                                \n 004EA492DA04  [(0, 4), (5, 14), (14, 15), (15, 16), (16, 17)...   \n 0083B82A9C6F  [(0, 4), (5, 14), (14, 15), (15, 16), (16, 17)...   \n 015BB7DA58EE  [(0, 4), (5, 8), (9, 13), (14, 18), (19, 24), ...   \n 00885C23A764  [(0, 3), (4, 8), (9, 11), (12, 18), (19, 23), ...   \n 019B73E2A599  [(0, 3), (4, 7), (7, 8), (9, 11), (12, 15), (1...   \n \n                                                    word_mapping  \\\n id                                                                \n 004EA492DA04  [(0, 4), (5, 15), (17, 18), (19, 24), (25, 29)...   \n 0083B82A9C6F  [(0, 4), (5, 15), (17, 18), (19, 26), (27, 31)...   \n 015BB7DA58EE  [(0, 4), (5, 8), (9, 13), (14, 18), (19, 24), ...   \n 00885C23A764  [(0, 3), (4, 8), (9, 11), (12, 18), (19, 23), ...   \n 019B73E2A599  [(0, 3), (4, 8), (9, 11), (12, 15), (16, 20), ...   \n \n                                                       rle_token  \\\n id                                                                \n 004EA492DA04  [(2, 5, 21), (4, 22, 50), (3, 105, 129), (4, 1...   \n 0083B82A9C6F  [(2, 5, 16), (3, 19, 81), (6, 84, 110), (7, 11...   \n 015BB7DA58EE  [(1, 0, 78), (2, 79, 103), (4, 106, 120), (3, ...   \n 00885C23A764  [(1, 0, 81), (2, 82, 113), (3, 116, 339), (4, ...   \n 019B73E2A599  [(1, 0, 34), (2, 35, 58), (4, 59, 63), (4, 64,...   \n \n                                                          labels  \n id                                                               \n 004EA492DA04  [0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n 0083B82A9C6F  [0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n 015BB7DA58EE  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n 00885C23A764  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n 019B73E2A599  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ,\n                                                            text  \\\n id                                                                \n 017FB36B3B0C  You just finished a long, hard day at school. ...   \n 00E3F86E3E6A  dear principle,\\n\\nI believe that we do not ne...   \n 014BF1790D44  TEACHER_NAME\\n\\nSCHOOL_NAME\\n\\nDes Plaines, Il...   \n 00BD97EA4041  Should computers read the emotional expression...   \n 00B2AE3212D2  .\\n\\nSenator i believe the electoral college s...   \n \n                                                        rle_char  \\\n id                                                                \n 017FB36B3B0C  [(1, 0, 379), (2, 381, 457), (4, 458, 518), (4...   \n 00E3F86E3E6A  [(2, 17, 101), (4, 103, 204), (6, 206, 272), (...   \n 014BF1790D44  [(2, 95, 165), (4, 168, 382), (3, 385, 930), (...   \n 00BD97EA4041  [(1, 0, 74), (2, 76, 131), (4, 133, 270), (3, ...   \n 00B2AE3212D2  [(2, 3, 164), (3, 166, 664), (3, 668, 784), (4...   \n \n                                                       input_ids  \\\n id                                                                \n 017FB36B3B0C  [1185, 95, 1550, 10, 251, 6, 543, 183, 23, 334...   \n 00E3F86E3E6A  [417, 4352, 9322, 6, 50118, 50118, 100, 679, 1...   \n 014BF1790D44  [6433, 11083, 2076, 1215, 48307, 50118, 50118,...   \n 00BD97EA4041  [31231, 7796, 1166, 5, 3722, 17528, 9, 521, 11...   \n 00B2AE3212D2  [4, 50118, 50118, 36328, 939, 679, 5, 7169, 15...   \n \n                                                  offset_mapping  \\\n id                                                                \n 017FB36B3B0C  [(0, 3), (4, 8), (9, 17), (18, 19), (20, 24), ...   \n 00E3F86E3E6A  [(0, 1), (1, 4), (5, 14), (14, 15), (15, 16), ...   \n 014BF1790D44  [(0, 2), (2, 5), (5, 7), (7, 8), (8, 12), (12,...   \n 00BD97EA4041  [(0, 6), (7, 16), (17, 21), (22, 25), (26, 35)...   \n 00B2AE3212D2  [(0, 1), (1, 2), (2, 3), (3, 10), (11, 12), (1...   \n \n                                                    word_mapping  \\\n id                                                                \n 017FB36B3B0C  [(0, 3), (4, 8), (9, 17), (18, 19), (20, 25), ...   \n 00E3F86E3E6A  [(0, 4), (5, 15), (17, 18), (19, 26), (27, 31)...   \n 014BF1790D44  [(0, 12), (14, 25), (27, 30), (31, 39), (40, 4...   \n 00BD97EA4041  [(0, 6), (7, 16), (17, 21), (22, 25), (26, 35)...   \n 00B2AE3212D2  [(0, 1), (3, 10), (11, 12), (13, 20), (21, 24)...   \n \n                                                       rle_token  \\\n id                                                                \n 017FB36B3B0C  [(1, 0, 84), (2, 85, 98), (4, 98, 109), (4, 11...   \n 00E3F86E3E6A  [(2, 6, 21), (4, 22, 41), (6, 42, 55), (7, 55,...   \n 014BF1790D44  [(2, 39, 55), (4, 58, 103), (3, 106, 231), (4,...   \n 00BD97EA4041  [(1, 0, 11), (2, 12, 23), (4, 24, 52), (3, 55,...   \n 00B2AE3212D2  [(2, 3, 30), (3, 31, 134), (3, 137, 162), (4, ...   \n \n                                                          labels  \n id                                                               \n 017FB36B3B0C  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n 00E3F86E3E6A  [0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n 014BF1790D44  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n 00BD97EA4041  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, ...  \n 00B2AE3212D2  [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  )"},"metadata":{}}]},{"cell_type":"code","source":"if LOG_TO_WANDB and save_to_wandb:\n    data.remove_columns([#'input_ids', \n                         #'rle_token', \n                         'labels', \n                         #'offset_mapping'\n    ]).save_to_disk('data')\n\n    artifact = wandb.Artifact('data', description='train test split', type='dataset')\n    artifact.add_dir('data')\n    wandb.log_artifact(artifact)\n    !ls -sRh data\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if  not isinstance(data.column_names, dict):\n#     data = data.train_test_split(test_size=0.1, shuffle=True, seed=42)\n    \n# chunk_data = to_chunk_data(data, \n#                            chunk_len=max_length, \n#                            stride=stride, \n#                            prefix=[tokenizer.bos_token_id],\n#                            postfix=[tokenizer.eos_token_id])\n# chunk_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def chop_up(data, tokenizer, max_length, stride):\n    examples = {k: list(data[k]) for k in data.columns}\n    examples['labels'] = list(data['labels'])\n    examples['id'] = list(data.index.values)\n    f = chunk_mapping(chunk_len=max_length, \n                      stride=stride, \n                      prefix=[tokenizer.bos_token_id],\n                      postfix=[tokenizer.eos_token_id])\n    return f(examples)\n\ndef to_records(data):\n    return [dict(zip(data.keys(), rec))  for rec in zip(*data.values())]\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:35:09.155963Z","iopub.execute_input":"2022-02-24T08:35:09.156978Z","iopub.status.idle":"2022-02-24T08:35:09.164855Z","shell.execute_reply.started":"2022-02-24T08:35:09.156938Z","shell.execute_reply":"2022-02-24T08:35:09.163759Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"chunk_data = {\n    k: chop_up(v, tokenizer, max_length=max_length, stride=stride)\n    for k,v in data.items()\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:35:11.915426Z","iopub.execute_input":"2022-02-24T08:35:11.916308Z","iopub.status.idle":"2022-02-24T08:35:11.925569Z","shell.execute_reply.started":"2022-02-24T08:35:11.916261Z","shell.execute_reply":"2022-02-24T08:35:11.924448Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import yaml\nprint(yaml.dump(\n    {\n        k: {\n            k0: f'size={len(v0[0])}, type={type(v0[0][0]).__name__}' \n            if isinstance(v0[0], list) else v0[0] \n            for k0, v0 in v.items()\n        } \n     for k,v in chunk_data.items()\n    }\n))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:35:14.041489Z","iopub.execute_input":"2022-02-24T08:35:14.041972Z","iopub.status.idle":"2022-02-24T08:35:14.051628Z","shell.execute_reply.started":"2022-02-24T08:35:14.041921Z","shell.execute_reply":"2022-02-24T08:35:14.050511Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"test:\n  input_ids: size=128, type=int\n  labels: size=128, type=int\n  offset: 0\n  text_id: 017FB36B3B0C\ntrain:\n  input_ids: size=128, type=int\n  labels: size=128, type=int\n  offset: 0\n  text_id: 004EA492DA04\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-18T20:40:22.999032Z","iopub.execute_input":"2022-02-18T20:40:22.999325Z","iopub.status.idle":"2022-02-18T20:40:23.005487Z","shell.execute_reply.started":"2022-02-18T20:40:22.999294Z","shell.execute_reply":"2022-02-18T20:40:23.004696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if not has_name(data, 'rle_word'):\n#     from feedback2021.helper import Block\n#     def add_rle_word2(data):\n#         # assert has_name(data, 'offset_mapping'), 'add input_ids first!'\n#         if not has_name(data,'word_mapping'):\n#             data = add_word_mapping(data)\n#         return data.map(lambda x: {'rle_word': [Block(t).inv_map(x['word_mapping']) \n#                                                  for t in x['rle_char']]},\n#                             desc='rle to word coordinates')\n#     data = add_rle_word2(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from collections import defaultdict\n# import numpy as np\n# word_counts = defaultdict(list)\n# from  datasets import concatenate_datasets\n# all_data = concatenate_datasets(list(data.values()))\n# for x in all_data['rle_word']:\n#     for cls_id, start, end  in x:\n#         word_counts[id2label[cls_id]].append(end-start)\n\n# for k, v in word_counts.items():\n#     plt.hist(v,bins=np.arange(1,max(v)+1)-0.5)\n#     plt.title(f'{k} min:{min(v)} max: {max(v)}, 2%,5%: {np.percentile(v,[2,5])}')\n#     plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model and Training","metadata":{}},{"cell_type":"code","source":"# chunk_data = chunk_data.rename_column('labels','label')\n# DataLoader?","metadata":{"execution":{"iopub.status.busy":"2022-02-18T18:13:53.277895Z","iopub.execute_input":"2022-02-18T18:13:53.278471Z","iopub.status.idle":"2022-02-18T18:13:53.338729Z","shell.execute_reply.started":"2022-02-18T18:13:53.278431Z","shell.execute_reply":"2022-02-18T18:13:53.337945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# def mk_collate_fn(tokenizer, max_length=512):\n#     def collate_fn(features):\n        \n#         batch ={key: np.array([f[key]+[t]*(max_length-len(f[key])) for f in features], dtype=np.int32)\n#                 for t,key in zip([tokenizer.pad_token_id,-100],['input_ids','labels'])}\n#         return batch\n#     return collate_fn\n# from torch.utils.data import DataLoader\n\n# train_dataset = DataLoader(chunk_data_list, shuffle=True, #.remove_columns(['offset', 'text_id']), \n#                            batch_size=16,\n#                            collate_fn=mk_collate_fn(tokenizer, 512))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T19:05:29.59293Z","iopub.execute_input":"2022-02-18T19:05:29.593448Z","iopub.status.idle":"2022-02-18T19:05:29.602207Z","shell.execute_reply.started":"2022-02-18T19:05:29.59341Z","shell.execute_reply":"2022-02-18T19:05:29.601535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport tensorflow.data as tfdata\n#ds=\nimport numpy as np\n\ndef mk_collate_fn(tokenizer, max_length=512):\n    def collate_fn(features):\n        \n        batch = features.copy()\n        for t, key in zip([tokenizer.pad_token_id,-100], ['input_ids','labels']):\n            batch[key] = np.array([f+[t]*(max_length-len(f)) for f in batch[key]], \n                                  dtype=np.int32)\n        return batch\n    \n    return collate_fn\n\n    \ncollate_fn = mk_collate_fn(tokenizer, max_length)\n\nds ={k: tfdata.Dataset.from_tensor_slices(collate_fn(v)) for k,v in chunk_data.items()}\n#(chunk_data_list)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:35:21.540051Z","iopub.execute_input":"2022-02-24T08:35:21.540454Z","iopub.status.idle":"2022-02-24T08:35:21.569134Z","shell.execute_reply.started":"2022-02-24T08:35:21.540412Z","shell.execute_reply":"2022-02-24T08:35:21.568139Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"CPU times: user 21 ms, sys: 906 µs, total: 21.9 ms\nWall time: 21 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 32 if kaggle_init.is_tpu_available() else 2\ndummy_data = tfdata.Dataset.from_tensor_slices(\n    {\n        'input_ids': np.zeros((batch_size, max_length), dtype=np.int32),\n        'labels': -100*np.ones((batch_size, max_length), dtype=np.int32),\n        'text_id': np.array(['0'*11]*batch_size),\n        'offset': np.array(np.zeros(batch_size, dtype=np.int32))\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:35:25.692395Z","iopub.execute_input":"2022-02-24T08:35:25.693116Z","iopub.status.idle":"2022-02-24T08:35:25.703087Z","shell.execute_reply.started":"2022-02-24T08:35:25.693057Z","shell.execute_reply":"2022-02-24T08:35:25.702154Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"dummy_data","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:56:43.980698Z","iopub.execute_input":"2022-02-24T07:56:43.981196Z","iopub.status.idle":"2022-02-24T07:56:43.990582Z","shell.execute_reply.started":"2022-02-24T07:56:43.981126Z","shell.execute_reply":"2022-02-24T07:56:43.989179Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<TensorSliceDataset shapes: {input_ids: (128,), labels: (128,), text_id: (), offset: ()}, types: {input_ids: tf.int32, labels: tf.int32, text_id: tf.string, offset: tf.int32}>"},"metadata":{}}]},{"cell_type":"code","source":"import jax\njax.devices()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:35:30.190462Z","iopub.execute_input":"2022-02-24T08:35:30.190767Z","iopub.status.idle":"2022-02-24T08:35:30.210388Z","shell.execute_reply.started":"2022-02-24T08:35:30.190731Z","shell.execute_reply":"2022-02-24T08:35:30.209506Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[CpuDevice(id=0), CpuDevice(id=1)]"},"metadata":{}}]},{"cell_type":"code","source":"def subset(x):\n    return {k: x[k] for k in ['input_ids', 'labels', 'offset']}\n\ntrain_dataset = (ds['train'].\n                 map(subset).\n                 repeat().\n                 shuffle(4096).\n                 batch(batch_size=batch_size).\n                 batch(batch_size=jax.device_count()).as_numpy_iterator())\n\ntest_dataset = (ds['test'].\n                concatenate(dummy_data.repeat(jax.device_count())).\n                map(subset).batch(batch_size=batch_size, drop_remainder=True).\n                batch(batch_size=jax.device_count()).as_numpy_iterator())","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:35:32.363949Z","iopub.execute_input":"2022-02-24T08:35:32.364582Z","iopub.status.idle":"2022-02-24T08:35:32.454580Z","shell.execute_reply.started":"2022-02-24T08:35:32.364539Z","shell.execute_reply":"2022-02-24T08:35:32.453837Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"len(ds['test']), len(ds['train'])","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:35:37.165889Z","iopub.execute_input":"2022-02-24T08:35:37.166893Z","iopub.status.idle":"2022-02-24T08:35:37.172650Z","shell.execute_reply.started":"2022-02-24T08:35:37.166839Z","shell.execute_reply":"2022-02-24T08:35:37.171896Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(41, 393)"},"metadata":{}}]},{"cell_type":"code","source":"class Metric:\n    def __init__(self):\n        self.reset()\n    def reset(self):\n        self._value = 0\n        self._n = 0\n    def update(self,v):\n        self._n += 1\n        self._value += v\n    def value(self):\n        return self._value/self._n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T12:51:18.38627Z","iopub.execute_input":"2022-02-21T12:51:18.386819Z","iopub.status.idle":"2022-02-21T12:51:18.396472Z","shell.execute_reply.started":"2022-02-21T12:51:18.386763Z","shell.execute_reply":"2022-02-21T12:51:18.394711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{k: f'shape={v.shape}, dtype={v.dtype}' for k,v in next(iter(train_dataset)).items()}","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:56:58.010235Z","iopub.execute_input":"2022-02-24T07:56:58.010685Z","iopub.status.idle":"2022-02-24T07:56:58.098718Z","shell.execute_reply.started":"2022-02-24T07:56:58.010652Z","shell.execute_reply":"2022-02-24T07:56:58.098066Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'input_ids': 'shape=(2, 2, 128), dtype=int32',\n 'labels': 'shape=(2, 2, 128), dtype=int32',\n 'offset': 'shape=(2, 2), dtype=int32'}"},"metadata":{}}]},{"cell_type":"code","source":"local_device_count = jax.device_count()\nlocal_device_count","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:57:00.978749Z","iopub.execute_input":"2022-02-24T07:57:00.979077Z","iopub.status.idle":"2022-02-24T07:57:00.985938Z","shell.execute_reply.started":"2022-02-24T07:57:00.979040Z","shell.execute_reply":"2022-02-24T07:57:00.984821Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"import haiku as hk\nimport jax.numpy as jnp\nimport optax\nimport functools\nfrom typing import Any, Mapping\n\nclass Updater:\n    \"\"\"A stateless abstraction around an init_fn/update_fn pair.\n    This extracts some common boilerplate from the training loop.\n    \"\"\"\n\n    def __init__(self, net_init, loss_fn,\n                   optimizer: optax.GradientTransformation):\n        self._net_init = net_init\n        self._loss_fn = loss_fn\n        self._opt = optimizer\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def init(self, rng, data, pretrained_params=None):\n        \"\"\"Initializes state of the updater.\"\"\"\n        out_rng, init_rng = jax.random.split(rng)\n        params = self._net_init(init_rng, data)\n        if pretrained_params is not None:\n            params = hk.data_structures.merge(params, pretrained_params)\n        #params = hk.data_structures.map(lambda x: jnp.stack([x]*local_device_count), params)\n        opt_state = self._opt.init(params)\n        # rng = jax.random.PRNGKey(FLAGS.train_init_random_seed)\n        #rng = jnp.broadcast_to(rng, (local_device_count,) + rng.shape)\n        out = dict(\n            step=np.array(0),\n            rng=out_rng,\n            opt_state=opt_state,\n            params=params,\n            loss=np.array(0),\n        )\n        return out\n\n    @functools.partial(jax.jit, static_argnums=0)\n    def update(self, state: Mapping[str, Any], data: Mapping[str, jnp.ndarray]):\n        \"\"\"Updates the state using some data and returns metrics.\"\"\"\n        rng, new_rng = jax.random.split(state['rng'])\n        params = state['params']\n        loss, grads = jax.value_and_grad(self._loss_fn)(params, rng, data)\n\n        if compute_on_tpu:\n            grads = jax.lax.pmean(grads, 'i')\n\n\n        updates, opt_state = self._opt.update(grads, state['opt_state'])\n        params = optax.apply_updates(params, updates)\n\n        new_state = {\n            'step': state['step'] + 1,\n            'rng': new_rng,\n            'opt_state': opt_state,\n            'params': params,\n            'loss': state['loss'] + loss\n        }\n\n        return new_state ","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:35:43.061874Z","iopub.execute_input":"2022-02-24T08:35:43.062213Z","iopub.status.idle":"2022-02-24T08:35:43.078981Z","shell.execute_reply.started":"2022-02-24T08:35:43.062181Z","shell.execute_reply":"2022-02-24T08:35:43.077972Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def get_predictions(forward_fn, state, test_ds):\n\n    def run_net(params, rng, data):\n        return forward_fn.apply(params, rng, data, is_training=False)\n    \n    run_net = jax.pmap(run_net, axis_name='i')\n    pred = [run_net(state['params'], state['rng'], batch) for batch in test_ds]\n    return jax.device_get(pred)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:50:05.520396Z","iopub.execute_input":"2022-02-24T08:50:05.520735Z","iopub.status.idle":"2022-02-24T08:50:05.527883Z","shell.execute_reply.started":"2022-02-24T08:50:05.520703Z","shell.execute_reply":"2022-02-24T08:50:05.526489Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"class Log:\n    def __init__(self, step=0):\n        self.step = step\n        self.start_time = self.prev_time = time.time()\n        \n    def update(self,state):\n        step = int(state['step'][0])\n        step_delta,self.step = step-self.step, step\n        \n        c_time = time.time()\n        time_delta, self.prev_time = c_time - self.prev_time, c_time\n        \n        loss = float(state['loss'].mean())/step_delta\n        state['loss'] = 0*state['loss']\n        \n        return {'step': self.step,\n                'loss': loss,\n                'elapsed_time': time_delta,\n                'total_time':   c_time-self.start_time,\n                'iter_per_sec': time_delta/max(1,step_delta),\n                'sec_per_iter': step_delta/max(1,time_delta),\n               }\n\ndef format_log(log):\n    return \"iteration: {step:<5}, loss: {loss:.4f}, elapsed_time:{elapsed_time:.2f}\".format(**log)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:35:49.819020Z","iopub.execute_input":"2022-02-24T08:35:49.819606Z","iopub.status.idle":"2022-02-24T08:35:49.827745Z","shell.execute_reply.started":"2022-02-24T08:35:49.819557Z","shell.execute_reply":"2022-02-24T08:35:49.827087Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import logging\nimport time\nfrom transformers import AutoConfig\nfrom feedback2021.hk_roberta import (build_forward_fn, \n                                     lm_loss_fn, \n                                     # GradientUpdater, \n                                     hk, optax, functools, Mapping, jnp, jax)\n\n## global variables\n# batch_size = 16  # Train batch size per core\ntotal_batch_size = batch_size*jax.device_count()\nlearning_rate = 2.5e-5*(total_batch_size/32) # Max learning-rate\ngrad_clip_value = 0.15  # Gradient norm clip value\n\ncheckpoint_dir = '/jax-transformer'  # Directory to store checkpoints\nif just_test:\n    LOG_EVERY = 1\n    MAX_STEPS = 3\nelse:\n    LOG_EVERY = 250\n    MAX_STEPS = (3*len(ds['train']))//total_batch_size\n\nconfig = AutoConfig.from_pretrained(model_checkpoint, #'distilroberta-base', \n                                    label2id=label2id, \n                                    id2label=id2label).to_dict()\ntranslation = hk_roberta.weight_name_translation(config=config, prefix='roberta')\npretrained_params = hk_roberta.load_hf_pytorch_weights(model_checkpoint, #'distilroberta-base', \n                                                       translation)\n\nlogging.info = print\nlogging.info('Starting...')\n\nforward_fn = build_forward_fn(config)\n\nforward_fn = hk.transform(forward_fn)\n\nloss_fn = functools.partial(lm_loss_fn, forward_fn.apply, config)\n\nlr_schedule=optax.warmup_cosine_decay_schedule(init_value=0, \n                                               peak_value=1, \n                                               warmup_steps=min(500, MAX_STEPS//6), \n                                               decay_steps=MAX_STEPS-min(500,MAX_STEPS//6), \n                                               end_value=1e-4)\n\noptimizer = optax.chain(\n        optax.clip_by_global_norm(grad_clip_value),\n        optax.adam(learning_rate, b1=0.9, b2=0.99),\n        optax.scale_by_schedule(lr_schedule),\n    )\n\nupdater = Updater(forward_fn.init, loss_fn, optimizer)\n\n# Initialize parameters.\nlogging.info('Initializing parameters...')\nrng = jax.random.PRNGKey(428)\ndata = next(iter(train_dataset))\nstate = updater.init(rng, #jnp.broadcast_to(rng, (local_device_count,) + rng.shape), \n                     {k:v[0] for k,v in data.items()},\n                     pretrained_params=pretrained_params)\nif compute_on_tpu:\n    state = jax.device_put_replicated(state, jax.devices())\n    update = jax.pmap(updater.update, axis_name='i')\nelse:\n    update = updater.update\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:35:52.731207Z","iopub.execute_input":"2022-02-24T08:35:52.731848Z","iopub.status.idle":"2022-02-24T08:36:24.262050Z","shell.execute_reply.started":"2022-02-24T08:35:52.731809Z","shell.execute_reply":"2022-02-24T08:36:24.260225Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/316M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"666d4d36aeab4454afb4f62d3229cb51"}},"metadata":{}},{"name":"stdout","text":"unused torch weights: roberta.embeddings.token_type_embeddings.weight,\nroberta.pooler.dense.weight, roberta.pooler.dense.bias, lm_head.bias,\nlm_head.dense.weight, lm_head.dense.bias, lm_head.layer_norm.weight,\nlm_head.layer_norm.bias, lm_head.decoder.weight\nStarting...\nInitializing parameters...\n","output_type":"stream"}]},{"cell_type":"code","source":"logging.info('Starting train loop...')\ntrain_iter = iter(train_dataset)\nlog = Log()\nfor step  in range(MAX_STEPS): #enumerate(train_dataset):\n        data = next(train_iter)\n        state = update(state, data)\n        # We use JAX runahead to mask data preprocessing and JAX dispatch overheads.\n        # Using values from state/metrics too often will block the runahead and can\n        # cause these overheads to become more prominent.\n        if step % LOG_EVERY == 0:\n            last_log=log.update(state)\n            logging.info(last_log)\n\nlogging.info(last_log)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = get_predictions(forward_fn, state=state, test_ds=test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:50:16.489704Z","iopub.execute_input":"2022-02-24T08:50:16.489977Z","iopub.status.idle":"2022-02-24T08:50:23.373679Z","shell.execute_reply.started":"2022-02-24T08:50:16.489949Z","shell.execute_reply":"2022-02-24T08:50:23.372981Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"len(pred), pred[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:50:54.188065Z","iopub.execute_input":"2022-02-24T08:50:54.188883Z","iopub.status.idle":"2022-02-24T08:50:54.195233Z","shell.execute_reply.started":"2022-02-24T08:50:54.188841Z","shell.execute_reply":"2022-02-24T08:50:54.194070Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(5, (2, 2, 128, 8))"},"metadata":{}}]},{"cell_type":"code","source":"params = hk.data_structures.map(lambda name,module,x: x[0], state['params'])\nimport pickle\nwith open('params.pkl','wb') as f:\n    pickle.dump(params, f)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T06:13:23.821943Z","iopub.execute_input":"2022-02-23T06:13:23.822508Z","iopub.status.idle":"2022-02-23T06:13:27.022087Z","shell.execute_reply.started":"2022-02-23T06:13:23.822465Z","shell.execute_reply":"2022-02-23T06:13:27.020853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-23T06:13:31.428136Z","iopub.execute_input":"2022-02-23T06:13:31.428826Z","iopub.status.idle":"2022-02-23T06:13:32.394128Z","shell.execute_reply.started":"2022-02-23T06:13:31.428764Z","shell.execute_reply":"2022-02-23T06:13:32.39248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_schedule=optax.warmup_cosine_decay_schedule(init_value=0, \n                                               peak_value=1, \n                                               warmup_steps=500, \n                                               decay_steps=8500, \n                                               end_value=1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:41:44.23837Z","iopub.execute_input":"2022-02-21T06:41:44.238975Z","iopub.status.idle":"2022-02-21T06:41:44.245739Z","shell.execute_reply.started":"2022-02-21T06:41:44.238926Z","shell.execute_reply":"2022-02-21T06:41:44.244518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jaxlib, jax\njaxlib.__version__, jax.__version__, hk.__version__","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:45:48.632171Z","iopub.execute_input":"2022-02-21T06:45:48.632588Z","iopub.status.idle":"2022-02-21T06:45:48.640181Z","shell.execute_reply.started":"2022-02-21T06:45:48.632543Z","shell.execute_reply":"2022-02-21T06:45:48.639215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt = np.arange(0,9000,10)\nlr = [lr_schedule(jnp.array([i])) for i in cnt]\nplt.plot(cnt, lr)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T06:41:48.464737Z","iopub.execute_input":"2022-02-21T06:41:48.465445Z","iopub.status.idle":"2022-02-21T06:42:26.896087Z","shell.execute_reply.started":"2022-02-21T06:41:48.465381Z","shell.execute_reply":"2022-02-21T06:42:26.893875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{'loss': 2.4778389930725098, 'step': 0.0, 'steps_per_sec': 13.779059174634387}\n{'loss': 1.3683964014053345, 'step': 500.0, 'steps_per_sec': 2.5767113856201855}\n{'loss': 1.6631159782409668, 'step': 1000.0, 'steps_per_sec': 2.57725389686341}\n{'loss': 1.3581798076629639, 'step': 1500.0, 'steps_per_sec': 2.5771785561488483}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jax.core.gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T18:59:27.862142Z","iopub.execute_input":"2022-02-18T18:59:27.862405Z","iopub.status.idle":"2022-02-18T18:59:29.421439Z","shell.execute_reply.started":"2022-02-18T18:59:27.862376Z","shell.execute_reply":"2022-02-18T18:59:29.420597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jax.numpy.array([1,1])\n#jax.device_get('gpu')\n#jax.devices('gpu')\n! nvcc --version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n# TRAINING HYPERPARAMS\neffective_batch_size = 32\nmax_steps = 4000\nlog_steps = 500\n#n_step_examples = 8*500\nbatch_size = 16\ngrad_accumulation = effective_batch_size//batch_size\nlearning_rate = 5e-5\nweight_decay = 0.01\nwarmup_ratio = 0.1\nn_epochs = 3\nmodel_name = model_checkpoint.split(\"/\")[-1]\ntraining_args = TrainingArguments(\n    f\"{model_name}-{task}\",\n    evaluation_strategy = \"steps\",\n    eval_steps = log_steps,\n    logging_strategy = \"steps\",\n    logging_steps = log_steps,\n    save_strategy = \"steps\",\n    save_steps = log_steps,\n    learning_rate = learning_rate,\n    per_device_train_batch_size = batch_size,\n    per_device_eval_batch_size = batch_size,\n    #num_train_epochs = n_epochs,\n    max_steps = max_steps,\n    weight_decay = weight_decay,\n    report_to = 'wandb', \n    gradient_accumulation_steps = grad_accumulation,\n    warmup_steps = int(1.5*(log_steps)),\n    # logging_steps = 100,\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    greater_is_better=True,\n)\n#training_args","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['test']=add_rle_word2(data['test'])\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=chunk_data[\"train\"].remove_columns(['offset', 'text_id']), #.select(range(100)),\n    eval_dataset=chunk_data[\"test\"].remove_columns(['offset', 'text_id']), #.select(range(100)),\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=mk_binary_metric(chunk_ds=chunk_data['test'],\n                                     orig_ds=data['test'])\n    #,\n    #                                 min_word_cnt=[0,10,5,10,3,10,6,6]), #.select(range(100))), \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.save_model(model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wandb.init()\nimport pickle\nfrom feedback2021.postprocess import mk_prediction_transform\nfor k,v in chunk_data.items():\n    predictions = trainer.predict(v.remove_columns(['offset', 'text_id']))\n    prediction_transform = mk_binary_prediction_transform(chunk_ds=v, orig_ds=data[k])\n    predictions = prediction_transform(predictions[0])\n    with open(f'{k}_predictions.pkl','wb') as f:\n        pickle.dump(predictions, f)\n    wandb.save(f'{k}_predictions.pkl','./','now')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! rm longformer-base-4096-token_classification/ -rf\n#!rm distilroberta-base-token_classification -rf\n! ls -sh distilroberta-base-1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# From this point on there is no need to gpu!","metadata":{"execution":{"iopub.execute_input":"2021-12-30T06:52:35.965148Z","iopub.status.busy":"2021-12-30T06:52:35.964896Z","iopub.status.idle":"2021-12-30T06:52:36.089436Z","shell.execute_reply":"2021-12-30T06:52:36.088549Z","shell.execute_reply.started":"2021-12-30T06:52:35.96512Z"}}},{"cell_type":"code","source":"prediction_file = wandb.restore('predictions.pkl', run_path='prvi/huggingface/d17yam8m')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_file_name = 'test_predictions.pkl' #if os.path.exists('test_predictions.pkl') else prediction_file.name\nwith open(prediction_file_name, 'rb') as f:\n    saved_predictions = pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chunk_ds, orig_ds = chunk_data['test'].to_dict(), data['test'].to_dict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter_prediction(prediction, min_word_cnt):\n    return [b for b in prediction if b[2]-b[1]>=min_word_cnt[b[0]]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport pandas as pd\nres = []\nfor mwc in tqdm(range(0,15)):\n#     transform_prediction = mk_prediction_transform(chunk_ds=chunk_ds,\n#                                                    orig_ds=orig_ds, min_word_cnt=mwc)\n#     predictions = transform_prediction(saved_predictions[0])\n    \n    scores = np.array([metric.score_example(y_true=y_true, \n                                            y_pred=filter_prediction(y_pred,mwc)) \n              for y_pred,y_true in zip(saved_predictions,orig_ds['rle_word'])]).sum(axis=0)\n    scores = [metric.f1(*score) for score in scores]\n    f1 = sum(scores)/len(scores)\n    scores = {id2label[i+1]:score for i,score in enumerate(scores)}\n    scores['f1'] = f1\n    scores['min_word_cnt']=mwc\n    res.append(scores)\n\npd.DataFrame(res).set_index('min_word_cnt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mwc =[0, 10, 6, 15, 6, 11, 9, 8]\n\nscores_ = np.array([metric.score_example(y_true=y_true, \n                                        y_pred=filter_prediction(y_pred,mwc)) \n              for y_pred,y_true in zip(saved_predictions,orig_ds['rle_word'])]).sum(axis=0)\nscores = [metric.f1(*score) for score in scores_]\nf1 = sum(scores)/len(scores)\nscores = {id2label[i+1]:score for i,score in enumerate(scores)}\nscores['f1'] = f1\n    \n# transform_prediction = mk_prediction_transform(chunk_ds=chunk_ds,\n#                                                 orig_ds=orig_ds, \n#                                                min_word_cnt=[0, 10, 6, 15, 6, 11, 9, 8])\n# predictions = transform_prediction(saved_predictions[0])\n# scores = np.array([metric.score_example(y_true=y_true, y_pred=y_pred) \n#               for y_true,y_pred in zip(predictions,orig_ds['pred_range'])]).sum(axis=0)\n# scores = [metric.f1(*score) for score in scores]\n# f1 = sum(scores)/len(scores)\n# scores = {id2label[i+1]:score for i,score in enumerate(scores)}\n# scores['f1'] = f1\nscores    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = [ sorted(pred, key=lambda x: x[1]) for pred in saved_predictions]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_result(i=20, orig_ds=data['test'],predictions=predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsaved_predictions[8],data['test'][8]['rle_token']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = [metric.score_example(y_true=y_true, y_pred=y_pred) for y_true,y_pred in zip(predictions,orig_ds['pred_range'])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[metric.f1(*x) for x in np.array(scores).sum(axis=0)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = np.argsort(np.array(scores)[:,:,1:].sum(axis=(1,2)))[::-1]\nidx[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}